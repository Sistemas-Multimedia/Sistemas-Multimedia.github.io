\input{../definitions}
\title{\SM{} - Study Guide - Milestone 10: Motion Estimation}

\maketitle

\section{Description}

\subsection{Motion estimation for what?}
Temporal correlation between video frames can be removed by MC (Motion
Compensation). MC implies to substract to the frames those
information, in form of a prediction frame $\hat{P}$, that can be
infered from neighbor frames, as long as these frames are known by the
decoder or the motion information is transmited from the encoder to
the decoder.

A MC Predictor (MCP) inputs one or more reference frames $R$, a
predicted frame $P$ (the frame that we want to compensate), and a
motion vectors field $\overset{\cdot\rightarrow\cdot}{V}$. In the next
milestone we will see how to find $\hat{P}$ and how to use it. In this
milestone we show how to compute $\overset{R\rightarrow P}{V}$.

\subsection{What exactly we need?}
Our main objective is to minimize the differences (for example, the
\href{https://en.wikipedia.org/wiki/Euclidean_distance}{L$_2$
  distance} between $P$ and $\hat{P}$, because $E=P-\hat{P}$ will be
more compressible. To achieve this, we can compute
$\overset{R\rightarrow P}{V}$ that simply minimizes the L$_2$ energy
of $E$, $|E|^2$, or we can compute a $\overset{R\rightarrow P}{V}$
that also describes the optical flow~\cite{horn1981determining}
between the pixels of $R$ and $P$, that although not necessary has to
minimize $|E|^2$, tries to show the true movement of the pixels
between $R$ and $P$. This second option has the advantage of generate
more visually pleasing predictions.

The first type of techniques are simply called ``motion estimation
techniques'', and are usually faster than the based on the computation
of the optical flow.

%Let's see two basic techniques to estimate the motion between 2
%frames, $R$ and $P$. In this discussion it will be supposed that the
%motion of the objects that are in both frames is bounded, and that the
%luminance varies smoothly between adjacent frames.

Let's see some of the most used techniques for estimating the motion
between two frames. Notice that, in general, better estimations can be
found if more than only two frames are used because the intertia of
the objects (with mass). However, this case will not be considered for
now.

\subsection{Disjoint block matching}
$P$ can be divided, for example, in blocks of 16x16 pixels, and we can
use the MSE (that is considered a L$_2$ distance) between each block
of $P$ and its surrounding pixels in $R$ (the so called search
area)~\cite{zhu2000new}. For each block a motion vector that indicates
the best match (smaller distance) is found. The set of motion vectors
form $\overset{R\rightarrow P}{V}$ that obviously, except for a block
size of 1x1, will be less dense than $R$ and $P$. Notice, however,
that, it is not a good idea to use such a small block size because, in
general, the motion vectors will not describe the optical flow.

\subsection{Overlaped block matching}
A better approximation to the optical flow can be found if we allow
the blocks to overlap in $P$~\cite{orchard1994overlapped}, and the
overlaped pixels between blocks are averaged for building
$\hat{P}$. The main drawback of this technique is that it more
computationally demanding than the previous one.

\subsection{Transform analysis}
One of the most successful techniques for computing the (dense)
optical flow is based on the analysis of the coefficients resulting
from transforming the frames using a polynomial expansion (the details
of this transform and the impact of the motion in the coefficients can
be found in the paper or Gunnar
Farneb{\"a}ck~\cite{farneback2003two}). This is the algorithm that we
will use in our experiments for two important reasons: (1) it is quite
efficient in terms both of performance and speed, and (2) it is
already
\href{https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html}{implemented}
in OpenCV.

\subsection{Machine learning}
ANNs (Artifical Neural Networks) can be trained to estimate the
motion between frames~\cite{dosovitskiy2015flownet}.

\begin{comment}
The optical flow~\cite{horn1981determining} tries to establish connections between the pixels of
the frames $P$ and $R$ supposing that:
\begin{enumerate}
\item $P$ and $R$ are adjacent in time (if $R$ was taken at time $t$,
  $P$ is taken at time $dt+t$) and therefore, similar in
  content.
\item Similarity between images implies that the pixels in both
  frames, $R$ and $P$, will have the same luminance. If $I(x,y,t)$
  measures the luminance of the pixel $(x,y)$ of the frame $R$,
  similarity can be modeled by
  \begin{equation}
    I(x+dx, y+dy, t+dt) = I(x,y,t),
    \label{eq:similarity}
  \end{equation}
  where $I(x+dx, y+dy, t+dt)$ is the corresponding pixel in the frame
  $P$. The first part of the Eq.~\ref{eq:similarity} can be also
  computed by (using the first-order Taylor expansion) as
  \begin{equation}
    I(x+dx, y+dy, t+dt) = I(x,y,t) + \frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt,
    \label{eq:taylor_exp}
  \end{equation}
  andtherefore, it must be true that
  \begin{equation}
    \frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt = 0.
    \label{eq:constraint}
  \end{equation}
  Dividing by $dt$, we finally get that
  \begin{equation}
    \frac{\partial I}{\partial x}\frac{dx}{dt} + \frac{\partial I}{\partial y}\frac{dy}{dt} + \frac{\partial I}{\partial t} = 0.
  \end{equation}
\item Adjacent pixels follow parallel
  trajectories~\cite{horn1981determining}, with basically means that
  neighbor pixels will have similar motion.
\end{enumerate}
\end{comment}

\section{What you have to do?}

In this notebook you can find how to estimate the optical flow between
two frames. Please, modify it to find suitable values for the
parameters \texttt{levels}, \texttt{winsize} and
\texttt{iterations}. Supposing that the impact of each parameter is
independent from the rest, the best way of comparing two different
configurations is render RD curves using quantization and compressing
the residues.

\section{Timming}

Please, finish this milestone before the next class session.

\section{Deliverables}

None.

\section{Resources}

\bibliography{motion-estimation}
