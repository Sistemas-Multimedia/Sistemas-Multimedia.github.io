\input{../definitions}
\title{\SM{} - Study Guide - Milestone 10: Motion Estimation}

\maketitle

\section{Description}

Temporal correlation between video frames can be removed by MC (Motion
Compensation). MC implies to substract to the frames those
information, in form of a prediction frame $\hat{P}$, that can be
infered from neighbor frames, as long as these frames are known by the
decoder or the motion information is transmited from the encoder to
the decoder.

A MC Predictor (MCP) inputs one or more reference frames $R$, a
predicted frame $P$ (the frame that we want to compensate), and a
motion vectors field $\overset{\rightarrow}{V}$. In the next milestone
we will see how to find $\hat{P}$ and how to use it. In this milestone
we show how to compute $\overset{\rightarrow}{V}$.

Let's see two basic techniques to estimate the motion between 2
frames, $R$ and $P$. In this discussion it will be supposed that the
motion of the objects that are in both frames is bounded, and that the
luminance varies smoothly between adjacent frames.

\subsection{Disjoint block matching}
$P$ can be divided, for example, in blocks of 16x16 pixels, and we can
apply some distortion metric (such as the MSE) to compute the
\href{https://en.wikipedia.org/wiki/Euclidean_distance}{L$_2$
  distance} between each block of $P$ and its surrounding blocks in
$R$ (the search area). For each block a motion vector that indicates
the best match (smaller distance) is found. The set of motion vectors
form $\overset{\rightarrow}{V}$.

\subsection{Overlaped block matching}
This technique is similar to the previous one, except in which the
blocks can be overlaped in $P$. Obviously, the number of motion
vectors is higher, which in general can model better the motion. The
overlaped pixels between blocks are averaged.

\subsection{(Dense) Optical flow}
The optical flow~\cite{horn1981determining} tries to establish connections between the pixels of
frames $P$ and $R$ supposing that:
\begin{enumerate}
\item $P$ and $R$ are adjacent in time (if $R$ was taken at time $t$,
  $P$ is taken at time $dt+t$) and therefore, similar in
  content.
\item Similarity between images implies that the pixels in both
  frames, $R$ and $P$, will have the same luminance. If $I(x,y,t)$
  measures the luminance of the pixel $(x,y)$ of the frame $R$,
  similarity can be modeled by
  \begin{equation}
    I(x+dx, y+dy, t+dt) = I(x,y,t),
    \label{eq:similarity}
  \end{equation}
  where $I(x+dx, y+dy, t+dt)$ is the corresponding pixel in the frame
  $P$. The first part of the Eq.~\ref{eq:similarity} can be also
  computed by (using the first-order Taylor expansion) as
  \begin{equation}
    I(x+dx, y+dy, t+dt) = I(x,y,t) + \frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt,
    \label{eq:taylor_exp}
  \end{equation}
  andtherefore, it must be true that
  \begin{equation}
    \frac{\partial I}{\partial x}dx + \frac{\partial I}{\partial y}dy + \frac{\partial I}{\partial t}dt = 0.
    \label{eq:constraint}
  \end{equation}
  Dividing by $dt$, we finally get that
  \begin{equation}
    \frac{\partial I}{\partial x}\frac{dx}{dt} + \frac{\partial I}{\partial y}\frac{dy}{dt} + \frac{\partial I}{\partial t} = 0.
  \end{equation}
\item Adjacent pixels follow parallel
  trajectories~\cite{horn1981determining}, with basically means that
  neighbor pixels will have similar motion.
\end{enumerate}

% http://www.jonathanmugan.com/GraphicsProject/OpticalFlow/
This one equation has two unknowns and so does not have a unique solution. This is the mathematical consequence of the aperture problem. The aperture problem is that there is not enough information in a small area to uniquely determine motion (this is what causes the barber pole illusion). To add an additional constraint, Horn and Schunck [2] use a global regularization calculation. They assume that images consist of objects undergoing rigid motion, and so over relatively large areas the optical flow will be smooth. They then minimize the square of the magnitude of the gradient of optical flow using the equation
%
%
%
In contrast, Lucas and Kanade [3] use a local least squares calculation to provide the constraint by minimizing in the neighborhood surrounding the pixel, represented in equation form by
%
%
%

% https://medium.com/@nabil.madali/introduction-to-optical-flow-77c8f61b04c4
It is the instantaneous velocity of the pixel movement of the spatially moving object on the observation imaging plane. the image constraint equation
%
In 1981, Horn and Schunck creatively linked the two-dimensional velocity field with the gray level, introduced the optical flow constraint equation, and obtained the basic algorithm for optical flow calculation.
%
Assuming that the pixel intensity of the target in the image does not change between consecutive frames and let I(x,y,t) denote the gray value of the pixel at time t ,we have:

\subsection{Sparse optical flow}
This is a special case of the dense clase in which only some
interesting points (such as the edges or the corners of the objects)
are tracked. This speeds up the ME process.

\section{What you have to do?}

Please, implement Eq.~\ref{eq:output}, preferiblely in a Jupyter
notebook. Verify also Eq.~\ref{eq:crs}.

\section{Timming}

In groups, you will present the results for this milestone during the
examination time.

\section{Deliverables}

None.

\section{Resources}

\bibliography{motion-estimation}
