\input{../definitions}
\title{\SM{} - Study Guide - Milestone 5: Quantizing in the RGB Domain}

\maketitle

\section{Description}
\href{https://en.wikipedia.org/wiki/Visual_system}{Humans} are quite
efficient recognizing the information stored in images (and frames of
a video), even when this information has been degraded or (partially)
lost. \href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{Quantization}~\cite{sayood2017introduction,vetterli2014foundations}
is a technique that can remove the part of the visual information that
is less relevant for us, and implies
\href{https://en.wikipedia.org/wiki/Lossy_compression}{lossy coding},
which provides
\href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression
  ratios} usually at least one order of magnitude higher than using
\href{https://en.wikipedia.org/wiki/Lossless_compression}{lossless
  coding}.

In this milestone we will quantize a frame in the
\href{https://en.wikipedia.org/wiki/RGB_color_model}{RGB color
  domain}. A
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{\textbf{quantizer}}
(typically denoted by $Q$) is a
\href{https://en.wikipedia.org/wiki/Data_compression}{encoding system}
that inputs a sequence of (digital) samples $x=\{x_i\}$ and outputs a
sequence of quantization indexes $k$ (see the Fig.~\ref{fig:Q}). The
inverse system, called a \textbf{dequantizer} (denoted by
$Q^{-1}$), recovers an approximate version of $x$ that we will denote
by $\tilde{x}$, whose similarity with $x$ inversely depends on a frame
quantization step (QS) $\Delta$. Notice that although $\Delta$ is an
input parameter to the quantizer, it has not been considered in the
figure to keep it simpler.

We define the quantization error\footnote{Also called quantization
noise.}
\begin{equation}
  e_i = x_i - \tilde{x}_i,
\end{equation}
that obviously, should be minimized.

\begin{figure}
  \centering
  \myfig{graphics/Q}{2cm}{200}
  \caption{Scalar quantization and dequantization of a signal.}
  \label{fig:Q}
\end{figure}

Quantizers can be classifies into:
\begin{enumerate}
\item \textbf{Scalar quantizers}: those that produce a quantization
  index $k_i$ by each input sample $x_i$.
\item \textbf{Vector quantizers}: that process the input by blocks of
  samples, called vectors, producing a quantization index by vector,
  and usually, the length of the quantization index y much shorter
  than the length of the vector. Vector Quantization (VQ) can remove
  correlation and therefore, are more efficient that Scalar
  Quantization (SQ). Unfortunately, the computational requirements of VQ
  are, by far, higher than the needed by SQ. If we also consider that
  there are other techniques (such as transform coding) that are able
  to decorrelate the samples with less computation than VQ, we can
  understand why SQ has been selected, for example, in
  most \href{https://en.wikipedia.org/wiki/Video_coding_format}{video
  codecs}.
\end{enumerate}

Quantizers, also, can be classified as:
\begin{enumerate}
\item \textbf{Uniform quantizers}: those in which $\Delta$ is
  idependent on the amplitude of the samples.
\item \textbf{Non-unifom quantizers}, on the contrary, when $\Delta$
  depends (directly or indirectly) on the amplitude of the samples. An
  example is a
  \href{https://en.wikipedia.org/wiki/Companding}{companded
    quantizer}.
\end{enumerate}

Non-uniform quantizers can be:
\begin{enumerate}
\item \textbf{Static quantizers}: if $\Delta$ is known \emph{a
priori}.
\item \textbf{Adaptive quantizers}: when $\Delta$ is adapted to
  minimize the quantization error, depending ``on-the-fly'' on the
  characteristics\footnote{Depending, for example, on the
    \href{https://en.wikipedia.org/wiki/Probability_density_function}{PDF}
    of the signal.} of the signal.
\end{enumerate}

All quantizers can be classified into:
\begin{enumerate}
\item \textbf{Mid-tread quantizers}, if $\tilde{x}_i$ can be $0$.
\item \textbf{Mid-rised quantizers}, if $\tilde{x}_i$ never is $0$,
  even if $x_i=0$.
\end{enumerate}

Finally, quantizers can be classified as:
\begin{enumerate}
\item \textbf{Dead-zone quantizers}, that are characterized by a QS of
  length $2\Delta$ for $x_i=0$. Deadzone quantizers tends to remove
  the
  \href{https://en.wikipedia.org/wiki/Noise_(electronics)}{electronic
    noise} (that usually has an small amplitude compared to the input
  signal $x$). Notice that dead-zone quantizers should not be
  consdered uniform, and that all dead-zone quantizers, by definition,
  are mid-tread.
\item \textbf{No dead-zone quantizers}, when the dead-zone does not
  exist.
\end{enumerate}

\begin{figure}
  \centering
  \myfig{iomap_mr}{5cm}{500}
  \caption{Input/output map of a mid-riser quantizer with $\Delta=2$.}
  \label{fig:iomap_mr}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_mr}{5cm}{500}
  \caption{Quantization error of a mid-riser quantizer with $\Delta=2$.}
  \label{fig:qe_mr}
\end{figure}

\begin{figure}
  \centering
  \myfig{iomap_mt}{5cm}{500}
  \caption{Input/output map of a mid-tread quantizer with $\Delta=2$.}
  \label{fig:iomap_mt}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_mt}{5cm}{500}
  \caption{Quantization error of a mid-tread quantizer with $\Delta=2$.}
  \label{fig:qe_mt}
\end{figure}

\begin{figure}
  \centering
  \myfig{iomap_dz}{5cm}{500}
  \caption{Input/output map of a dead-zone quantizer with $\Delta=2$.}
  \label{fig:iomap_dz}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_dz}{5cm}{500}
  \caption{Quantization error of a dead-zone quantizer with $\Delta=2$.}
  \label{fig:qe_dz}
\end{figure}

Figs.~\ref{fig:iomap_mr}, \ref{fig:qe_mr}, \ref{fig:iomap_mt},
\ref{fig:qe_mt}, \ref{fig:iomap_dz}, and \ref{fig:qe_dz} describe the
behaviour of 3 different quantizers.  Use this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/05-quantization/digital_quantization.ipynb}{notebook}
to gain more insights about quantization.

\subsection{Quantization in the RGB domain}
Supposing that we will use a static uniform dead-zone quantizer, a
color RGB image can be quantized chanel by channel, using QSs
$\Delta_{\text{R}}$, $\Delta_{\text{G}}$, and $\Delta_{\text{B}}$. A
reasonable question that arises here is: given a target bit-rate $R$
for the compressed frame, how the QSs should be chosen to minimize the
distortion?  At this point we can consider two different optimization
perspectives. In the first one, we consider strictly visual
considerations, and obviously, any alternative different from
\begin{equation}
  \Delta_{\text{R}} = \Delta_{\text{G}} = \Delta_{\text{B}}
  \label{eq:simple_Q}
\end{equation}
will produce some alteration in the color (also called the
``chroma'') of the reconstructed frame.

In the second one, only a pure
\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{Rate/Distortion
  (RD) performance} is considered. From a RD perspective, the best
combination of QSs is those that optimizes (makes closer to the origin
of coordinates) the RD curve. A RD curve expresses the distortion
(typically the
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{Root
  Mean Square Error (RMSE)}) as a function of the bit-rate. In the
case of encoding a RGB image, we have 3 RD curves, one for each
channel. Thus, for example, the RD curve for the red channel measures,
for different QSs, the distortion of reconstructing only the red
channel as a function of the bit-rate generated for the corresponding
QS.

\begin{figure}
  \centering
  \myfig{graphics/RD_slopes}{3cm}{300}
  \caption{Two RD curves with different shape.}
  \label{fig:RD_slopes}
\end{figure}

Normal RD curves are convex (see Fig.~\ref{fig:RD_slopes}), which
means that if $\lambda_i$ is the slope of the curve measured at the
$i$-th point of the curve (starting at the lowest bit-rate), it always
hold that
\begin{equation}
  \lambda_i > \lambda_{i+1}.
\end{equation}
$\lambda$ quantifies the trade-off between decreasing the distortion
(the slopes are always negative) while the bit-rate increases (the
higher the slope, the high the benefit). If we suppose now that the
contribution to the quality of each channel are additive, that is
\begin{equation}
  D = D_{\text{R}} + D_{\text{G}} + D_{\text{B}},
\end{equation}
where $D$ denotes distortion, then the optimal QSs must satisfy
that~\cite{vetterli1995wavelets,sayood2017introduction}
\begin{equation}
  \lambda_{\text{R}} = \lambda_{\text{G}} = \lambda_{\text{B}}.
  \label{eq:optimal_quantization}
\end{equation}

To see this, lets suppose that we have used, for example, a set of QSs
so that
$\lambda_{\text{R}} = 2\lambda_{\text{G}} = 2\lambda_{\text{B}},$ and
that we still have room for spending more bits encoding the frame. In
this situation, the maximum benefit would be obtained if and only if
we decrease $\Delta_{\text{R}}$ because the sloper is double the slope
of the other curves. Therefore, the optimal QSs are obtained when
Eq.~\ref{eq:optimal_quantization} is true.

\begin{comment}
Thus, the optimal QSs should
operate in the curves with the same RD slope,
\begin{equation}
  \lambda_{\text{R}} = \lambda_{\text{G}} = \lambda_{\text{B}},
  \label{eq:optimal_quantization}
\end{equation}
for a given total bit-rate $R$, which implies that the contribution of each channel (the ratio between
quality and bit-rate) to the quality of $\tilde{x}$ has been highest
possible~\cite{vetterli1995wavelets,sayood2017introduction}.
\end{comment}

Unfortunately, the previous procedure implies the computation of the
RD curve for each channel, which is a time-consuming operation. For
this reason, and supposing that the statistics of each channel are
similar and therefore, each channel is going to generate a RD curve
with the same slopes for the same QSs, we can suppose that
Eq.~\ref{eq:simple_Q} satisfies Eq.~\ref{eq:optimal_quantization}.

\section{What you have to do?}
\begin{enumerate}
\item Please, improve this jupyter
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/05-quantization/performance.ipynb}{notebook}
  to test if Eq.~\ref{eq:simple_Q} is not optimal (at least there is a
  different configuration of QSs better that this equation).
\item Do you think that our life would be easier if we had an entropy
  encoder that allows to select the quantization step by its slope?
\end{enumerate}
%\begin{enumerate}
%\item Please, modify this
%  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/05-quantization/performance.ipynb}{notebook}
%  in order to use the
%  \href{https://docs.opencv.org/master/d4/da8/group__imgcodecs.html}{TIFF
%    and JPEG 2000 image formats} instead of PNG. Compare the RD
%  curves.
%\item In the previous
%  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/05-quantization/performance.ipynb}{notebook}
%  the three color channels, R, G, and B has been quantized using the
%  same QS ($\Delta_{\text{R}} = \Delta_{\text{G}} =
%  \Delta_{\text{B}}$). Do you think that this strategy minimizes the
%  quantization error?
%\item Compare the estimation provided by the entropy with the
%  DEFLATE's bit-rates.
%\end{enumerate}

\section{Timming}

Please, finish this notebook before the next class session.

\section{Deliverables}

None.

\section{Resources}

\bibliography{data-compression,signal-processing,DWT}
