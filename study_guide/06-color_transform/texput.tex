\input{../definitions}
\title{\SM{} - Study Guide - Milestone 6: Removing Redundancy with a Color Transform}

\maketitle

\section{Description}

\subsection{Introduction}
The main objective of this milestone is to remove the intercomponent
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundancy} that
most of natural images exhibit. In general redundancy in signals is
usually expressed as a
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
or statistical/frequency/spatio/temporal dependency between
samples. In the case of an image (and of course, of a video), a sample
is a color component (or
\href{https://en.wikipedia.org/wiki/Color_image}{channel}) with 3
bands, and one source of redundancy is the correlation between color
components.

One way of estimating this redudancy is to compute the
\href{https://en.wikipedia.org/wiki/Entropy_(information_theory)}{0-order
  entropy} of the signal: the higher the entropy, the lower the
redudancy. In fact, if we suppose that the samples of the signal are
uncorrelated, the 0-order entropy is an exact mesarure of the expected
bit-rate achieved by an
\href{https://en.wikipedia.org/wiki/Arithmetic_coding}{arithmetic
  encoder}. Unfortunately, the 0-order entropy is usally a lower bound
for the estimation of the redundancy. A better way is to use an
\href{https://en.wikipedia.org/wiki/Data_compression}{lossless
  compressor}: the higher the length of the compressed file compared
to the length of the original file, the lower the
redundancy.\footnote{If the length of the compressed file equal or
  larger than the lengh of the original file, then, for the compressor
  that we are using, there is not redundancy in the original
  representation.} Notice, however, that although this estimation is
more accurate than the entropy, in general, it depends on the encoding
algorithm (different algoritms can provide different estimations).

In this milestone we are going to estimate the intercomponent
redundancy of a video frame $X$, i.e., the redundancy generated by the
\href{https://en.wikipedia.org/wiki/Color_space}{color space} that has
been used to represent $X$. The two color spaces that are going to be
researched are: (1)
\href{https://en.wikipedia.org/wiki/RGB_color_model}{the RGB color
  space}, and (2) the \href{https://en.wikipedia.org/wiki/YCbCr}{YCbCr
  color space}.

\subsection{The RGB/YCbCr transform}
To transform a (color) pixel from the RGB to the YCbCr domain, we will use
\href{https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html}{the
  RGB to YCbCr (analysis) transform}, defined as
\begin{equation}
  \begin{array}{lcl}
    \text{Y}  & = & 0.299\text{R} + 0.587\text{G} + 0.114\text{B} \\
    \text{Cr} & = & 0.713(\text{R} - \text{Y}) + \delta  \\
    \text{Cb} & = & 0.564(\text{B} - \text{Y}) + \delta,
  \end{array}
  \label{eq:analysis}
\end{equation}
where
\begin{equation}
  \delta = \left\{
  \begin{array}{ll}
    128 & \text{for 8 bits (unsigned) images},\\
    32768 & \text{for 16 bits (unsigned) images},\\
    0.5 & \text{for floating point (}[0,1]\text{) images}.
  \end{array}
  \right.
\end{equation}

The inverse (synthesis) transform is defined by
\begin{equation}
  \begin{array}{lcl}
    \text{R} & = & \text{Y} + 1.403(\text{Cr} - \delta) \\
    \text{G} & = & \text{Y} - 0.714(\text{Cr} - \delta) - 0.344(\text{Cb} - \delta)\\
    \text{B} & = & \text{Y} + 1.773(\text{Cb} - \delta).
  \end{array}
  \label{eq:synthesis}
\end{equation}

\subsection{Quantization in the YCbCr domain}
After analyzing the frame (representing it in the YCbCr domain), the
next natural step is quantization. Supposing that we will use a static
uniform dead-zone quantizer with quantization steps
$\Delta_{\text{Y}}$, $\Delta_{\text{Cb}}$, and $\Delta_{\text{Cr}}$,
for the components Y, Cb, and CR, repectively, and supposing that the
contribution to the reconstruction of $X$ of one of the components is
not influenced by the contribution of the rest of components (for
this, both color spaces (RGB and YCbCr) should be orthogonal), the
optimal quantization steps $\Delta^*_{\text{Y}}$,
$\Delta^*_{\text{Cb}}$, and $\Delta^*_{\text{Cr}}$, can be found using
the Constant-Slope
\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{Rate-Distortion}
Quantization Strategy
(CS-RS-QS)~\cite{vetterli1995wavelets,sayood2017introduction}. As it
can be seen in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
a RD (Rate-Distortion) curve is a 2D graph where we represent the
distortion as a function of the bit-rate. Thus, the closer the curve
to the point (0,0) of the graph, the better the performance of the
encoding system in terms of RD. Now, if we suppose that each component
(Y, Cb, and Cr) is quantized and compressed independently, we can find
the optimal quantization steps, given a maximum target bit-rate
$R^{\text{max}}$, selecting them as
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cb}} = \lambda_{\text{Cr}}
\end{equation}
where, $\lambda(R)$ is the slope of the RD curve for a given bit-rate
$R$, satisfiying also that
\begin{equation}
  R_{\text{Y}} + R_{\text{Cb}} + R_{\text{Cr}} \le R^{\text{max}}.
\end{equation}

Unfortunately, the transforms expressed by Eqs.~\ref{eq:analysis} and
\ref{eq:synthesis} are not orthogonal (for example, in
Eq.~\ref{eq:analysis}, the value of Cr depends on the value of Y, and
therefore, there is a dependency between both
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis}). This
dificults the finding of $\Delta^*_{\text{Y}}$,
$\Delta^*_{\text{Cb}}$, and $\Delta^*_{\text{Cr}}$ because the
quantization error generated in one of the components influences
the quantization error of the rest of components, and when this
happens, we cannot use CS-RS-QS.

\begin{comment}
The International Consultative Committee for Radio (CCIR)11 Recommendation 601:
\begin{equation}
\begin{array}
Y ′= 219(+0.299R′ + 0.587G′ + 0.114B′) + 16 \\
CB′= 224(-0.169R′ - 0.331G′ + 0.500B′) + 128 \\
CR′= 224(+0.500R′ - 0.419G′ - 0.081B′) + 128
\end{array}
\end{equation}

0.299*(−0.169) + 0.587*(−0.331) + 0.114*0.500 = -.187828

(-0.169)*0.500 + (-0.331)*(-0.419) + 0.500*(-0.081) = .013689
\end{comment}

Then, why we don't use an orthogonal transform? Why virtually all the
\href{https://en.wikipedia.org/wiki/Video_coding_format}{proposed
  video compression standards} use this transform (or a similar
alternative, but never orthogonal)? The reason (that will be studied
in a future milestone) is that the
\href{https://en.wikipedia.org/wiki/Visual_system}{HVS (Human Visual
  System)} is more sensitive to the Y component (luminance) than to
the CbCr components (crominance), and for this reason, the
\emph{croma} can be more severely degraded than the \emph{luma}
without perceiving this fact, achiving thus higher compression ratios.

Anyway, as you can see in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
the use of the YCbCr color domain can be beneficial, even using a
simple quantization strategy defined by
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cb}} = \Delta_{\text{Cr}}.
\end{equation}
As it can be seen, the RD curves can be improved for most bit-rates,
and therefore, it can be an interesting tool for removing the
intercomponent redundancy from a pure mathematical point of view.

\section{What you have to do?}

\begin{enumerate}
\item Please, run the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  to learn some insights about the problem of the optimal quantization
  (given a bit-rate, find the quantization pattern that minimizes the
  distortion). Can you imagine a strategy to find
  $\Delta^*_{\text{Y}}$, $\Delta^*_{\text{Cb}}$, and
  $\Delta^*_{\text{Cr}}$? Hint: Although this is not compulsory, it
  makes sense to suppose that
  $\Delta_{\text{Cb}} = \Delta_{\text{Cr}}$ because the HVS has the
  same sensitivity to both croma components.
\item What about using an orthogonal transform? Can you define it
  (find the analysis and the synthesis transform)?
\end{enumerate}
\section{Timming}

Please, finish this notebook before the next class session.

\section{Deliverables}

None.

\section{Resources}

\bibliography{data-compression,signal-processing,DWT}
