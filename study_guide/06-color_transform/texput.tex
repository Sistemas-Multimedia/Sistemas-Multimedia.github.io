\input{../definitions}
\title{\SM{} - Study Guide - Milestone 6: Removing Redundancy with a Color Transform}

\maketitle

\section{Description}

\subsection{Introduction}
As we saw in the previous milestone, the RGB domain is highly
correlated. For this reason, in this milestone we will try to remove
the intercomponent
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundancy} that
most of natural images exhibit. As a result, we will concentrate the
energy of the signal in a small number of samples.

In general, redundancy in signals is usually expressed as a
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
dependency between samples. In the case of an image (and of course, of
a video), a pixel is represented usually through three color components
(or \href{https://en.wikipedia.org/wiki/Color_image}{channels}), each
one measuring the energy in a different band of the
\href{https://en.wikipedia.org/wiki/Visible_spectrum}{visible
  spectrum}, and one source of redundancy is the possible correlation
between those color components.

To estimate the
\href{https://en.wikipedia.org/wiki/Redundancy_(information_theory)}{redundancy}
we will use basically two options:
\begin{enumerate}
\item To compute the
  \href{https://en.wikipedia.org/wiki/Entropy_(information_theory)}{0-order
    (memoryless sources) entropy} of the signal: the higher the
  entropy, the lower the redudancy. In fact, if we suppose that the
  samples of the signal are uncorrelated, the 0-order entropy is an
  exact mesarure of the expected bit-rate achieved by an
  \href{https://en.wikipedia.org/wiki/Arithmetic_coding}{arithmetic
    encoder}.  Unfortunately, the 0-order entropy is usually a lower
  bound for the estimation of the redundancy.
\item A better way is to use an
  \href{https://en.wikipedia.org/wiki/Data_compression}{lossless
    compressor}: the higher the length of the compressed file compared
  to the length of the original file, the lower the
  redundancy.\footnote{If the length of the compressed file is equal or
  larger than the lengh of the original file, then, for the compressor
  that we are using, there is not redundancy in the original
  representation.} Notice, however, that although this estimation is
  more accurate than the entropy, in general, it depends on the
  encoding algorithm (different algoritms can provide different
  estimations).
\end{enumerate}

In this milestone we are going to remove the intercomponent redundancy
of a video frame $X$, i.e., the redundancy that may exist between the
color components of each pixel of $X$. The
\href{https://en.wikipedia.org/wiki/Color_space}{color spaces} that we
will compare are: (1)
\href{https://en.wikipedia.org/wiki/RGB_color_model}{RGB}, (2) the
\href{https://en.wikipedia.org/wiki/YCbCr}{YCrCb}, and (3) the
\href{https://en.wikipedia.org/wiki/YCoCg}{YCoCg}.

\subsection{Some words about transform coding}
Quantization is more effective (the compression ratios are higher)
when the energy of the signal is accumulated in an small number of
samples because we can dedicate the bit-rate to encode the more
energetic samples.\footnote{For example, is the energy of a channel is
  small, quantization could completely remove such energy and the
  reconstruction of the image would be reasonable. The most part of
  entropy codecs (and of course, DEFLATE) works much better if we
  found sequences of zeros. Therefore, quantizing will improve the
  compression ratios.}
\href{https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf}{Transform
  coding} can exploit
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
in \href{https://en.wikipedia.org/wiki/Signal}{signals} to concentrate
the
\href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}.
All linear\footnote{Non-linear transform are also possible, but their
  mathematical operation can not be described using linear algebra.}
transforms can be described by
\href{https://en.wikipedia.org/wiki/Matrix_multiplication}{matrix-vector
  product}~\cite{strang4linear} as
\begin{equation}
  y = Kx,
  \label{eq:forward_transform_matrix_form}
\end{equation}
where $x$ is the input signal, $K$ is the analysis transform matrix,
and $y$ is the output decomposition. Notice that
\begin{equation}
  y_i = \langle K_i, x_i\rangle,
\end{equation}
where $K_i$ is the $i$-th row of $K$, and $\langle\cdot,\cdot\rangle$
denotes the
\href{https://mathworld.wolfram.com/InnerProduct.html}{inner
  product}. This basically means that $y_i$ is proportional to the
\href{https://en.wikipedia.org/wiki/Similarity_(geometry)}{similarity}
between the input signal $x$ and the
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{taps} of
the \href{https://en.wikipedia.org/wiki/Digital_filter}{filter}
$K_i$. These
\href{https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf}{slides}
can help you with this key idea. The inverse (synthesis) transform is
computed by
\begin{equation}
  x = K^{-1}y,
  \label{eq:backward_transform_matrix_form}
\end{equation}
where $K^{-1}$ denotes to the inverse matrix of $K$. For example, the
2x2-\href{https://en.wikipedia.org/wiki/Karhunen-Loeve_theorem}{KLT}~\cite{sayood2017introduction}
is defined by
\begin{equation}
  \begin{bmatrix}
    y_0 \\
    y_1
  \end{bmatrix}
  = 
  \begin{bmatrix} \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{-1}{\sqrt{2}} \end{bmatrix}
  \begin{bmatrix}
    x_0 \\
    x_1
  \end{bmatrix},
  \label{eq:KLT_transform}
\end{equation}
and it holds that
\begin{equation}
  K=K^{-1}=K^{\text T},
  \label{eq:orthogonal_matrix}
\end{equation}
where $K^{\text T}$ represents the transpose matrix of $K$. The
Eq.~\ref{eq:orthogonal_matrix} is true for all
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}
transforms, and therefore
\begin{equation}
  \langle K_i, K_j\rangle = 0, \forall i\neq j.
\end{equation}

\subsection{The \href{https://en.wikipedia.org/wiki/YCbCr}{RGB/YCrCb transform}}
\subsubsection{Analysis and synthesis}
To convert a (color) pixel from the RGB into the YCrCb domain, we use
the RGB/YCrCb (analysis) transform~\cite{malvar2008lifting}
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{Cr} \\
    \text{Cb}
  \end{bmatrix}
  =
  \begin{bmatrix}
    0.299   &   0.587 & 0.114 \\ 
    0.5     & -0.4187 & -0.0813 \\
    -0.1687 & -0.3313 & 0.5
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix},
  \label{eq:YCrCb}
\end{equation}
where Y is the luminance (or \emph{luma}) component and CrCb is the
crominance (or \emph{chroma}). The main reason for such a mapping is
that the \href{https://en.wikipedia.org/wiki/Visual_system}{HVS (Human
  Visual System)} is much less sensitive to high-frequency information
in chroma. Thus, compression systems such as
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG} can
\href{https://en.wikipedia.org/wiki/Downsampling_(signal_processing)}{downsample}
the chroma components (usually by 2:1 in each of the horizontal and
vertical directions), as well as increase their quantization step
sizes with respect to luma, to achieve further
\href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression}~\cite{malvar2008lifting}.

Eq.~\ref{eq:YCrCb}
\href{https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html}{can
  be also written as}
\begin{equation}
  \begin{array}{lcl}
    \text{Y}  & = & 0.299\text{R} + 0.587\text{G} + 0.114\text{B} \\
    \text{Cr} & = & 0.713(\text{R} - \text{Y}) + \delta \\
    \text{Cb} & = & 0.564(\text{B} - \text{Y}) + \delta,
  \end{array}
  \label{eq:analysis}
\end{equation}
where,
\begin{equation}
  \delta = \left\{
  \begin{array}{ll}
    128 & \text{for 8 bits (unsigned) images},\\
    32768 & \text{for 16 bits (unsigned) images},\\
    0.5 & \text{for floating point (}[0,1]\text{) images}.
  \end{array}
  \right.
  \label{eq:iYCrCb}
\end{equation}
is used to avoid negative components\footnote{In most transforms
  schemes, the output elements of the analysis transform are commonly
  called coefficients. However, in the context of the color transform,
  the most used term is component.}. As it can be seen, Cr and Cb are
scaled versions of $\text{R} - \text{Y}$ and $\text{B} - \text{Y}$, so
Cr and Cb can be interpreted as measures of how much red and blue
content in a pixel differs from luma, respectively. Notice also that
for a gray pixel, $\text{R}=\text{G}=\text{B}=\text{Y}$, and so
$\text{Cr}=\text{Cb}=0$~\cite{malvar2008lifting}.

The inverse (synthesis) transform is defined by
\begin{equation}
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1.402  & 0 \\ 
    1  &  -0.714  &  -0.344 \\ 
    1  & 0  & 1.772
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{Cr} \\
    \text{Cb}
  \end{bmatrix},
\end{equation}
or alternatively, by
\begin{equation}
  \begin{array}{lcl}
    \text{R} & = & \text{Y} + 1.403(\text{Cr} - \delta) \\
    \text{G} & = & \text{Y} - 0.714(\text{Cr} - \delta) - 0.344(\text{Cb} - \delta)\\
    \text{B} & = & \text{Y} + 1.773(\text{Cb} - \delta).
  \end{array}
  \label{eq:synthesis}
\end{equation}

\subsubsection{Quantization}
After analyzing the frame (representing it in the YCrCb domain), the
next natural step is quantization. Unfortunately, the RGB/YCrCb
transform is orthogonal is not orthogonal\footnote{The RGB/YCrCb is
  not orthogonal because, for example, as we can see in the
  Eq.~\ref{eq:YCrCb_analysis}, the value of Cr depends on the value of
  Y, and therefore, there is a dependency between both
  \href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis}.}
and therefore the contribution of each channel to the quality of the
reconstructed image $\tilde{X}$ are not additive (this can be seen in
this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}). For
that reason, and only for the sake of simplicity, we will use
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}

\begin{comment}
Lets suppose that we use a static
uniform dead-zone quantizer with QSs $\Delta_{\text{Y}}$,
$\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$, for the components Y,
Cr, and Cb, repectively. Lets suppose also that the RGB/YCrCb
transform is orthogonal\footnote{The RGB/YCrCb
  is not orthogonal because, for example, as we can see in the
  Eq.~\ref{eq:YCrCb_analysis}, the value of Cr depends on the value of
  Y, and therefore, there is a dependency between both
  \href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis}.},
that is, the filters of the analysis transform are orthogonal (that is
the same that the columns of the synthesis transform are orthogonal),
in order to assume that
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}
is a good quantization pattern. However, 

--------------

and under the
assumption of that the RGB/YCbCr is an
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}
transform and that each channel is compressed independently, the
optimal quantization of the channels should use $\Delta_{\text{Y}}$,
$\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$ so that
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cr}} = \lambda_{\text{Cb}},
  \label{eq:optimal_quantization}
\end{equation}
for a given total bit-rate $R$ (see this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook})~\cite{vetterli1995wavelets,sayood2017introduction}. Therefore,
if all the channels have the same gain\footnote{The gain of a
transform can be determined computing the squared norm of the columns
of the analysis transform.}, a quantization strategy that should
approximate Eq.~\ref{eq:optimal_quantization} is to use
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}
When the gains are not the same, the quantization steps should be
divided\footnote{The squared norms measure the contribution of each
component to the energy of the pixel, and therefore, the higher the
contribution, the lower the $\Delta$.} by the channel gains, that for
the RGB/YCrCb transform are:
\begin{equation*}
  \begin{array}{rl}
    \text{Y}: & 1^2 + 1^2 + 1^2 = 3\\
    \text{Cr}: & 1.402^2 + 0.714^2 = 2.4754\\
    \text{Cb}: & 0.344^2 + 1.772^2 = 3.25832
  \end{array}
\end{equation*}

% Si un coeficiente tiene una gran ganancia es implica que su
% quantization también se dejará sentir más que si la ganancia es
% menor. Por tanto, tiene sentido usar un QS mayor en aquellos
% coeficientes de menor ganancia.

Unfortunately, the RGB/YCrCb transform is not orthogonal. This
means that the quantization noise introduced in one of the channel
will also affect to the rest of channels, which will degrade the RD
performance. The lack of orthogonality also reduces the effectivity of
the previous algorithm for determining the optimal quantization steps.

\end{comment}

\begin{comment}

After analyzing the frame (representing it in the YCrCb domain), the
next natural step is quantization. Supposing that we will use a static
uniform dead-zone quantizer with quantization steps
$\Delta_{\text{Y}}$, $\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$,
for the coefficients Y, Cr, and Cb, repectively, and supposing that
the contribution to the reconstruction of $X$ of one of the
coefficients is not influenced by the contribution of the rest of
coefficients (for this, both color spaces (RGB and YCrCb) should be
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}), the
optimal quantization steps $\Delta^*_{\text{Y}}$,
$\Delta^*_{\text{Cr}}$, and $\Delta^*_{\text{Cb}}$, can be found using
a constant slope
(\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{RD}-$\lambda$)
quantization
strategy~\cite{vetterli1995wavelets,sayood2017introduction}.

As it can be seen in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
a RD (Rate-Distortion) curve is a 2D graph where we represent the
distortion generated by the quantization as a function of the bit-rate
of the quantization indexes. Thus, the closer the curve to the point
(0,0) of the graph, the better the performance of the encoding system
in RD terms. Now, if we suppose that each component (Y, Cr, and Cb) is
quantized and compressed independently, we can find the optimal
quantization steps, given a maximum target bit-rate $R^{\text{max}}$,
selecting them as
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cr}} = \lambda_{\text{Cb}},
\end{equation}
where $\lambda(R)$ is the slope of the RD curve for a given bit-rate
$R$, satisfiying also that
\begin{equation}
  R_{\text{Y}} + R_{\text{Cr}} + R_{\text{Cb}} \le R^{\text{max}}.
\end{equation}

Unfortunately, the RGB-to-YCrCb transform is not orthogonal (for
example, in Eq.~\ref{eq:YCrCb_analysis}, the value of Cr depends on the
value of Y, and therefore, there is a dependency between both
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis})\footnote{This
can be also seen computing the
\href{https://en.wikipedia.org/wiki/Dot_product}{inner product} of the
basis functions of the analysis transform (only the inner product of
orthogonal vectors is 0). Thus, for example, the product of the basis
functions for Y and Cr is $0.299\times 0.5+0.587\times (-0.4187) +
0.144\times (-0.0813) = -0.1055451$.} and therefore neither the RGB
and the YCrCb spaces. This dificults the finding of
$\Delta^*_{\text{Y}}$, $\Delta^*_{\text{Cr}}$, and
$\Delta^*_{\text{Cb}}$ because the quantization error generated in one
of the components influences the quantization error of the rest of
components, and when this happens, we cannot use CS-RS-QS.

Anyway, as you can see in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
the use of the YCrCb color domain can be beneficial, even using a
simple quantization strategy such as
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
\end{equation}
As it can be seen, the RD curves can be improved for most bit-rates,
and therefore, it can be an interesting tool for removing the
intercomponent redundancy from a pure mathematical point of view.
\end{comment}

\subsection{The \href{https://en.wikipedia.org/wiki/YCoCg}{RGB/YCoCg transform}}
\subsubsection{Analysis and synthesis}
Clearly, orthogonality is a desired property in compression
systems. On the other hand, Eqs.~\ref{eq:YCrCb} and \ref{eq:iYCrCb}
were derived by
\href{https://en.wikipedia.org/wiki/Principal_component_analysis}{Principal
  Component Analysis (PCA)} on old\footnote{Recorded with the first
analog color cameras in the 70's.} video data. The same procedure has
been carried out with newer\footnote{\cite{malvar2008lifting} is dated
in 2008.} images, obtaining
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{C}_1 \\
    \text{C}_2
  \end{bmatrix}
  =
  \begin{bmatrix}
    \frac{1}{3} & \frac{1}{3} &  \frac{1}{3} \\ 
    \frac{1}{2} &           0 & -\frac{1}{2} \\
   -\frac{1}{4} & \frac{1}{2} & -\frac{1}{4}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  \Leftrightarrow
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1  & -\frac{2}{3} \\ 
    1  &  0  &  \frac{4}{3} \\ 
    1  & -1  & -\frac{2}{3}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{C}_1 \\
    \text{C}_2
  \end{bmatrix}.
  \label{eq:optimal}
\end{equation}

This transform is orthogonal. However, as \cite{malvar2008lifting}
points it has to disadvantages:
\begin{enumerate}
\item The gains of the channels are different (2, 3 and 8/3).
\item From a perceptual perspective, the influence of the green
  channel on the luma channel should be stronger.
\end{enumerate}
For these reasons, \cite{malvar2008lifting} proposes
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{Co} \\
    \text{Cg}
  \end{bmatrix}
  =
  \begin{bmatrix}
    \frac{1}{4} &  \frac{1}{2}  &  \frac{1}{4} \\ 
    \frac{1}{2} &            0  & -\frac{1}{2} \\
    -\frac{1}{4} &  \frac{1}{2}  & -\frac{1}{4}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  \Leftrightarrow
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1  & -1 \\ 
    1  &  0  &  1 \\ 
    1  & -1  & -1
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{Co} \\
    \text{Cg}
  \end{bmatrix},
\end{equation}
that is near orthogonal\footnote{For example,
  $\frac{1}{4}\frac{-1}{4} + \frac{1}{2}\frac{1}{2} +
  \frac{1}{4}\frac{-1}{4} = \frac{1}{8}$}.

\subsubsection{Quantization}
As happens with the RGB/YCrCb transform, the RGB/YCoCg transform is
not orthogonal (see this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}). Therefore,
again (for simplicity) we will take
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Co}} = \Delta_{\text{Cg}}.
\end{equation}
However, as it can be seen in the notebook, the RGB/YCoCg transform concentrates more the energy than the RGB/YCrCb transform.

and the
channels gains are the same. Therefore, the Eq.~\ref{eq:simple_Q}
stands Eq.~\ref{eq:optimal_quantization}.  As it can be also seen in
this \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}w,
the YCoCg domain can significantly concentrate the energy of the
pixels in the Y channel. This is beneficial because quantization will
remove (completely quantize) ``noise'' in the chroma channels.

\section{What you have to do?}

\begin{enumerate}
\item Please, run the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  to learn some insights about the problem of the optimal
  quantization in the color domain.
\item Include in the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  an implementation of the
  \href{https://en.wikipedia.org/wiki/JPEG_2000#Color_components_transformation}{RCT
    (Reversible Color Transform)} and compare it's RD performance with
  the other transforms.
\item Implement the transform described in Eq.~\ref{eq:optimal}, and
  compare it with the other transforms.
\end{enumerate}

\section{Timming}

Please, finish this notebook before the next class session.

\section{Deliverables}

None.

\section{Resources}

\bibliography{maths,data-compression,signal-processing,DWT,image-compression}
