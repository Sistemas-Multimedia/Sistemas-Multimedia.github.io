\input{../definitions}
\title{\SM{} - Study Guide - Milestone 6: Removing Redundancy with a Color Transform}

\maketitle

\section{Description}

\subsection{Introduction}
The main objective of this milestone is to remove the intercomponent
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundancy} that
most of natural images exhibit, and to concentrate the energy of the
signal. 

In general, redundancy in signals is
usually expressed as a
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
dependency between samples. In the case of an image (and of course, of
a video), a pixel (a sample) is represented usually with three color
components (or
\href{https://en.wikipedia.org/wiki/Color_image}{channels}), each one
measuring the energy in a different band of the
\href{https://en.wikipedia.org/wiki/Visible_spectrum}{visible
  spectrum}, and one source of redundancy is the possible correlation
between those color components.

To estimate the
\href{https://en.wikipedia.org/wiki/Redundancy_(information_theory)}{redundancy}
there are basically two options:
\begin{enumerate}
\item To compute the
  \href{https://en.wikipedia.org/wiki/Entropy_(information_theory)}{0-order
    (memoryless sources) entropy} of the signal: the higher the
  entropy, the lower the redudancy. In fact, if we suppose that the
  samples of the signal are uncorrelated, the 0-order entropy is an
  exact mesarure of the expected bit-rate achieved by an
  \href{https://en.wikipedia.org/wiki/Arithmetic_coding}{arithmetic
    encoder}.  Unfortunately, the 0-order entropy is usally a lower
  bound for the estimation of the redundancy.
\item A better way is to use an
  \href{https://en.wikipedia.org/wiki/Data_compression}{lossless
    compressor}: the higher the length of the compressed file compared
  to the length of the original file, the lower the
  redundancy.\footnote{If the length of the compressed file equal or
  larger than the lengh of the original file, then, for the compressor
  that we are using, there is not redundancy in the original
  representation.} Notice, however, that although this estimation is
  more accurate than the entropy, in general, it depends on the
  encoding algorithm (different algoritms can provide different
  estimations).
\end{enumerate}

In this milestone we are going to remove the intercomponent redundancy
of a video frame $X$, i.e., the redundancy that may exist between the
color components of each pixel of $X$. The
\href{https://en.wikipedia.org/wiki/Color_space}{color spaces} that we
are goint to compare are: (1)
\href{https://en.wikipedia.org/wiki/RGB_color_model}{RGB}, (2) the
\href{https://en.wikipedia.org/wiki/YCbCr}{YCrCb}, and (3) the
\href{https://en.wikipedia.org/wiki/YCoCg}{YCoCg}.

\subsection{The \href{https://en.wikipedia.org/wiki/YCbCr}{RGB/YCrCb transform}}
\subsubsection{Analysis and synthesis}
To convert a (color) pixel from the RGB into the YCrCb domain, we use
the RGB/YCrCb (analysis) transform~\cite{malvar2008lifting}
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{Cr} \\
    \text{Cb}
  \end{bmatrix}
  =
  \begin{bmatrix}
    0.299   &   0.587 & 0.114 \\ 
    0.5     & -0.4187 & -0.0813 \\
    -0.1687 & -0.3313 & 0.5
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix},
  \label{eq:YCrCb}
\end{equation}
where Y is the luminance (\emph{luma}) component and CrCb is the
crominance (\emph{chroma}). The main reason for such a mapping is that
the \href{https://en.wikipedia.org/wiki/Visual_system}{HVS (Human
  Visual System)} is much less sensitive to high-frequency components
in chroma. Thus, compression systems such as
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG} can
\href{https://en.wikipedia.org/wiki/Downsampling_(signal_processing)}{downsample}
the chroma components (usually by 2:1 in each of the horizontal and
vertical directions), as well as increase their quantization step
sizes with respect to luma, to achieve further
\href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression}.

Eq.~\ref{eq:YCrCb}
\href{https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html}{can
  be also written as}
\begin{equation}
  \begin{array}{lcl}
    \text{Y}  & = & 0.299\text{R} + 0.587\text{G} + 0.114\text{B} \\
    \text{Cr} & = & 0.713(\text{R} - \text{Y}) + \delta \\
    \text{Cb} & = & 0.564(\text{B} - \text{Y}) + \delta,
  \end{array}
  \label{eq:analysis}
\end{equation}
where,
\begin{equation}
  \delta = \left\{
  \begin{array}{ll}
    128 & \text{for 8 bits (unsigned) images},\\
    32768 & \text{for 16 bits (unsigned) images},\\
    0.5 & \text{for floating point (}[0,1]\text{) images}.
  \end{array}
  \right.
  \label{eq:iYCrCb}
\end{equation}
is used to avoid negative components\footnote{In most transforms
schemes, the output elements of the analysis transform are commonly
called coefficients. However, in the context of the color transform,
the most used term is component.}. As it can be seen, Cr and Cb are
scaled versions of $\text{R} - \text{Y}$ and $\text{B} - \text{Y}$, so
Cr and Cb can be interpreted as measures of how much red and blue
content in a pixel differs from luma, respectively. Notice also that
for a gray pixel, $\text{R}=\text{G}=\text{B}=\text{Y}$, and so
$\text{Cr}=\text{Cb}=0$~\cite{malvar2008lifting}.

The inverse (synthesis) transform is defined by
\begin{equation}
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1.402  & 0 \\ 
    1  &  -0.714  &  -0.344 \\ 
    1  & 0  & 1.772
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{Cr} \\
    \text{Cb}
  \end{bmatrix},
\end{equation}
or alternatively, by
\begin{equation}
  \begin{array}{lcl}
    \text{R} & = & \text{Y} + 1.403(\text{Cr} - \delta) \\
    \text{G} & = & \text{Y} - 0.714(\text{Cr} - \delta) - 0.344(\text{Cb} - \delta)\\
    \text{B} & = & \text{Y} + 1.773(\text{Cb} - \delta).
  \end{array}
  \label{eq:synthesis}
\end{equation}

\subsubsection{Quantization}
After analyzing the frame (representing it in the YCrCb domain), the
next natural step is quantization. Supposing that we will use a static
uniform dead-zone quantizer with quantization steps
$\Delta_{\text{Y}}$, $\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$,
for the coefficients Y, Cr, and Cb, repectively, and under the
assumption of that the RGB/YCbCr is an
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}
transform and that each channel is compressed independently, the
optimal quantization of the channels should use $\Delta_{\text{Y}}$,
$\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$ so that
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cr}} = \lambda_{\text{Cb}},
  \label{eq:optimal_quantization}
\end{equation}
where $\lambda_{\text{channel}}(R)$ is the slope, for a given bit-rate
$R$,
(\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{Rate-Distortion})
of the curve for the corresponding channel in the RD plane (see this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook})~\cite{vetterli1995wavelets,sayood2017introduction}.

Unfortunately, the use of Eq.~\ref{eq:optimal_quantization} implies
the computation of the RD curve for each channel, which is a
time-consuming operation. For this reason, and supposing that the
statistics of each channel are similar, we can suppose that the length
(the bit-rate) of each channel is proportional to the variance of the
channel, which is proportional to the quantization step. Therefore, if
all the channels have the same gain\footnote{The gain of a transform
can be determined computing the squared norm of the columns of the
analysis transform.}, a quantization strategy that should approximate
Eq.~\ref{eq:optimal_quantization} is to use
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}
When the gains are not the same, the quantization steps should be
divided\footnote{The squared norms measure the contribution of each
component to the energy of the pixel, and therefore, the higher the
contribution, the lower the $\Delta$.} by the gains, that for the
RGB/YCrCb transform are:
\begin{equation*}
  \begin{array}{rl}
    \text{Y}: & 1^2 + 1^2 + 1^2 = 3\\
    \text{Cr}: & 1.402^2 + 0.714^2 = 2.4754\\
    \text{Cb}: & 0.344^2 + 1.772^2 = 3.25832
  \end{array}
\end{equation*}

Unfortunately, the RGB/YCrCb transform is not orthogonal. This
means that the quantization noise introduced in one of the channel
will also affect to the rest of channels, which will degrade the RD
performance. The lack of orthogonality also reduces the effectivity of
the previous algorithm for determining the optimal quantization steps.

\begin{comment}

After analyzing the frame (representing it in the YCrCb domain), the
next natural step is quantization. Supposing that we will use a static
uniform dead-zone quantizer with quantization steps
$\Delta_{\text{Y}}$, $\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$,
for the coefficients Y, Cr, and Cb, repectively, and supposing that
the contribution to the reconstruction of $X$ of one of the
coefficients is not influenced by the contribution of the rest of
coefficients (for this, both color spaces (RGB and YCrCb) should be
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}), the
optimal quantization steps $\Delta^*_{\text{Y}}$,
$\Delta^*_{\text{Cr}}$, and $\Delta^*_{\text{Cb}}$, can be found using
a constant slope
(\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{RD}-$\lambda$)
quantization
strategy~\cite{vetterli1995wavelets,sayood2017introduction}.

As it can be seen in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
a RD (Rate-Distortion) curve is a 2D graph where we represent the
distortion generated by the quantization as a function of the bit-rate
of the quantization indexes. Thus, the closer the curve to the point
(0,0) of the graph, the better the performance of the encoding system
in RD terms. Now, if we suppose that each component (Y, Cr, and Cb) is
quantized and compressed independently, we can find the optimal
quantization steps, given a maximum target bit-rate $R^{\text{max}}$,
selecting them as
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cr}} = \lambda_{\text{Cb}},
\end{equation}
where $\lambda(R)$ is the slope of the RD curve for a given bit-rate
$R$, satisfiying also that
\begin{equation}
  R_{\text{Y}} + R_{\text{Cr}} + R_{\text{Cb}} \le R^{\text{max}}.
\end{equation}

Unfortunately, the RGB-to-YCrCb transform is not orthogonal (for
example, in Eq.~\ref{eq:analysis}, the value of Cr depends on the
value of Y, and therefore, there is a dependency between both
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis})\footnote{This
can be also seen computing the
\href{https://en.wikipedia.org/wiki/Dot_product}{inner product} of the
basis functions of the analysis transform (only the inner product of
orthogonal vectors is 0). Thus, for example, the product of the basis
functions for Y and Cr is $0.299\times 0.5+0.587\times (-0.4187) +
0.144\times (-0.0813) = -0.1055451$.} and therefore neither the RGB
and the YCrCb spaces. This dificults the finding of
$\Delta^*_{\text{Y}}$, $\Delta^*_{\text{Cr}}$, and
$\Delta^*_{\text{Cb}}$ because the quantization error generated in one
of the components influences the quantization error of the rest of
components, and when this happens, we cannot use CS-RS-QS.

Anyway, as you can see in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
the use of the YCrCb color domain can be beneficial, even using a
simple quantization strategy such as
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
\end{equation}
As it can be seen, the RD curves can be improved for most bit-rates,
and therefore, it can be an interesting tool for removing the
intercomponent redundancy from a pure mathematical point of view.
\end{comment}

\subsection{The \href{https://en.wikipedia.org/wiki/YCoCg}{RGB/YCoCg transform}}
\subsubsection{Analysis and synthesis}
Clearly, orthogonality is a desired property in compression
systems. On the other hand, Eqs.~\ref{eq:YCrCb} and \ref{eq:iYCrCb}
were derived by
\href{https://en.wikipedia.org/wiki/Principal_component_analysis}{Principal
  Component Analysis (PCA)} on old\footnote{Recorded with the first
analog color cameras in the 70's.} video data. The same procedure has
been carried out with newer\footnote{\cite{malvar2008lifting} is dated
in 2008.} images, obtaining
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{C}_1 \\
    \text{C}_2
  \end{bmatrix}
  =
  \begin{bmatrix}
    \frac{1}{3} & \frac{1}{3} &  \frac{1}{3} \\ 
    \frac{1}{2} &           0 & -\frac{1}{2} \\
   -\frac{1}{4} & \frac{1}{2} & -\frac{1}{4}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  \Leftrightarrow
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1  & -\frac{2}{3} \\ 
    1  &  0  &  \frac{4}{3} \\ 
    1  & -1  & -\frac{2}{3}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{C}_1 \\
    \text{C}_2
  \end{bmatrix}.
\end{equation}

This transform is orthogonal. However, as \cite{malvar2008lifting}
points it has to disadvantages:
\begin{enumerate}
\item The gains of the channels are different (2, 3 and 8/3).
\item From a perceptual perspective, the influence of the green
  channel on the luma channel should be stronger.
\end{enumerate}
For these reasons, \cite{malvar2008lifting} proposes
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{Co} \\
    \text{Cg}
  \end{bmatrix}
  =
  \begin{bmatrix}
    \frac{1}{4} &  \frac{1}{2}  &  \frac{1}{4} \\ 
    \frac{1}{2} &            0  & -\frac{1}{2} \\
    -\frac{1}{4} &  \frac{1}{2}  & -\frac{1}{4}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  \Leftrightarrow
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1  & -1 \\ 
    1  &  0  &  1 \\ 
    1  & -1  & -1
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{Co} \\
    \text{Cg}
  \end{bmatrix}.
\end{equation}

\subsubsection{Quantization}
As it can be seen, the RGB/YCoCg transform is orthogonal and the
channels gains are the same. Therefore, the Eq.~\ref{eq:simple_Q}
stands Eq.~\ref{eq:optimal_quantization}.  As it can be also seen in
this \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
the YCoCg domain can significantly concentrate the energy of the
pixels in the Y channel. This is beneficial because quantization will
remove (completely quantize) ``noise'' in the chroma channels.

\section{What you have to do?}

\begin{enumerate}
\item Please, run the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  to learn some insights about the problem of the optimal
  quantization.
\item Include in the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  an implementation of the
  \href{https://en.wikipedia.org/wiki/JPEG_2000#Color_components_transformation}{RCT
    (Reversible Color Transform)} and compare it's RD performance with
  the other transforms.
\end{enumerate}

\section{Timming}

Please, finish this notebook before the next class session.

\section{Deliverables}

None.

\section{Resources}

\bibliography{data-compression,signal-processing,DWT,image-compression}
