{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/gray_SQ/gray_SQ_LloydMax.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/gray_SQ/gray_SQ_LloydMax.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lloyd-Max Quantization\n",
    "\n",
    "Use K-means to find the centroid of each bin. See [scikit-learn's Vector Quantization Example](https://scikit-learn.org/stable/auto_examples/cluster/plot_face_compress.html#sphx-glr-auto-examples-cluster-plot-face-compress-py).\n",
    "\n",
    "Notice that the centroids must be transmitted to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pygments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/scalar_quantization\" ]; then\n",
    "    cd $HOME/repos/scalar_quantization\n",
    "    echo \"$HOME/repos/scalar_quantization ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/scalar_quantization.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/MRVC\" ]; then\n",
    "    cd $HOME/repos/MRVC\n",
    "    echo \"$HOME/repos/MRVC ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/Sistemas-Multimedia/MRVC.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_IO\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/image_IO ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_IO.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/information_theory\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/information_theory ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/information_theory.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -sf ~/MRVC/src/logging_config.py .\n",
    "!ln -sf ~/repos/scalar_quantization/quantization.py .\n",
    "!ln -sf ~/repos/scalar_quantization/deadzone_quantization.py .\n",
    "!ln -sf ~/repos/scalar_quantization/LloydMax_quantization.py .\n",
    "!ln -sf ~/repos/information_theory/distortion.py .\n",
    "!ln -sf ~/repos/information_theory/information.py .\n",
    "!ln -sf ~/repos/image_IO/image_1.py .\n",
    "!ln -sf ~/repos/image_IO/logging_config.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    #plt.rcParams['text.usetex'] = True\n",
    "    #plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "except:\n",
    "    !pip install scipy\n",
    "    \n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip install opencv-python\n",
    "    !pip install opencv-python-headless # Binder compatibility\n",
    "    import cv2\n",
    "\n",
    "try:\n",
    "    import skimage\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    import skimage\n",
    "    \n",
    "try:\n",
    "    from sklearn import cluster\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn import cluster\n",
    "\n",
    "try:\n",
    "    import colored\n",
    "except:\n",
    "    !pip install colored\n",
    "    import colored\n",
    "\n",
    "#try:\n",
    "#    import warnings\n",
    "#except:\n",
    "#    !pip install warnings\n",
    "#    import warnings\n",
    "\n",
    "import pylab\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import os\n",
    "import deadzone_quantization as deadzone\n",
    "import LloydMax_quantization as quantization\n",
    "import distortion\n",
    "#import image_3 as RGB_image\n",
    "import image_1 as gray_image\n",
    "import colored\n",
    "import information\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ[\"HOME\"]\n",
    "fn = home + \"/repos/MRVC/images/lena_bw/\"\n",
    "#fn = home + \"/repos/MRVC/images/Hommer_bw/\"\n",
    "!ls -l {fn}\n",
    "\n",
    "# Quantizer selection\n",
    "quantizer = quantization.LloydMax_Quantizer\n",
    "\n",
    "n_clusters = 4  # Number of bins\n",
    "N_tries = 4  # Number of times K-means is run\n",
    "#N_bins = range(2, 128, 1)\n",
    "N_bins = [2, 4, 8, 16, 32, 64, 128] #range(2, 128, 1)\n",
    "gray_image.write = gray_image.debug_write # faster\n",
    "#gray_image.write = gray_image.write # higher compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gray_image.read(fn, 0)\n",
    "gray_image.show(img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lloyd-Max quantization using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize quantization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize LloydMax_quantization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSS = 4 # Quantization Step Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = quantizer(img, Q_step=QSS, min_val=0, max_val=255)\n",
    "print(\"decision_levels =\", Q.get_decision_levels())\n",
    "print(\"representation_levels =\", Q.get_representation_levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, xlabel='', ylabel='', title=''):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "    ax.xaxis.set_label_text(xlabel)\n",
    "    ax.yaxis.set_label_text(ylabel)\n",
    "    ax.plot(x, y)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 255, 500) # Input samples\n",
    "y, k = Q.quan_dequan(x)\n",
    "plot(x, y, \"Input Sample\", \"Reconstructed Sample\", f\"Lloyd-Max Quantizer ({fn}, $\\Delta={QSS}$)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither, the decision levels nor the representation levels are equally spaced. This is a direct consequence of the PDF of the input image. Thus, those input ranges where the number of gray-tones are more frequent, the resolution of the quantizer is increased. The representation levels are placed where the MSE is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, k = Q.quan_dequan(img)\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes ($\\\\Delta={QSS}$)\")\n",
    "gray_image.show(y, f\"Dequantized Image ($\\\\Delta={QSS}$)\")\n",
    "print(\"MSE =\", distortion.MSE(img, y))\n",
    "print(\"SSIM =\", distortion.SSIM(img, y))\n",
    "print(\"entropy =\", information.entropy(k.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels = np.round(Q.get_representation_levels()).astype(np.uint8)\n",
    "representation_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(np.diff(representation_levels), representation_levels[::-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels = np.round(Q.get_representation_levels()).astype(np.uint8)\n",
    "representation_levels_DPCM = np.append(np.diff(representation_levels), representation_levels[::-1][0]) # We start at the end!\n",
    "print(representation_levels)\n",
    "print(representation_levels_DPCM)\n",
    "#with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "#    np.save(file=f, arr=representation_levels)\n",
    "#np.save(file=\"/tmp/representation_levels.npy.gz\", arr=representation_levels)\n",
    "\n",
    "fileobj = open(\"/tmp/representation_levels.bin\", mode='wb')\n",
    "representation_levels.tofile(fileobj)\n",
    "print(\"Bytes needed for the representation levels:\", os.path.getsize(\"/tmp/representation_levels.bin\"))\n",
    "\n",
    "with gzip.GzipFile(\"/tmp/representation_levels.bin.gz\", \"w\") as f:\n",
    "    representation_levels.tofile(f)\n",
    "print(\"Bytes needed for the representation levels:\", os.path.getsize(\"/tmp/representation_levels.bin.gz\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD curve\n",
    "We compare two versions:\n",
    "1. When the centroids are initialized using an scalar quantizer.\n",
    "2. When the centroids are initialized at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RD_curve_random_init(img, N_bins):\n",
    "    points = []\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    for n in N_bins:\n",
    "        #k_means = cluster.KMeans(n_clusters=n, n_init=N_tries)\n",
    "        k_means = cluster.KMeans(n_clusters=n)\n",
    "        k_means.fit(flatten_img)\n",
    "        centroids = k_means.cluster_centers_.squeeze().astype(np.uint8)  # Centroids\n",
    "        k = k_means.labels_.astype(np.uint8)  # Labels of the centroids\n",
    "        #y = np.choose(k, centroids)\n",
    "        #y = centroids[k[range(len(k))]]\n",
    "        y = centroids[k]\n",
    "        y.shape = img.shape\n",
    "        k.shape = img.shape\n",
    "        print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            centroids.tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=centroids)\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes ($\\\\Delta={QSS}$)\")\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "RD_points_random_init = RD_curve_random_init(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RD_curve_sorted_labels(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            Q.get_representation_levels().tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=Q.get_representation_levels())\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #_distortion = distortion.RMSE(img, y)\n",
    "        _distortion = distortion.RMSE(img, np.round(y).astype(np.uint8))\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes ($\\\\Delta={QSS}$)\")\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RD_points_sorted_labels = RD_curve_sorted_labels(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), c='m', marker='x', label=\"Using sorted labels\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points_random_init), c='b', marker='x', label=\"Using unsorted labels\", linestyle=\"dotted\")\n",
    "pylab.title(f\"Rate/Distortion Performance\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more efficient in terms of rate (and faster, because K-Means runs only one time) to initialize the centroids (notice that this disables the random selection of the initial centroids and therefore, it converts to K-means in a deterministic clustering algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"LloydMax_RD_points.txt\", 'w') as f:\n",
    "    for item in RD_points_sorted_labels:\n",
    "        f.write(f\"{item[0]}\\t{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if we increase the granuality?\n",
    "Let's see the effect of using a finer quantization step (size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = [i for i in range(2, 128, 1)]\n",
    "print(N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _(a, cmap, vmin, vmax):\n",
    "    pass\n",
    "plt.show = print\n",
    "plt.imshow = _\n",
    "RD_points_finer = RD_curve_sorted_labels(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), c='m', marker='x', label=f\"Using powers of 2\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points_finer), c='g', marker='.', label=f\"Using more quantization steps\", linestyle=\"dotted\")\n",
    "pylab.title(fn)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the quantization steps that are powers of 2 describe reasonably well the convex hull of the RD curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDO (Rate Distortion Optimization)\n",
    "\n",
    "So far, the design of the Lloyd-Max quantizer has been independent of the rate (only the distortion has been minimized). However, the final RD performance of the encoding system depends on both opposed features (rate and distortion), generating a tradeoff that can be optimized under certain conditions.\n",
    "\n",
    "For example, let's imagine that the image is quantized by tiles. Thus, in each tile, a \"local\" Lloyd-Max quantizer can be used, potentially decreasing the distortion (the PDF of a tile is more accurate describing the counts of the gray-scale values of the tile, than the PDF of the whole image). Besides, each tile requires at least a slighly different set of representation levels, aspect that will increase the rate (the representation levels must be transmitted in the code-stream). Supposing that all the tiles have the same size, which tiling-configuration (tile size) is the most RD-efficient?\n",
    "\n",
    "The following code determines the optimal tile size (in a linear and supposedly convex search space spawned by the side of the squared tiles, that are powers of two) for different RD points. To determine the RD performance in a point $i$, we will use the Lagrangian:\n",
    "$$\n",
    "\\mathbf{J}_i = \\mathbf{D}_i + \\mathbf{\\lambda}_i \\mathbf{R}_i,\n",
    "$$\n",
    "where $\\mathbf{D}$ stands for distortion and $\\mathbf{R}$ for (bit-)rate. A $\\mathbf{\\lambda}_i$ is known as a Lagrangian Multipler that controls the relative importance between $\\mathbf{D}$ and $\\mathbf{R}$. For example, if $\\mathbf{\\lambda}_i=0$, and we are minimizing $\\mathbf{J}_i$, we are only interested in minimizing the distortion and therefore, we are \"exploring\" the bottom-right segment of the RD curve (considering a RMSE VS bit-rate RD curve), if $\\mathbf{\\lambda}_i=\\infty$ (in the practice, a very large value) we are minimizing the RD tradeoff at the top-left segment of the RD curve (high compression ratio and probably, a higher distortion), and intermediate values of $\\mathbf{\\lambda}$ correspond to other intermediate points of the RD curve.\n",
    "\n",
    "Finally, notice that we have defined $\\mathbf{\\lambda}_i$ as a continuous parameter, but the number of points of the RD curve is finite. Therefore, to determine $\\mathbf{\\lambda}_i$ for the point $i$ of the curve, we can define that:\n",
    "$$\n",
    "\\mathbf{\\lambda}_i = \\frac{\\mathbf{D}_i-\\mathbf{D}_{i+1}}{\\mathbf{R}_{i+1}-\\mathbf{R}_i}\n",
    "$$\n",
    "and that:\n",
    "$$\n",
    "\\mathbf{\\lambda}_{\\mathbf{\\Delta_i}=1}=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = []\n",
    "for i in range(len(RD_points_sorted_labels)-1):\n",
    "    _lambda.append((RD_points_sorted_labels[i][1] - RD_points_sorted_labels[i+1][1])/(RD_points_sorted_labels[i+1][0]-RD_points_sorted_labels[i][0]))\n",
    "_lambda.append(0)\n",
    "print(_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = [2, 4, 8, 16, 32, 64, 128] #range(2, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_sides = [256, 128, 64, 32, 16]\n",
    "# The search space is so small that a sequential search should be fast enough.\n",
    "\n",
    "for n in N_bins:\n",
    "    K = np.empty_like(img)\n",
    "    prev_J = 10^10\n",
    "    for ts in tile_sides:\n",
    "        tiles_in_y = img.shape[0]//ts\n",
    "        tiles_in_x = img.shape[1]//ts\n",
    "        number_of_tiles = tiles_in_y*tiles_in_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tile_side = 64  # Must be a multiple of both dimensions of the image\n",
    "tiles_in_y = img.shape[0]//tile_side\n",
    "tiles_in_x = img.shape[1]//tile_side\n",
    "number_of_tiles = tiles_in_y*tiles_in_x\n",
    "K = np.empty_like(img)\n",
    "Y = np.empty_like(img)\n",
    "def RD_curve(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        rate = 0\n",
    "        _distortion = 0\n",
    "        prev_representation_levels = np.zeros(n, dtype=np.int8)\n",
    "        #print(prev_representation_levels.shape)\n",
    "        for ty in range(tiles_in_y):\n",
    "            for tx in range(tiles_in_x):\n",
    "                tile = img[ty*tile_side:(ty+1)*tile_side, tx*tile_side:(tx+1)*tile_side]\n",
    "                Q = quantizer(tile, Q_step=Q_step, min_val=0, max_val=255)\n",
    "                #Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "                y, k = Q.quan_dequan(tile)\n",
    "                K[ty*tile_side:(ty+1)*tile_side, tx*tile_side:(tx+1)*tile_side] = k\n",
    "                Y[ty*tile_side:(ty+1)*tile_side, tx*tile_side:(tx+1)*tile_side] = y\n",
    "                #representation_levels = Q.get_representation_levels()\n",
    "                #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "                #    diff_representation_levels = representation_levels - prev_representation_levels\n",
    "                #    np.save(file=f, arr=diff_representation_levels)\n",
    "                #    print(representation_levels, prev_representation_levels, diff_representation_levels)\n",
    "                #prev_representation_levels[:] = representation_levels\n",
    "                #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(img.shape[0]*img.shape[1]))\n",
    "                _distortion += distortion.RMSE(tile, y)\n",
    "        rate += gray_image.write(K, \"/tmp/\" + str(n) + '_', 0)*8/(img.shape[0]*img.shape[1])\n",
    "        _distortion /= number_of_tiles\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "        gray_image.show_normalized(K, f\"Quantization Indexes (n={n})\")\n",
    "        gray_image.show(Y, f\"Reconstruction (n={n})\")\n",
    "    return points\n",
    "\n",
    "RDO_points = RD_curve(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), c='m', marker='x', label=f\"No tiling\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RDO_points), c='b', marker='x', label=f\"RDO over tile size\", linestyle=\"dotted\")\n",
    "pylab.title(f\"Rate/Distortion Performance\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is posible to improve the RD curve using stocastic search? The idea is to, given a K-Means solution, perform a (finite) number of training steps of the classifier with the hope of finding a better one (remember that K-Means obtains different solutions when it is run several times). If this happens, the process is repeated. Otherwise, we stop.\n",
    "\n",
    "To determine if the current classifier is better than the previous one, we can use a Lagrangian Multiplier\n",
    "$$\n",
    "J = D+\\lambda R,\n",
    "$$\n",
    "where the tradeoff between rate (R) and distortion (D) is quantified for a given slope $\\lambda$. Thus, the smaller the $J$, the better the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class RDO(quantization.LloydMax_Quantizer):\n",
    "\n",
    "    def __init__(img, Q_step, max_number_of_iters, _lambda):\n",
    "        self.Q = super().__init__(img, Q_step=QS, min_val=0, max_val=255)\n",
    "        self.img = img\n",
    "        self.Q_step = Q_step\n",
    "        self.max_number_of_iters = max_number_of_iters\n",
    "        #self.lambda = _lambda\n",
    "\n",
    "    def RDO_step():\n",
    "        y, k = self.Q.quan_dequan(self.img)\n",
    "        R = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        D = distortion.RMSE(img, y)\n",
    "        current_J = D + _lambda * R\n",
    "        next_Q = self.quantizer(self.img, Q_step=self.Q_step, min_val=0, max_val=255)\n",
    "        y, k = next_Q.quan_dequan(self.img)\n",
    "        R = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        D = distortion.RMSE(img, y)\n",
    "        next_J = D + _lambda * R\n",
    "        if next_J < current_J:\n",
    "            return next_Q\n",
    "        else:\n",
    "            return current_Q\n",
    "\n",
    "    def RDO():\n",
    "        Q = self.quantizer(self.img, Q_step=self.Q_step, min_val=0, max_val=255)\n",
    "        for i in range(max_number_of_iters):\n",
    "            Q = RDO_step(Q)\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def optimize_step(Q, Q_step, _lambda):\n",
    "    print(\"Q.get_representation_levels=\", Q.get_representation_levels())\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    R = gray_image.write(k, \"/tmp/\" + str(Q_step) + '_Q_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "    D = distortion.RMSE(img, y)\n",
    "    current_J = D + _lambda * R\n",
    "    next_Q = copy.deepcopy(Q)\n",
    "    next_Q.retrain(img)\n",
    "    print(\"next_Q.get_representation_levels=\", next_Q.get_representation_levels())\n",
    "    #next_Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "    y, k = next_Q.quan_dequan(img)\n",
    "    R = gray_image.write(k, \"/tmp/\" + str(Q_step) + '_next_Q_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "    D = distortion.RMSE(img, y)\n",
    "    next_J = D + _lambda * R\n",
    "    print(current_J, next_J)\n",
    "    if next_J < current_J:\n",
    "         return next_Q\n",
    "    else:\n",
    "         return Q\n",
    "\n",
    "def optimize(Q, Q_step, _lambda, max_number_of_iters):\n",
    "    #ext_Q = quantizer(img, Q_step, min_val=0, max_val=255)\n",
    "    for i in range(max_number_of_iters):\n",
    "        Q = optimize_step(Q, Q_step, _lambda)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_bins = 32\n",
    "Q_step = 256//N_bins\n",
    "max_number_of_iters = 10\n",
    "N_bins = [2, 4, 8, 16, 32, 64, 128]\n",
    "_lambda = 200\n",
    "\n",
    "def RDO_curve(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "        Q = optimize(Q, Q_step, max_number_of_iters, _lambda)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes: \", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        if n<16:\n",
    "            plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "            plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RDO_points = RDO_curve(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # makes the random numbers predictable\n",
    "flatten_img = img.reshape((-1, 1))  # flatten\n",
    "k_means = cluster.KMeans(n_clusters=n_clusters, n_init=N_tries)\n",
    "k_means.fit(flatten_img)  # train\n",
    "centroids = k_means.cluster_centers_.squeeze()  # Centroids\n",
    "print(\"centroids =\", centroids)\n",
    "labels = k_means.labels_  # Labels of the centroids\n",
    "labels.shape = img.shape\n",
    "print(len(labels), len(centroids), img.shape, n_clusters, len(centroids.flatten()))\n",
    "gray_image.show_normalized(labels, \"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indexes (labels) are not sorted by the corresponding intensity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create an array from labels and values\n",
    "#img_dequantized = np.choose(labels, centroids)\n",
    "#img_dequantized = centroids[range(len(labels)), labels]\n",
    "#img_dequantized = np.empty_like(flatten_img)\n",
    "#for i in range(len(labels)):\n",
    "#    img_dequantized[i] = centroids[labels[i]]\n",
    "#img_dequantized = centroids[labels[range(len(labels))]]\n",
    "img_dequantized = centroids[labels]\n",
    "#img_dequantized.shape = img.shape\n",
    "\n",
    "print(\"labels\", labels, labels.shape)\n",
    "print(\"max and min dequantized image\", img_dequantized.max(), img_dequantized.min())\n",
    "prediction = k_means.predict(flatten_img)  # Quantize\n",
    "prediction.shape = img.shape\n",
    "print(\"prediction =\", prediction)\n",
    "print(\"prediction.shape =\", prediction.shape)\n",
    "\n",
    "vmin = img.min()\n",
    "vmax = img.max()\n",
    "\n",
    "gray_image.show(img_dequantized, \"Dequantized\")\n",
    "new_img_dequantized = centroids[prediction]\n",
    "gray_image.show(new_img_dequantized, \"New Dequantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
