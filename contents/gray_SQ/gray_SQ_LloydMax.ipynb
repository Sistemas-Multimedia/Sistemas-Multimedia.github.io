{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/gray_SQ/gray_SQ_LloydMax.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/gray_SQ/gray_SQ_LloydMax.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gray-scale Image compression Using a Lloyd-Max Midtread Scalar Quantizer and PNG\n",
    "\n",
    "We use [K-means](https://en.wikipedia.org/wiki/K-means_clustering) to find the centroid of each [bin](https://en.wikipedia.org/wiki/Data_binning) (see [scikit-learn's Vector Quantization Example](https://scikit-learn.org/stable/auto_examples/cluster/plot_face_compress.html#sphx-glr-auto-examples-cluster-plot-face-compress-py)). Alternatively, we can also use [K-medoids](https://scikit-learn-extra.readthedocs.io/en/stable/generated/sklearn_extra.cluster.KMedoids.html).\n",
    "\n",
    "Notice that: **The centroids or the original histogram must be transmitted to the decoder!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/scalar_quantization\" ]; then\n",
    "    cd $HOME/repos/scalar_quantization\n",
    "    echo \"$HOME/repos/scalar_quantization ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/scalar_quantization.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/MRVC\" ]; then\n",
    "    cd $HOME/repos/MRVC\n",
    "    echo \"$HOME/repos/MRVC ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/Sistemas-Multimedia/MRVC.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_IO\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/image_IO ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_IO.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/information_theory\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/information_theory ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/information_theory.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ln -sf ~/MRVC/src/logging_config.py .\n",
    "!ln -sf ~/repos/scalar_quantization/quantization.py .\n",
    "!ln -sf ~/repos/scalar_quantization/deadzone_quantization.py .\n",
    "!ln -sf ~/repos/scalar_quantization/LloydMax_quantization.py .\n",
    "!ln -sf ~/repos/information_theory/distortion.py .\n",
    "!ln -sf ~/repos/information_theory/information.py .\n",
    "!ln -sf ~/repos/image_IO/image_1.py .\n",
    "!ln -sf ~/repos/image_IO/logging_config.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    #plt.rcParams['text.usetex'] = True\n",
    "    #plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "except:\n",
    "    !pip install scipy\n",
    "    \n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip install opencv-python\n",
    "    !pip install opencv-python-headless # Binder compatibility\n",
    "    import cv2\n",
    "\n",
    "try:\n",
    "    import skimage\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    import skimage\n",
    "    \n",
    "try:\n",
    "    from sklearn import cluster\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn import cluster\n",
    "\n",
    "try:\n",
    "    import colored\n",
    "except:\n",
    "    !pip install colored\n",
    "    import colored\n",
    "\n",
    "#try:\n",
    "#    import warnings\n",
    "#except:\n",
    "#    !pip install warnings\n",
    "#    import warnings\n",
    "\n",
    "import pylab\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import os\n",
    "import deadzone_quantization as deadzone\n",
    "import LloydMax_quantization as quantization\n",
    "import distortion\n",
    "#import image_3 as RGB_image\n",
    "import image_1 as gray_image\n",
    "import colored\n",
    "import information\n",
    "import gzip\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ[\"HOME\"]\n",
    "fn = home + \"/repos/MRVC/images/lena_bw/\"\n",
    "#fn = home + \"/repos/MRVC/images/circle/\"\n",
    "#fn = home + \"/repos/MRVC/images/Hommer_bw/\"\n",
    "!ls -l {fn}\n",
    "\n",
    "# Quantizer selection\n",
    "quantizer = quantization.LloydMax_Quantizer\n",
    "\n",
    "n_clusters = 4  # Number of bins\n",
    "N_tries = 4  # Number of times K-means is run\n",
    "\n",
    "#N_bins = range(2, 128, 1)\n",
    "N_bins = [2, 4, 8, 16, 32, 64, 128] #range(2, 128, 1)\n",
    "\n",
    "gray_image.write = gray_image.debug_write # faster\n",
    "#gray_image.write = gray_image.write # higher compression\n",
    "\n",
    "#gray_image.logger.setLevel(logging.INFO)\n",
    "#quantization.logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read an image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gray_image.read(fn, 0)\n",
    "gray_image.show(img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram, bin_edges = np.histogram(img, bins=256, range=(0, 255))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Histogram\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.plot(bin_edges[0:-1], histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbols_information(sequence_of_symbols):\n",
    "    assert sequence_of_symbols.ndim == 1\n",
    "    value, counts = np.unique(sequence_of_symbols, return_counts = True)\n",
    "    probs = counts / len(sequence_of_symbols)\n",
    "    n_classes = np.count_nonzero(probs)\n",
    "\n",
    "    if n_classes <= 1:\n",
    "        return 0\n",
    "\n",
    "    information_of_symbols = []\n",
    "    for i in probs:\n",
    "        information_of_symbols.append(-math.log(i, 2))\n",
    "\n",
    "    return information_of_symbols\n",
    "\n",
    "information_of_symbols = symbols_information(img.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(information_of_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bins and representation levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QSS = 4 # Quantization Step Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q = quantizer(img, Q_step=QSS, min_val=np.min(img), max_val=np.max(img))\n",
    "#Q = quantizer(img, Q_step=QSS, min_val=np.min(img), max_val=np.max(img), speedme=True)\n",
    "print(\"decision_levels =\", Q.get_decision_levels())\n",
    "print(\"representation_levels =\", Q.get_representation_levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y, xlabel='', ylabel='', title=''):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.grid()\n",
    "    ax.xaxis.set_label_text(xlabel)\n",
    "    ax.yaxis.set_label_text(ylabel)\n",
    "    ax.plot(x, y)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 255, 500) # Input samples\n",
    "y, k = Q.encode_and_decode(x)\n",
    "#plot(x, y, \"Input Sample\", \"Reconstructed Sample\", f\"Lloyd-Max Quantizer ({fn}, $\\Delta={QSS}$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = \"Input Sample\"\n",
    "ylabel = \"Reconstructed Sample\"\n",
    "title = f\"Lloyd-Max Quantizer ({fn}, $\\Delta={QSS}$)\"\n",
    "\n",
    "ax1 = plt.subplot()\n",
    "counts, bins = np.histogram(img, range(257))\n",
    "l1 = ax1.bar(bins[:-1] - 0.5, counts, width=1, edgecolor='none')\n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(x, y, color='m')\n",
    "\n",
    "plt.legend([l1, l2], [\"Histogram\", \"Lloyd-Max Quantizer\"])\n",
    "ax1.yaxis.set_label_text(\"Pixel Value Count\")\n",
    "ax2.yaxis.set_label_text(\"Reconstructed Value\")\n",
    "ax1.xaxis.set_label_text(\"Input Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(bins)-1):\n",
    "    print(i, bins[i], counts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, in general, neither, the decision levels nor the representation levels are equally spaced. This is a direct consequence of the histogram of the input image. Thus, those input ranges where the number of gray-tones are more frequent, the resolution of the quantizer is increased. The representation levels are placed where the MSE is minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a quantization result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, k = Q.quan_dequan(img)\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "gray_image.show_normalized(k, f\"Quantization Indexes ($\\\\Delta={QSS}$)\")\n",
    "gray_image.show(y, f\"Dequantized Image ($\\\\Delta={QSS}$)\")\n",
    "print(\"MSE =\", distortion.MSE(img, y))\n",
    "print(\"SSIM =\", distortion.SSIM(img, y))\n",
    "print(\"entropy =\", information.entropy(k.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the representation of the pallete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels = np.round(Q.get_representation_levels()).astype(np.uint8)\n",
    "representation_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(np.diff(representation_levels), representation_levels[::-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_levels = np.round(Q.get_representation_levels()).astype(np.uint8)\n",
    "representation_levels_DPCM = np.append(np.diff(representation_levels), representation_levels[::-1][0]) # We start at the end!\n",
    "print(representation_levels)\n",
    "print(representation_levels_DPCM)\n",
    "#with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "#    np.save(file=f, arr=representation_levels)\n",
    "#np.save(file=\"/tmp/representation_levels.npy.gz\", arr=representation_levels)\n",
    "\n",
    "fileobj = open(\"/tmp/representation_levels.bin\", mode='wb')\n",
    "representation_levels.tofile(fileobj)\n",
    "print(\"Bytes needed for the representation levels:\", os.path.getsize(\"/tmp/representation_levels.bin\"))\n",
    "\n",
    "with gzip.GzipFile(\"/tmp/representation_levels.bin.gz\", \"w\") as f:\n",
    "    representation_levels.tofile(f)\n",
    "print(\"Bytes needed for the representation levels in .gz format:\", os.path.getsize(\"/tmp/representation_levels.bin.gz\"))\n",
    "\n",
    "fileobj = open(\"/tmp/representation_levels_DPCM.bin\", mode='wb')\n",
    "representation_levels_DPCM.tofile(fileobj)\n",
    "print(\"Bytes needed for the representation levels DPCM:\", os.path.getsize(\"/tmp/representation_levels_DPCM.bin\"))\n",
    "\n",
    "with gzip.GzipFile(\"/tmp/representation_levels_DPCM.bin.gz\", \"w\") as f:\n",
    "    representation_levels_DPCM.tofile(f)\n",
    "print(\"Bytes needed for the representation levels DPCM in .gz format:\", os.path.getsize(\"/tmp/representation_levels_DPCM.bin.gz\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the encoding seems to perform similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD curve\n",
    "We compare two versions:\n",
    "1. When the centroids are initialized using an scalar quantizer.\n",
    "2. When the centroids are initialized at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RD_curve_random_init(img, N_bins):\n",
    "    points = []\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    for n in N_bins:\n",
    "        k_means = cluster.KMeans(n_clusters=n)\n",
    "        k_means.fit(flatten_img)\n",
    "        centroids = k_means.cluster_centers_.squeeze().astype(np.uint8)  # Centroids\n",
    "        k = k_means.labels_.astype(np.uint8)  # Labels of the centroids\n",
    "        y = centroids[k]\n",
    "        y.shape = img.shape\n",
    "        k.shape = img.shape\n",
    "        print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            centroids.tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=centroids)\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={n})\")\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"N_bins={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "RD_points_random_init = RD_curve_random_init(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RD_curve_sorted_labels(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            Q.get_representation_levels().tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=Q.get_representation_levels())\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #_distortion = distortion.RMSE(img, y)\n",
    "        _distortion = distortion.RMSE(img, np.round(y).astype(np.uint8))\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={n})\")\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"N_bins={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RD_points_sorted_labels = RD_curve_sorted_labels(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), c='m', marker='x', label=\"Using sorted labels\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points_random_init), c='b', marker='x', label=\"Using unsorted labels\", linestyle=\"dotted\")\n",
    "pylab.title(f\"Rate/Distortion Performance\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more efficient in terms of rate (and faster, because K-Means runs only one time) to initialize the centroids using the representation levels of a midtread quantizer. Notice that this disables the random selection of the initial centroids and therefore, it converts to K-means in a deterministic clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"LloydMax_RD_points.txt\", 'w') as f:\n",
    "    for item in RD_points_sorted_labels:\n",
    "        f.write(f\"{item[0]}\\t{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using [K-medoids](https://scikit-learn-extra.readthedocs.io/en/stable/generated/sklearn_extra.cluster.KMedoids.html)\n",
    "\n",
    "Selects one element of the input (a medoid) as the center for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_step = 16\n",
    "Q = quantizer(img[::10,::10], Q_step=Q_step, use_medoid=True, N_samples=img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = quantizer(img[::10,::10], Q_step=Q_step, use_medoid=False, N_samples=img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[::10,::10].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RD_curve_KMedoids(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step, use_medoid=True, N_samples=1_000)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            Q.get_representation_levels().tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=Q.get_representation_levels())\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #_distortion = distortion.RMSE(img, y)\n",
    "        _distortion = distortion.RMSE(img, np.round(y).astype(np.uint8))\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={n})\")\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"N_bins={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RD_points_KMedoids = RD_curve_KMedoids(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), c='m', marker='x', label=\"KMeans\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points_KMedoids), c='b', marker='x', label=\"KMedoids\", linestyle=\"dotted\")\n",
    "pylab.title(f\"Rate/Distortion Performance\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if we increase the granuality?\n",
    "Let's see the effect of using a finer quantization step (size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = [i for i in range(2, 128, 1)]\n",
    "print(N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _(a, cmap, vmin, vmax):\n",
    "    pass\n",
    "plt.show = print\n",
    "plt.imshow = _\n",
    "RD_points_finer = RD_curve_sorted_labels(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), c='m', marker='x', label=f\"Using powers of 2\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points_finer), c='g', marker='.', label=f\"Using more quantization steps\", linestyle=\"dotted\")\n",
    "pylab.title(fn)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the quantization steps that are powers of 2 describe reasonably well the convex hull of the RD curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDO (Rate Distortion Optimization) over the tile size\n",
    "\n",
    "So far, the design of the Lloyd-Max quantizer has been independent of the rate (only the distortion has been minimized). However, the final RD performance of the encoding system depends on both opposed features (rate and distortion), generating a tradeoff that can be optimized under certain conditions.\n",
    "\n",
    "For example, let's imagine that the image is quantized by tiles. Thus, in each tile, a \"local\" Lloyd-Max quantizer can be used, potentially decreasing the distortion (the histogram of a tile is more accurate describing the counts of the gray-scale values of the tile, than the histogram of the whole image). On the other hand, each tile requires at least a slighly different set of representation levels, aspect that will increase the rate (remember that in the case of the Lloyd-Max quantizer, the representation levels must be transmitted in the code-stream). Supposing that all the tiles have the same size, which tiling-configuration (tile size) is the most RD-efficient?\n",
    "\n",
    "The following code determines the optimal tile size (in a linear and supposedly convex search space spawned by the side of the squared tiles, being the side a power of two) for different RD points. To determine the RD performance in a point $i$ of the RD curve (considering a RMSE VS bit-rate RD curve), we will use the [Lagrangian](https://en.wikipedia.org/wiki/Lagrange_multiplier):\n",
    "$$\n",
    "\\mathbf{J}_i = \\mathbf{D}_i + \\mathbf{\\lambda}_i \\mathbf{R}_i,\n",
    "$$\n",
    "where $\\mathbf{D}$ is a set of distortions (one for each point of the RD curve), $\\mathbf{R}$ is a set of (bit-)rates (one for each point of the RD curve), and $\\mathbf{\\lambda}$ is known as a Lagrangian Multipler that controls the relative *importance* between $\\mathbf{D}$ and $\\mathbf{R}$ (that selects the $i$-th point of the RD curve). For example:\n",
    "1. If $\\mathbf{\\lambda}_i=0$, and we are minimizing the Lagrangian, we are only interested in minimizing the distortion and therefore, we are \"exploring\" the bottom-right segment of the RD curve.\n",
    "2. If $\\mathbf{\\lambda}_i=\\infty$ (in the practice, a very large value) we are minimizing the RD tradeoff at the top-left segment of the RD curve (high compression ratio and probably, and a higher distortion).\n",
    "3. Intermediate values of $\\mathbf{\\lambda}$ correspond to other internal points of the RD curve.\n",
    "\n",
    "Finally, notice that we have defined $\\mathbf{\\lambda}_i$ as a continuous parameter, but the number of points of the RD curve is finite. Therefore, to determine $\\mathbf{\\lambda}_i$ for the point $i$ of the curve, we can define that:\n",
    "$$\n",
    "\\mathbf{\\lambda}_i = \\frac{\\mathbf{D}_i-\\mathbf{D}_{i+1}}{\\mathbf{R}_{i+1}-\\mathbf{R}_i}\n",
    "$$\n",
    "and that:\n",
    "$$\n",
    "\\mathbf{\\lambda}_{(\\Delta=1)}=0.\n",
    "$$\n",
    "\n",
    "Therefore, the idea is to find, given a $i$, which tile size is the optimal one (minimizes the Lagrangian). Such tile size must be encoded (represented in the code-stream).\n",
    "\n",
    "Finally, notice that this is a form of Forward Adaptive Quantization (see Sayood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = []\n",
    "for i in range(len(RD_points_sorted_labels)-1):\n",
    "    _lambda.append((RD_points_sorted_labels[i][1] - RD_points_sorted_labels[i+1][1])/(RD_points_sorted_labels[i+1][0]-RD_points_sorted_labels[i][0]))\n",
    "_lambda.append(_lambda[::-1][0]/2)  # Dividing by 2 is a good estimation when we are duplicating the number of bins with each point\n",
    "print(_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = [2, 4, 8, 16, 32, 64, 128] #range(2, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tile_sides = [512, 256, 128, 64, 32, 16]\n",
    "# The search space is small and a sequential search should be fast enough.\n",
    "\n",
    "def optimize_tile_side(img, N_bins, tile_sides):\n",
    "    print(\"img.shape =\", img.shape)\n",
    "    K = np.empty_like(img)\n",
    "    Y = np.empty_like(img)\n",
    "    J = np.empty(shape=(len(tile_sides), len(N_bins)))\n",
    "    for tsc, ts in enumerate(tile_sides):\n",
    "        print(\"ts =\", ts)\n",
    "        tiles_in_y = img.shape[0]//ts\n",
    "        tiles_in_x = img.shape[1]//ts\n",
    "        number_of_tiles = tiles_in_y*tiles_in_x\n",
    "        print(\"tiles_in_y =\", tiles_in_y)\n",
    "        print(\"tiles_in_x =\", tiles_in_x)\n",
    "        for nc, n in enumerate(N_bins):\n",
    "            Q_step = 256//n\n",
    "            _distortion = 0\n",
    "            rate = 0\n",
    "            pallete = np.empty(shape=(tiles_in_y, tiles_in_x, n), dtype=np.uint8)\n",
    "            for ty in range(tiles_in_y):\n",
    "                for tx in range(tiles_in_x):\n",
    "                    tile = img[ty*ts:(ty+1)*ts, tx*ts:(tx+1)*ts]\n",
    "                    Q = quantizer(tile, Q_step=Q_step)\n",
    "                    y, k = Q.quan_dequan(tile)\n",
    "                    K[ty*ts:(ty+1)*ts, tx*ts:(tx+1)*ts] = k\n",
    "                    Y[ty*ts:(ty+1)*ts, tx*ts:(tx+1)*ts] = np.rint(y)  # The representation levels are integers to minimize the data-overhead\n",
    "                    representation_levels = np.rint(Q.get_representation_levels()).astype(np.uint8)\n",
    "                    _distortion += distortion.RMSE(tile, y)\n",
    "                    pallete[ty, tx, :] = np.append(np.diff(representation_levels), representation_levels[::-1][0])\n",
    "            rate += gray_image.write(K, \"/tmp/\" + str(n) + '_', 0)*8/(img.shape[0]*img.shape[1])\n",
    "            overhead = 0\n",
    "            for i in range(n):\n",
    "                overhead += gray_image.write(pallete[..., i], f\"/tmp/pallete_bin={i}_Nbins={n}_\", 0)*8/(img.shape[0]*img.shape[1])\n",
    "            print(\"overhead =\", overhead, \"bits/pixel\")\n",
    "            _distortion /= number_of_tiles\n",
    "            rate += overhead\n",
    "            J[tsc, nc] = _distortion + _lambda[nc] * rate\n",
    "            print(f\"{tsc} {nc} ts={ts:>3} n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f} J={J[tsc, nc]} lambda={_lambda[nc]}\")\n",
    "    return J\n",
    "\n",
    "J = optimize_tile_side(img, N_bins, tile_sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_ts = []\n",
    "for nc in range(len(N_bins)):\n",
    "    optimal_ts_index = np.argmin(J[..., nc])\n",
    "    optimal_ts.append(tile_sides[optimal_ts_index])\n",
    "print(optimal_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_RD_curve(img, N_bins, optimal_ts):\n",
    "    K = np.empty_like(img)\n",
    "    Y = np.empty_like(img)\n",
    "    points = []\n",
    "    for nc, n in enumerate(N_bins):\n",
    "        ts = optimal_ts[nc]\n",
    "        tiles_in_y = img.shape[0]//ts\n",
    "        tiles_in_x = img.shape[1]//ts\n",
    "        number_of_tiles = tiles_in_y*tiles_in_x\n",
    "        Q_step = 256//n\n",
    "        _distortion = 0\n",
    "        rate = 0\n",
    "        pallete = np.empty(shape=(tiles_in_y, tiles_in_x, n), dtype=np.uint8)\n",
    "        for ty in range(tiles_in_y):\n",
    "            for tx in range(tiles_in_x):\n",
    "                #print(\"ty =\", ty, \"tx =\", tx)\n",
    "                tile = img[ty*ts:(ty+1)*ts, tx*ts:(tx+1)*ts]\n",
    "                #print(tile.shape)\n",
    "                Q = quantizer(tile, Q_step=Q_step, min_val=0, max_val=255)\n",
    "                y, k = Q.quan_dequan(tile)\n",
    "                K[ty*ts:(ty+1)*ts, tx*ts:(tx+1)*ts] = k\n",
    "                Y[ty*ts:(ty+1)*ts, tx*ts:(tx+1)*ts] = np.rint(y)  # The representation levels are integers to minimize the data-overhead\n",
    "                representation_levels = np.rint(Q.get_representation_levels()).astype(np.uint8)\n",
    "                _distortion += distortion.RMSE(tile, y)\n",
    "                pallete[ty, tx, :] = np.append(np.diff(representation_levels), representation_levels[::-1][0])\n",
    "        rate += gray_image.write(K, \"/tmp/\" + str(n) + '_', 0)*8/(img.shape[0]*img.shape[1])\n",
    "        overhead = 0\n",
    "        for i in range(n):\n",
    "            overhead += gray_image.write(pallete[..., i], f\"/tmp/pallete_bin={i}_Nbins={n}_\", 0)*8/(img.shape[0]*img.shape[1])\n",
    "        print(\"overhead =\", overhead, \"bits/pixel\")\n",
    "        _distortion /= number_of_tiles\n",
    "        rate += overhead\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}, tile_side={ts}\")\n",
    "    return points\n",
    "\n",
    "RDO_points = optimal_RD_curve(img, N_bins, optimal_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points_sorted_labels), label=f\"No tiling\", marker='o', linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RDO_points), label=f\"Optimal Tiling\", marker='o', linestyle=\"dotted\")\n",
    "pylab.title(f\"Rate/Distortion Performance\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDO over the \"boundary\" intensitiy values\n",
    "\n",
    "Some value pixels of the image are in limit between bins. Those pixels are susceptible of being quantized in the closest bin, if the RD Lagrangian provides a higher slope.\n",
    "\n",
    "Supposing that the impact on the RD curve of shift of the representation levels are independent (if we shift, for example, a decision level and the curve gets worse, this behaviour does not depend on any other possible shift in the rest of decision and representation levels), the following experiment optimizes the levels under the RD perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_levels(img, N_bins, search_range):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        #print(\"Quantization indexes:\", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "            Q.get_representation_levels().tofile(f)\n",
    "        rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "        #    np.save(file=f, arr=Q.get_representation_levels())\n",
    "        #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(k.shape[0]*k.shape[1]))\n",
    "        #_distortion = distortion.RMSE(img, y)\n",
    "        _distortion = distortion.RMSE(img, np.round(y).astype(np.uint8))\n",
    "        gray_image.show_normalized(k, f\"Quantization Indexes (N_bins={n})\")\n",
    "        #if n<16:\n",
    "        #    plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "        #    plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"N_bins={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RDO_points = optimize_levels(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar a mover los representation levels, calculando el bit-rate. En teoría, los niveles de representación calculados por Kmeans deberían ser casi los que minimizan J, y por lo tanto, el espacio de búsqueda es pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, it should be possible to design a RD-optimized Lloyd-Max quantizer for the whole image (so far, only D has beeb optimized) if instead of minimizing only the distortion we minimize the lagrangian:\n",
    "$$\n",
    "J = D + \\lambda R\n",
    "$$\n",
    "for each possible input (gray level) value (supposing that the contribution to $R$ of each pixel will be proportional to the definitive $R$), for a given $\\lambda$. Thus, we could build our optimized quantizer in three steps:\n",
    "1. Use a Lloyd-Max quantizer to compute the D (in terms of the RMSE) and the average R (in terms of the entropy) of each gray-value of the image. This will generate a \"J\" 1D-array with 256 entries, that maps pixel values to J values.\n",
    "2. Using the previous array, build a \"J\" 2D-array, replacing the pixel values by the corresponding J values.\n",
    "3. Find the Lloyd-Max quantizer considering the J 2D-array.\n",
    "\n",
    "To encode a pixel, we need to find the corresponding J value, and quantize this using the optimized quantizer. To decode an index, we need to find the pixel value that corresponds to the dequantized J value. For this, we need to use the 1D array that maps J values to pixel values.\n",
    "\n",
    "Finally, notice that the quantizer must be optimized for a given $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tile_side = 128  # Must be a multiple of both dimensions of the image\n",
    "\n",
    "def RD_curve(img, N_bins, tile_side):\n",
    "    tiles_in_y = img.shape[0]//tile_side\n",
    "    tiles_in_x = img.shape[1]//tile_side\n",
    "    print(\"tile_side =\", tile_side)\n",
    "    print(\"tiles_in_y =\", tiles_in_y)\n",
    "    print(\"tiles_in_x =\", tiles_in_x)\n",
    "    number_of_tiles = tiles_in_y*tiles_in_x\n",
    "    K = np.empty_like(img)\n",
    "    Y = np.empty_like(img)\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        _distortion = 0\n",
    "        rate = 0\n",
    "        prev_representation_levels = np.zeros(n, dtype=np.int8)\n",
    "        pallete = np.empty(shape=(tiles_in_y, tiles_in_x, n), dtype=np.uint8)\n",
    "        #print(prev_representation_levels.shape)\n",
    "        for ty in range(tiles_in_y):\n",
    "            for tx in range(tiles_in_x):\n",
    "                tile = img[ty*tile_side:(ty+1)*tile_side, tx*tile_side:(tx+1)*tile_side]\n",
    "                Q = quantizer(tile, Q_step=Q_step, min_val=0, max_val=255)\n",
    "                #Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "                y, k = Q.quan_dequan(tile)\n",
    "                K[ty*tile_side:(ty+1)*tile_side, tx*tile_side:(tx+1)*tile_side] = k\n",
    "                Y[ty*tile_side:(ty+1)*tile_side, tx*tile_side:(tx+1)*tile_side] = np.rint(y)  # The representation levels are integers to minimize the data-overhead\n",
    "                representation_levels = np.rint(Q.get_representation_levels()).astype(np.uint8)\n",
    "                #print(representation_levels)\n",
    "                #with gzip.GzipFile(\"/tmp/representation_levels.npy.gz\", \"w\") as f:\n",
    "                #    diff_representation_levels = representation_levels - prev_representation_levels\n",
    "                #    np.save(file=f, arr=diff_representation_levels)\n",
    "                #    print(representation_levels, prev_representation_levels, diff_representation_levels)\n",
    "                #prev_representation_levels[:] = representation_levels\n",
    "                #rate += (os.path.getsize(\"/tmp/representation_levels.npy.gz\")*8/(img.shape[0]*img.shape[1]))\n",
    "                _distortion += distortion.RMSE(tile, y)\n",
    "                pallete[ty, tx, :] = np.append(np.diff(representation_levels), representation_levels[::-1][0])\n",
    "                #pallete[ty, tx, :] = representation_levels\n",
    "                #gray_image.show_normalized(pallete[..., 0], \"\")\n",
    "                #with open(\"/tmp/representation_levels.uint8\", mode=\"wb\") as f:\n",
    "                #    Q.get_representation_levels().tofile(f)\n",
    "                #rate += (os.path.getsize(\"/tmp/representation_levels.uint8\")*8/(img.shape[0]*img.shape[1]))\n",
    "        rate += gray_image.write(K, \"/tmp/\" + str(n) + '_', 0)*8/(img.shape[0]*img.shape[1])\n",
    "        overhead = 0\n",
    "        for i in range(n):\n",
    "            #print(pallete[..., i])\n",
    "            overhead += gray_image.write(pallete[..., i], f\"/tmp/pallete_bin={i}_Nbins={n}_\", 0)*8/(img.shape[0]*img.shape[1])\n",
    "        print(\"overhead =\", overhead, \"bits/pixel\")\n",
    "        _distortion /= number_of_tiles\n",
    "        rate += overhead\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "        gray_image.show_normalized(K, f\"Quantization Indexes (n={n})\")\n",
    "        gray_image.show(Y, f\"Reconstruction (n={n})\")\n",
    "        J = _distortion + _lambda[len(points)-1] * rate\n",
    "        print(\"J =\", J, _distortion, _lambda[len(points)-1],  rate)\n",
    "    return points\n",
    "\n",
    "RDO_points_256 = RD_curve(img, N_bins, 256)\n",
    "RDO_points_128 = RD_curve(img, N_bins, 128)\n",
    "RDO_points_64 = RD_curve(img, N_bins, 64)\n",
    "RDO_points_32 = RD_curve(img, N_bins, 32)\n",
    "#RDO_points_16 = RD_curve(img, N_bins, 16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is posible to improve the RD curve using stocastic search? The idea is to, given a K-Means solution, perform a (finite) number of training steps of the classifier with the hope of finding a better one (remember that K-Means obtains different solutions when it is run several times). If this happens, the process is repeated. Otherwise, we stop.\n",
    "\n",
    "To determine if the current classifier is better than the previous one, we can use a Lagrangian Multiplier\n",
    "$$\n",
    "J = D+\\lambda R,\n",
    "$$\n",
    "where the tradeoff between rate (R) and distortion (D) is quantified for a given slope $\\lambda$. Thus, the smaller the $J$, the better the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDO(quantization.LloydMax_Quantizer):\n",
    "\n",
    "    def __init__(img, Q_step, max_number_of_iters, _lambda):\n",
    "        self.Q = super().__init__(img, Q_step=QS, min_val=0, max_val=255)\n",
    "        self.img = img\n",
    "        self.Q_step = Q_step\n",
    "        self.max_number_of_iters = max_number_of_iters\n",
    "        #self.lambda = _lambda\n",
    "\n",
    "    def RDO_step():\n",
    "        y, k = self.Q.quan_dequan(self.img)\n",
    "        R = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        D = distortion.RMSE(img, y)\n",
    "        current_J = D + _lambda * R\n",
    "        next_Q = self.quantizer(self.img, Q_step=self.Q_step, min_val=0, max_val=255)\n",
    "        y, k = next_Q.quan_dequan(self.img)\n",
    "        R = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        D = distortion.RMSE(img, y)\n",
    "        next_J = D + _lambda * R\n",
    "        if next_J < current_J:\n",
    "            return next_Q\n",
    "        else:\n",
    "            return current_Q\n",
    "\n",
    "    def RDO():\n",
    "        Q = self.quantizer(self.img, Q_step=self.Q_step, min_val=0, max_val=255)\n",
    "        for i in range(max_number_of_iters):\n",
    "            Q = RDO_step(Q)\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def optimize_step(Q, Q_step, _lambda):\n",
    "    print(\"Q.get_representation_levels=\", Q.get_representation_levels())\n",
    "    y, k = Q.quan_dequan(img)\n",
    "    R = gray_image.write(k, \"/tmp/\" + str(Q_step) + '_Q_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "    D = distortion.RMSE(img, y)\n",
    "    current_J = D + _lambda * R\n",
    "    next_Q = copy.deepcopy(Q)\n",
    "    next_Q.retrain(img)\n",
    "    print(\"next_Q.get_representation_levels=\", next_Q.get_representation_levels())\n",
    "    #next_Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "    y, k = next_Q.quan_dequan(img)\n",
    "    R = gray_image.write(k, \"/tmp/\" + str(Q_step) + '_next_Q_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "    D = distortion.RMSE(img, y)\n",
    "    next_J = D + _lambda * R\n",
    "    print(current_J, next_J)\n",
    "    if next_J < current_J:\n",
    "         return next_Q\n",
    "    else:\n",
    "         return Q\n",
    "\n",
    "def optimize(Q, Q_step, _lambda, max_number_of_iters):\n",
    "    #ext_Q = quantizer(img, Q_step, min_val=0, max_val=255)\n",
    "    for i in range(max_number_of_iters):\n",
    "        Q = optimize_step(Q, Q_step, _lambda)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_bins = 32\n",
    "Q_step = 256//N_bins\n",
    "max_number_of_iters = 10\n",
    "N_bins = [2, 4, 8, 16, 32, 64, 128]\n",
    "_lambda = 200\n",
    "\n",
    "def RDO_curve(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        Q_step = 256//n\n",
    "        Q = quantizer(img, Q_step=Q_step, min_val=0, max_val=255)\n",
    "        Q = optimize(Q, Q_step, max_number_of_iters, _lambda)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes: \", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/(k.shape[0]*k.shape[1])\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        if n<16:\n",
    "            plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "            plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RDO_points = RDO_curve(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # makes the random numbers predictable\n",
    "flatten_img = img.reshape((-1, 1))  # flatten\n",
    "k_means = cluster.KMeans(n_clusters=n_clusters, n_init=N_tries)\n",
    "k_means.fit(flatten_img)  # train\n",
    "centroids = k_means.cluster_centers_.squeeze()  # Centroids\n",
    "print(\"centroids =\", centroids)\n",
    "labels = k_means.labels_  # Labels of the centroids\n",
    "labels.shape = img.shape\n",
    "print(len(labels), len(centroids), img.shape, n_clusters, len(centroids.flatten()))\n",
    "gray_image.show_normalized(labels, \"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indexes (labels) are not sorted by the corresponding intensity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create an array from labels and values\n",
    "#img_dequantized = np.choose(labels, centroids)\n",
    "#img_dequantized = centroids[range(len(labels)), labels]\n",
    "#img_dequantized = np.empty_like(flatten_img)\n",
    "#for i in range(len(labels)):\n",
    "#    img_dequantized[i] = centroids[labels[i]]\n",
    "#img_dequantized = centroids[labels[range(len(labels))]]\n",
    "img_dequantized = centroids[labels]\n",
    "#img_dequantized.shape = img.shape\n",
    "\n",
    "print(\"labels\", labels, labels.shape)\n",
    "print(\"max and min dequantized image\", img_dequantized.max(), img_dequantized.min())\n",
    "prediction = k_means.predict(flatten_img)  # Quantize\n",
    "prediction.shape = img.shape\n",
    "print(\"prediction =\", prediction)\n",
    "print(\"prediction.shape =\", prediction.shape)\n",
    "\n",
    "vmin = img.min()\n",
    "vmax = img.max()\n",
    "\n",
    "gray_image.show(img_dequantized, \"Dequantized\")\n",
    "new_img_dequantized = centroids[prediction]\n",
    "gray_image.show(new_img_dequantized, \"New Dequantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
