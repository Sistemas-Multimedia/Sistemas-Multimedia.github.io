{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/scalar_quantization/LloydMax.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/scalar_quantization/LloydMax.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Lloyd-Max Quantization\n",
    "\n",
    "Use K-means to find the centroid of each bin. See [scikit-learn's Vector Quantization Example](https://scikit-learn.org/stable/auto_examples/cluster/plot_face_compress.html#sphx-glr-auto-examples-cluster-plot-face-compress-py).\n",
    "\n",
    "Notice that the centroids must be transmitted to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos\" ]; then\n",
    "    echo \"\\\"$HOME/repos\\\" exists\"\n",
    "else\n",
    "    mkdir ~/repos\n",
    "    echo Created $HOME/repos\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/scalar_quantization\" ]; then\n",
    "    cd $HOME/repos/scalar_quantization\n",
    "    echo \"$HOME/repos/scalar_quantization ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/scalar_quantization.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/MRVC\" ]; then\n",
    "    cd $HOME/repos/MRVC\n",
    "    echo \"$HOME/repos/MRVC ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/Sistemas-Multimedia/MRVC.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d \"$HOME/repos/image_IO\" ]; then\n",
    "    cd $HOME/repos/image_IO\n",
    "    echo \"$HOME/repos/image_IO ... \"\n",
    "    git pull \n",
    "else\n",
    "    cd $HOME/repos\n",
    "    git clone https://github.com/vicente-gonzalez-ruiz/image_IO.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -sf ~/MRVC/src/logging_config.py .\n",
    "!ln -sf ~/repos/scalar_quantization/quantization.py .\n",
    "!ln -sf ~/repos/scalar_quantization/deadzone_quantization.py .\n",
    "!ln -sf ~/repos/scalar_quantization/LloydMax_quantization.py .\n",
    "!ln -sf ~/repos/information_theory/distortion.py .\n",
    "!ln -sf ~/repos/information_theory/information.py .\n",
    "!ln -sf ~/repos/image_IO/image_1.py .\n",
    "!ln -sf ~/repos/image_IO/logging_config.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.axes as ax\n",
    "    #plt.rcParams['text.usetex'] = True\n",
    "    #plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "except:\n",
    "    !pip install scipy\n",
    "    \n",
    "try:\n",
    "    import cv2\n",
    "except:\n",
    "    !pip install opencv-python\n",
    "    !pip install opencv-python-headless # Binder compatibility\n",
    "    import cv2\n",
    "\n",
    "try:\n",
    "    import skimage\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    import skimage\n",
    "    \n",
    "try:\n",
    "    from sklearn import cluster\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn import cluster\n",
    "\n",
    "try:\n",
    "    import colored\n",
    "except:\n",
    "    !pip install colored\n",
    "    import colored\n",
    "\n",
    "import pylab\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import os\n",
    "import deadzone_quantization as deadzone\n",
    "import LloydMax_quantization as quantization\n",
    "import distortion\n",
    "#import image_3 as RGB_image\n",
    "import image_1 as gray_image\n",
    "import colored\n",
    "import information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ[\"HOME\"]\n",
    "fn = home + \"/repos/MRVC/images/lena_bw/\"\n",
    "!ls -l {fn}\n",
    "\n",
    "quantizer = quantization.LloydMax_Quantizer\n",
    "\n",
    "n_clusters = 4  # Number of bins\n",
    "N_tries = 4  # Number of times K-means is run\n",
    "#N_bins = range(2, 128, 1)\n",
    "N_bins = [2, 4, 8, 16, 32, 64, 128] #range(2, 128, 1)\n",
    "gray_image.write = gray_image.debug_write # faster\n",
    "#gray_image.write = gray_image.write # higher compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = gray_image.read(fn, 0)\n",
    "gray_image.show(img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics of Lloyd-Max quantization using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # makes the random numbers predictable\n",
    "flatten_img = img.reshape((-1, 1))  # flatten\n",
    "k_means = cluster.KMeans(n_clusters=n_clusters, n_init=N_tries)\n",
    "k_means.fit(flatten_img)\n",
    "centroids = k_means.cluster_centers_.squeeze()  # Centroids\n",
    "labels = k_means.labels_  # Labels of the centroids\n",
    "labels.shape = img.shape\n",
    "print(len(labels), len(centroids), img.shape, n_clusters, len(centroids.flatten()))\n",
    "\n",
    "# create an array from labels and values\n",
    "#img_dequantized = np.choose(labels, centroids)\n",
    "#img_dequantized = centroids[range(len(labels)), labels]\n",
    "#img_dequantized = np.empty_like(flatten_img)\n",
    "#for i in range(len(labels)):\n",
    "#    img_dequantized[i] = centroids[labels[i]]\n",
    "#img_dequantized = centroids[labels[range(len(labels))]]\n",
    "img_dequantized = centroids[labels]\n",
    "#img_dequantized.shape = img.shape\n",
    "\n",
    "print(\"centroids\", centroids)\n",
    "print(\"labels\", labels, labels.shape)\n",
    "print(\"max and min dequantized image\", img_dequantized.max(), img_dequantized.min())\n",
    "prediction = k_means.predict(flatten_img)\n",
    "prediction.shape = img.shape\n",
    "print(\"prediction =\", prediction)\n",
    "print(\"prediction.shape =\", prediction.shape)\n",
    "\n",
    "vmin = img.min()\n",
    "vmax = img.max()\n",
    "\n",
    "gray_image.show(img_dequantized, \"Dequantized\")\n",
    "new_img_dequantized = centroids[prediction]\n",
    "gray_image.show(new_img_dequantized, \"New Dequantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QS = 32 # Quantization Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = quantizer(img, Q_step=QS, min_val=0, max_val=255)\n",
    "print(Q.get_decision_levels())\n",
    "print(Q.get_representation_levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, k = Q.quan_dequan(img)\n",
    "print(\"Used quantization indexes:\", np.unique(k))\n",
    "gray_image.show_normalized(k, f\"$\\\\Delta={QS}$\")\n",
    "gray_image.show(y, f\"$\\\\Delta={QS}$\")\n",
    "print(\"MSE =\", distortion.MSE(img, y))\n",
    "print(\"SSIM =\", distortion.SSIM(img, y))\n",
    "print(\"entropy =\", information.entropy(k.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def RD_curve2(img, N_bins):\n",
    "    points = []\n",
    "    flatten_img = img.reshape((-1, 1))  # flatten\n",
    "    for n in N_bins:\n",
    "        k_means = cluster.KMeans(n_clusters=n, n_init=N_tries)\n",
    "        k_means.fit(flatten_img)\n",
    "        centroids = k_means.cluster_centers_.squeeze().astype(np.uint8)  # Centroids\n",
    "        k = k_means.labels_.astype(np.uint8)  # Labels of the centroids\n",
    "        #y = np.choose(k, centroids)\n",
    "        #y = centroids[k[range(len(k))]]\n",
    "        y = centroids[k]\n",
    "        y.shape = img.shape\n",
    "        k.shape = img.shape\n",
    "        print(\"Quantization indexes: \", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/k.size\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        if n<16:\n",
    "            plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "            plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "def RD_curve(img, N_bins):\n",
    "    points = []\n",
    "    for n in N_bins:\n",
    "        QS = 256//n\n",
    "        Q = quantizer(img, Q_step=QS, min_val=0, max_val=255)\n",
    "        y, k = Q.quan_dequan(img)\n",
    "        print(\"Quantization indexes: \", np.unique(k))\n",
    "        rate = gray_image.write(k, \"/tmp/\" + str(n) + '_', 0)*8/k.size\n",
    "        _distortion = distortion.RMSE(img, y)\n",
    "        if n<16:\n",
    "            plt.imshow(y, cmap=plt.cm.gray, vmin=0, vmax=256)\n",
    "            plt.show()\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"n={n:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "RD_points = RD_curve(img, N_bins)\n",
    "RD_points2 = RD_curve2(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points), c='m', marker='x', label=f\"Sorted\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points2), c='b', marker='x', label=f\"Unsorted\", linestyle=\"dotted\")\n",
    "pylab.title(f\"Rate/Distortion Performance\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"LloydMax_RD_points.txt\", 'w') as f:\n",
    "    for item in RD_points:\n",
    "        f.write(f\"{item[0]}\\t{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens if we increase the granuality?\n",
    "Let's see the effect of using a finer quantization step (size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = [i for i in range(2, 128, 1)]\n",
    "print(N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _(a, cmap, vmin, vmax):\n",
    "    pass\n",
    "plt.show = print\n",
    "plt.imshow = _\n",
    "RD_points_finer = RD_curve(img, N_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RD_points_finer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_points_finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_points), c='m', marker='x', label=f\"Using powers of 2\", linestyle=\"dotted\")\n",
    "pylab.plot(*zip(*RD_points_finer), c='g', marker='x', label=f\"Using more quantization steps\", linestyle=\"dotted\")\n",
    "pylab.title(fn)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen:\n",
    "\n",
    "1. The use of quantization steps that are not powers of 2 can generate some cases in which when we decrease the step, the rate increases.\n",
    "2. The use of quantization steps that are powers of 2 are on the convex hull of the RD curve (all the points contributes to the convexity of the curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
