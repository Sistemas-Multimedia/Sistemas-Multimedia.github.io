% Emacs, this is -*-latex-*-

\input{../../definitions}
\title{\SM{} - \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/perceptual_coding}{Perceptual Coding}}

\maketitle
\tableofcontents

\section{What is perceptual coding?}

So far, we have been focused on minimizing the lagrangian~\cite{sullivan1998rate}
\begin{equation}
  J = R + \lambda D,
\end{equation}
where $D$ is an additive\footnote{The total distortion of two (or
  more) sources of distortion is the sum of the distortions of these
  two (or more) sources.} distance metric, such as the RMSE, the PSNR
or SSIM index~\cite{wang2004image}. However, the way in which human
beings perceive distortion is generally different from how these
metrics express it. This chapter introduces some of the most common
ways of exploiting the distortion perceived by humans.

Notice that if, by requirements of the encoding process, $D$ is below
a threshold of noticeable distortion (ToND), the RDO process boilds down to
select the option with smaller $R$.

\section{ToND varies with the luma intensity}

The Weber-Fechner law states that the minimum perceivable visual
stimulus difference increases with the background
luminance\footnote{In general, this is not true for the chroma.}, up
to a point in which decreases. Therefore, the perception of the
distortion generated by the lossy coding of an image is smaller in
those areas with higher and lower intensity
values~\cite{naccari2014perceptually}. For this reason, one of the
most used quantizers is the deadzone, which also in general change
signal noise (for example, electronic noise) by quantization noise,
where the SNR of the signal is small.

\section{ToND varies with the spatial frequency}
The HVS can be modeled as a low-pass filter whose cut-off frequency
depends on the distance between the observer and the content (in terms
of frequency) of the image.

Some image and video coding standards, such as JPEG and H.264 specify
quantization matrices designed to perceptual coding. In the case of
video, such matrices can change between images. Usually, luma and
chroma can have different quantization
matrices~\cite{naccari2014perceptually}.

\section{Visual masking of the quantization noise}

The quantization noise is generated by the quantizer, generating
different coding artifacts\footnote{``Random'' noise, blocking,
  ringing, etc.}, which are perceived hardly when the (area of the)
encoded image is textured~\cite{wu2017digital}. This effect can
happens up to the ToND.

Another important aspect of our perception is its directionality,
which leads the HVS to be more sensitive to distortions added to
horizontal and vertical frequencies rather than to diagonal
ones~\cite{naccari2014perceptually}.

Finally, the rationale behind the temporal masking is that the HVS
sensitivity to coding artifacts is lower in areas with very high
motion activity. Modeling temporal masking is more challenging because
the spatio-temporal sensitivity function of the HVS is not separable,
i.e., it depends on both the spatial and temporal
frequencies~\cite{naccari2014perceptually}.

\section{Loop filters}

Loop filters are used in motion compensated video codecs to improve
the visual quality (and also the encoding RD performance). For
example, H.264/AVC uses (usually directional) deblocking filters in
the encoding loop for smooth the transitions between the blocks, when
the boundaries between them become perceptible.

\section{Luma redundancy}

The HVS can perceive only a finite number of different intensities
(luma). This number depends on the dynamic range of the pixels, but in
general, we are not able to distinguish more than 64 intensity
values~\cite{vruiz__visual_redundancy}.

\section{Chroma redundancy}

Humans do not perceive detail in the chrominance as well as in they
does in the luminance~\cite{burger2016digital}. As in $\text{YCrCb}$,
the
\href{https://en.wikipedia.org/wiki/Sampling_(signal_processing)}{sampling
  rate} of the chroma is usually reduces to 1/4 without any noticeable
distortion. This feature is used in some of the last image and video
compression systems such as
\href{https://en.wikipedia.org/wiki/JPEG_XR#Description}{JPEG XR} and
\href{https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding#Video_coding_layer}{HEVC}.

See the notebook
\href{https://github.com/vicente-gonzalez-ruiz/color_transforms/blob/main/docs/color_redundancy.ipynb}{Spectral
  (color) redundancy}.

\section{Redundancy in the RGB domain}

The Human Visual System (HVS) is more sensitive to luminance than to
chrominance~\cite{vruiz__visual_redundancy}. This basically means that
we can an encoding process we modify the color information of an image
or a video without noticing a high distortion.

Since the \href{https://en.wikipedia.org/wiki/Visual_system}{HVS
  (Human Visual System)} is not able to perceive detail in the
chrominance as well as it does in the luminance, the amount of
information, and consequently
\href{https://en.wikipedia.org/wiki/Sampling_(signal_processing)}{sampling
  rate}, used in the chrominance can be generally reduced to 1/4 of
the used for the luminance without a noticeable distortion (see
Fig.~\ref{fig:san-diego_chroma_subsampled})~\cite{burger2016digital}. This
\href{https://en.wikipedia.org/wiki/Bandwidth_(computing)}{fact is
  used when compressing} digital still images and is one of the reason
why, for example, the $\text{YCrCb}$ transform is used in the
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG} image compressor.

%  V E R   R E P O   V I S U A L   R E D U N D A N C Y

\begin{figure}
  \centering
  \png{san-diego_chroma_subsampled}{1000}
  \caption{Visual effect of chroma subsamplig in the YCrCb domain. See
    this
    \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/06-YUV_compression/chroma_subsampling.ipynb}{notebook}.}
  \label{fig:san-diego_chroma_subsampled}
\end{figure}

\section{Perceptual video coding}
Hummans perceive distortion generated by the (lossy) compression
artifacts depending on the characteristics of the sequence. Therefore,
we can apply a coarser compression to image areas where the human
visual system is less sensitive to artifacts and a finer compression
otherwise.

\section{Motion estimation}
\begin{figure}
  \centering
  \png{stockholm_MVs_block}{800}
  \caption{Motion vectors to map ${\mathbf P}$ (which is divided into
    disjoint blocks) onto ${\mathbf R}$. See
    \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/09-ME/full_search_block_ME.ipynb}{this}.}
  \label{fig:MVs_block}
\end{figure}

As it can be seen in the Figure~\ref{fig:MVs_block}, the motion
information computed by a ME algorithm not always represents the true
motion in the scene in the case of using block-based matching. In
non-reliable transmission environments this issue also dificults the
prediction of the missing motion information. Notice also that the
entropy of the motion data increases. Therefore, in unreliable
decoding environments, OF estimators can provide motion fields with a
higher resilience to errors.

\section{To-Do}
Please, select one of the following tasks to develop:
\begin{enumerate}
\item
\end{enumerate}

\section{References}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{quantization,video_compression,rate_control,image_compression}
