% Emacs, this is -*-latex-*-

\input{../../definitions}
\title{\href{https://sistemas-multimedia.github.io/contents/perceptual_coding/}{Perceptual Coding}}

\maketitle
\tableofcontents

\section{What is perceptual coding?}

So far, we have focused on minimizing the
Lagrangian~\cite{sullivan1998rate}
\begin{equation}
  J = R + \lambda D,
  \label{eq:RD}
\end{equation}
where $R$ is the data rate, and $D$ is an additive\footnote{The total
distortion of two (or more) sources of distortion is the sum of the
distortions of these two (or more) sources.} distance metric, such as
the RMSE, the PSNR or the SSIM index~\cite{wang2004image}. However, the
way in which human beings perceive distortion is generally different
from how these metrics express it. This chapter introduces some of the
most common ways of exploiting the visual distortion perceived by
humans.

Notice that if, according to the requirements of the encoding process, $D$ is below
a Threshold of Noticeable Distortion (ToND), the RDO process described
by Eq.~\eqref{eq:RD} boilds down to select the option with smaller $R$.

\section{ToND varies with the luma intensity}

The
\href{https://en.wikipedia.org/wiki/Weber%E2%80%93Fechner_law}{Weber-Fechner law}
  states that the minimum perceivable visual stimulus difference
  increases with background luminance\footnote{In general, this is not
    true for the chroma.}~\cite{naccari2014perceptually}, up to a
  point in which it decreases. Therefore, the perception of the
  distortion generated by the lossy coding is smaller in areas
  (regions) with high and low intensity values. For this reason, one
  of the most used quantizers is the deadzone, which also in general
  changes signal noise (for example, electronic noise) by quantization
  noise, where the SNR of the signal is smaller (arround 0).

\section{ToND varies with the spatial frequency}
The
\href{https://en.wikipedia.org/wiki/Human_visual_system_model}{HVS}
can be modeled as a low-pass filter whose cut-off frequency depends on
the distance between the observer and the content (in terms of
frequency) of the visual stimulus.

Some DCT-based image and video coding standards, such as JPEG and
H.264, define quantization matrices designed for perceptual
coding~\cite{ernawan2014optimal}. These matrices indicate a different
quantization step size for each 8x8-DCT coefficient, whose values were
found through a study of the subjective impact of the quantization of
each coefficient in the ToND. In the case of H.264, such matrices can
change between images~\cite{naccari2014perceptually}.

In the case of JPEG2000, each subband uses a different quantization
step size~\cite{liu2020visibility}. However, note that these values
depend on the selected DWT filter.

\section{Visual masking of the quantization noise}

Quantization noise is generated by the quantizer, producing
different coding artifacts\footnote{``Random'' noise, blocking,
  ringing, etc.}, which are hardly perceived when the (area of the)
encoded image is textured~\cite{wu2017digital}. This effect can
occur until reaching the ToND.

Another important aspect of our perception is its directionality,
which leads the HVS to be more sensitive to distortions added to
horizontal and vertical frequencies than to diagonal
frequencies~\cite{naccari2014perceptually}. This basically means that,
for example, in the 2D-DWT domain, the subband HH can be more
severely quantized than the other subbands.

Finally, the rationale behind temporal masking is that the HVS
sensitivity to coding artifacts is lower in areas with very high
motion activity.

In video, modeling temporal masking is more challenging because the
spatio-temporal sensitivity function of the HVS is not separable,
i.e., it depends on both the spatial\footnote{Which in turn depends on
  the distance between the user and the display.} and temporal
frequencies~\cite{naccari2014perceptually}. However, sources of
distortion such as
\href{https://en.wikipedia.org/wiki/Compression_artifact#Mosquito_noise}{mosquito
  noise} can be hardly perceived in video because this type of noise
is temporally uncorrelated.

\section{Loop filters}

Loop filters are used in motion-compensated video codecs to improve
visual quality (and also the encoding RD performance). For example,
H.264/AVC uses (usually directional\footnote{Anisotropic.})
deblocking filters in the encoding loop to smooth the transitions
between the blocks, when the boundaries between them become
perceptible. Loop filters improve significantly the perceived quality
of the video in ``flat'' areas, where the blocking can be more easely
appreciated.

\section{Luma redundancy}

The HVS can perceive only a finite number of different
intensities. This number depends on the dynamic range of the pixels,
but, in general, we are unable to distinguish more than 64 intensity
values~\cite{vruiz__visual_redundancy}.

\section{Chroma redundancy}

Humans do not perceive (spatial) detail in chrominance as well as in
luminance~\cite{burger2016digital}. For this reason, the croma can be
downsampled to (for example) 1/4 of the original
\href{https://en.wikipedia.org/wiki/Sampling_(signal_processing)}{sampling
  rate} without noticeable distortion. This feature is used in most of
lossy image and video encoding algoritms.

\section{Resources}
\begin{enumerate}
\item \href{https://github.com/vicente-gonzalez-ruiz/color_transforms/blob/main/docs/color_redundancy.ipynb}{Spectral
    (color) redundancy}.
\end{enumerate}

\section{To-Do}
\begin{enumerate}
\item Modify the VCF compression pipeline to take advantage of the
  chroma redundancy. Use different quantization step sizes for each
  color subband, where applicable. Notice, however, that this
  functionality should be optional. Complexity 5.
\item A similar effect can be obtained if we perform a spatial
  low-pass filtering of the chromas and subsampling. Implement this
  optional functionality where possible. Complexity 8.
\item \texttt{2D-DCT.py} already implements the optional use of
  perceptual quantization matrices for the $8\times 8$-blocks
  case. Using an image resizing technique, use such matrices for
  applying perceptual coding for blocks of any size in
  $\{2\times 2, 4\times 4, \cdots, 2^n\times 2^n\}$. Complexity 4.
\item In the case of the 2D-DWT, we can exploit the lower sensitivity
  of the HVS to diagonal frequencies. This means that we can increase
  the quantization step size of the HH subbands (compared to the
  others) without noticeably increasing the perceived
  distortion. Complexity 4.
\item The
  \href{https://scikit-image.org/docs/stable/auto_examples/filters/plot_entropy.html}{local
    entropy} of the motion vectors can be a good estimation of the
  motion complexity in a video sequence. In a new motion compensated
  video codec, adapt the quantization step size to the local entropy,
  trying to increase the compression ratios without increasing the
  perceived distortion. Complexity 10.
\end{enumerate}

\section{References}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{image_processing,image_compression,video_compression,rate_control,JPEG,JPEG2000}
