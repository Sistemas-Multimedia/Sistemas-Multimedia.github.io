<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Sistemas Multimedia - Spatial Transforms</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'><a href='https://sistemas-multimedia.github.io/'>Sistemas Multimedia</a> - <a href='https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/spatial_transforms'>Spatial Transforms</a></h2>
 <div class='author'><a href='https://vicente-gonzalez-ruiz.github.io/'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es/universidad/departamentos/informatica'><span class='ecrm-1200'>Departamento de Informática</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es'><span class='ecrm-1200'>UAL</span></a></div><br />
<div class='date'><span class='ecrm-1200'>February 3, 2024</span></div>
   </div>
   <h3 class='likesectionHead'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#x1-20001' id='QQ2-1-2'>Spatial decorrelation</a></span>
<br />    <span class='sectionToc'>2 <a href='#x1-30002' id='QQ2-1-3'>Benefits of spatial transforms</a></span>
<br />    <span class='sectionToc'>3 <a href='#x1-40003' id='QQ2-1-4'>Scalar quantization and rate/distortion optimization in the transform domain</a></span>
<br />    <span class='sectionToc'>4 <a href='#x1-50004' id='QQ2-1-5'>Learned transforms</a></span>
<br />    <span class='sectionToc'>5 <a href='#x1-60005' id='QQ2-1-6'>2D-partitioning</a></span>
<br />    <span class='sectionToc'>6 <a href='#x1-80006' id='QQ2-1-8'>To-Do</a></span>
<br />    <span class='sectionToc'>7 <a href='#x1-90007' id='QQ2-1-9'>References</a></span>
   </div>
<!-- l. 43 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>1   </span> <a id='x1-20001'></a>Spatial decorrelation</h3>
<!-- l. 46 --><p class='noindent'>Spatial transforms used in image and video compression exploit the statistical correlation (and
perceptual redundancy<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-2001f1'></a>)
that the pixels show as a consequence of the spatial (2D) correlation. For example,
some areas of an image can occur more than once, and, usually, neighbor pixels tend
to have similar values.
</p><!-- l. 53 --><p class='indent'>   Spatial transforms are image-wise operators. This means that the transform
inputs an image of pixels and outputs a matrix of coefficients, which generally
express the resemblance between the image and a set of basis functions. For example,
after using the 2D-DCT <span class='cite'>[<a href='#Xvruiz__DCT'>2</a>]</span>, each coefficient represents a different spatial
frequency<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-2003f2'></a>
and its value, the amount of the corresponding basis found in the image. In the case
of the 2D-DWT <span class='cite'>[<a href='#Xvruiz__DWT'>3</a>]</span>, the coefficients “speak” additionally about a spatial resolution
and position.
                                                                  

                                                                  
</p><!-- l. 66 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>2   </span> <a id='x1-30002'></a>Benefits of spatial transforms</h3>
<!-- l. 69 --><p class='noindent'>Spatial transforms provide:
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-3002x1'><span class='ecbx-1000'>Energy   concentration:  </span>Usually,   a   small   set   of   (low-frequency)
     coefficients represents most of the information (energy) of the image. This
     decreases the entropy and increases the range of the quantization step
     sizes, because the dynamic range of the coefficients is higher than the
     dynamic range of the pixels.
     </li>
<li class='enumerate' id='x1-3004x2'><span class='ecbx-1000'>Low/High frequency analysis: </span>Our visual system is more sensitive to
     the low frequencies (for this reason, the <a href='https://en.wikipedia.org/wiki/Contrast_(vision)#Contrast_sensitivity'>contrast sensitiviy function</a> is not
     flat).
     </li>
<li class='enumerate' id='x1-3006x3'><span class='ecbx-1000'>Multiresolution:  </span>Depending  on  the  transform,  it  is  possible  to
     reconstruct the original image by resolution levels <span class='cite'>[<a href='#Xvruiz__DWT'>3</a>]</span>.</li></ol>
<!-- l. 87 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>3   </span> <a id='x1-40003'></a>Scalar quantization and rate/distortion optimization in the transform
domain</h3>
<!-- l. 90 --><p class='noindent'>Scalar quantization is efficient in the transform domain because the coefficients are
decorrelated. The next logical step (after quantization) is the entropy coding of the
quantization indexes. Here, depending on how the coefficients are quantized, we can
trace different RD curves (all of them starting (and finising) in the same distortion).
For example, if we compress each subband independently, we must find the
quantization step sizes that select the same slope in the RD curve of each
subband <span class='cite'>[<a href='#Xvruiz__information_theory'>4</a>]</span>.
                                                                  

                                                                  
</p><!-- l. 101 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>4   </span> <a id='x1-50004'></a>Learned transforms</h3>
<!-- l. 104 --><p class='noindent'>Using machine learning techniques (for example, with an artificial neural network), it
is possible to build a machine-krafted transform, specifically tuned for some
type of images, or at least, capable of determining specific features in the
images.
</p><!-- l. 109 --><p class='indent'>   Potentially, learned-based image (and video) compressors are adaptive
algorithms that can be more efficient than those in which the transforms are
pre-defined.
</p><!-- l. 115 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>5   </span> <a id='x1-60005'></a>2D-partitioning</h3>
<!-- l. 117 --><p class='noindent'>Depending on the content of the image, it can be necessary to divide the image into
2D chunks (usually called <span class='ecti-1000'>tiles </span>or <span class='ecti-1000'>blocks</span>), and encode each chunk independently. In
general:
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-6002x1'>Tiles are used when the image is made up of very different areas (for
     example, text and natural images). Tiles are usually rectangular but can
     have any size, and are usually defined attending to perceptual issues (for
     example, text is not well compressed by lossy configurations).
     </li>
<li class='enumerate' id='x1-6004x2'>Blocks are smaller than tiles and, in most of cases, squared. The block
     partition can be adaptive and, in this case, should be found using RDO.</li></ol>
<!-- l. 131 --><p class='noindent'>
</p>
   <h3 class='likesectionHead'><a id='x1-7000'></a>Resources</h3>
<!-- l. 134 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-7002x1'>Use of <a href='https://github.com/Sistemas-Multimedia/VCF/blob/main/src/DWT.py'>2D-DWT in VCF</a>.
                                                                  

                                                                  
     </li>
<li class='enumerate' id='x1-7004x2'><a href='https://github.com/vicente-gonzalez-ruiz/DCT2D/blob/master/src/DCT2D/YCoCg_2D_DCT_SQ.ipynb'>Image Compression with YCoCg + 2D-DCT</a>.
     </li>
<li class='enumerate' id='x1-7006x3'><a href='https://www.tensorflow.org/tutorials/generative/data_compression'>Learned data compression</a>.
     </li>
<li class='enumerate' id='x1-7008x4'><a href='https://github.com/vicente-gonzalez-ruiz/learned_image_compression/blob/main/LIC.ipynb'>Learned Image Compression (LIC) using auto-encoders</a>.
     </li>
<li class='enumerate' id='x1-7010x5'><a href='https://github.com/fchollet/deep-learning-with-python-notebooks'>Companion  Jupyter  notebooks  for  the  book  “Deep  Learning  with
     Python”</a> <span class='cite'>[<a href='#Xchollet2021deep'>1</a>]</span>.</li></ol>
<!-- l. 153 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>6   </span> <a id='x1-80006'></a>To-Do</h3>
<!-- l. 156 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-8002x1'>Modify VCF to use the block-based 2D-DCT in the compression pipeline.
     Complexity 3.
     </li>
<li class='enumerate' id='x1-8004x2'>Using RDO, determine the optimal block sizes in the 2D-DCT-based image
     compressor. Implement such a codec in VCF. Complexity 4.
     </li>
<li class='enumerate' id='x1-8006x3'>Modify VCF to use an autoencoder (at the image level) in the compression
     pipeline. Complexity 5.
                                                                  

                                                                  
     </li>
<li class='enumerate' id='x1-8008x4'>Autoencoders can be used in the transform domain. Modify VCF to use
     an autoencoder with a small input to compress the 2D-DWT transform of
     an image. Notice that in this case, the parameters of the neural network
     could be sent with the code-stream. Complexity 6.
     </li>
<li class='enumerate' id='x1-8010x5'>If the right coefficients in the DWT domain are multiplied by a power of 2
     before quantization, we can define a ROI of arbitrary shape at compression
     time <span class='cite'>[<span class='ecbx-1000'>?</span>]</span>. Include this possibility in the DWT-based compression pipeline
     of VCF.</li></ol>
<!-- l. 177 --><p class='noindent'>
</p>
   <h3 class='sectionHead'><span class='titlemark'>7   </span> <a id='x1-90007'></a>References</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xchollet2021deep'></a>Francois Chollet. <a href='https://docs.google.com/viewer?a=v&amp;pid=sites&amp;srcid=dW10LmVkdS5wa3xzbmxwfGd4Ojc1ODc1ODY2OTZiOTUzOGQ'><span class='ecti-1000'>Deep learning with Python</span></a>. Simon and Schuster, 2021.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='Xvruiz__DCT'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/DCT'>The DCT (Discrete Cosine Transform)</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [3]<span class='bibsp'>   </span></span><a id='Xvruiz__DWT'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/DWT'>The DWT (Discrete Wavelet Transform)</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [4]<span class='bibsp'>   </span></span><a id='Xvruiz__information_theory'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/information_theory'>Information Theory</a>.
</p>
   </div>
   <div class='footnotes'><a id='x1-2002x1'></a>
<!-- l. 48 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>We will see this later in this course.</span></p><a id='x1-2004x1'></a>
<!-- l. 59 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>That depends on the position of the coefficient in the transformed domain.</span></p>             </div>
 
</body> 
</html>