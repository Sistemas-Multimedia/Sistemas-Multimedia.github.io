% Emacs, this is -*-latex-*-

% TODO: In the DWT domain, use block-based neural compression using autoencoders

% https://stackabuse.com/autoencoders-for-image-reconstruction-in-python-and-keras/
% https://github.com/FireFYF/modulatedautoencoder
% https://www.tensorflow.org/tutorials/generative/data_compression
% https://www.youtube.com/watch?v=x_q7cZviXkY ( PCS 2018 – Learned Image Compression )
% https://keras.io/examples/generative/vq_vae/
% https://jhui.github.io/2017/03/06/Variational-autoencoders/
% https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2
% https://deepai.org/machine-learning-glossary-and-terms/prior-probability
% https://towardsdatascience.com/auto-regressive-generative-models-pixelrnn-pixelcnn-32d192911173
% https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w50/Le_Tan_DeepVQ_A_Deep_CVPR_2018_paper.pdf
% https://www.deeplearningbook.org/
% https://arxiv.org/pdf/1711.00937.pdf (Neural Discrete Representation Learning)
% https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vq_vae.ipynb (Vector-Quantized Variational Autoencoders)
% https://www.tensorflow.org/tutorials/generative/autoencoder
% https://blog.paperspace.com/autoencoder-image-compression-keras/
% https://www.analyticsvidhya.com/blog/2021/06/complete-guide-on-how-to-use-autoencoders-in-python/
% https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb
% https://blog.keras.io/building-autoencoders-in-keras.html
% https://keras.io/examples/generative/vae/
% https://arxiv.org/pdf/1611.01704.pdf (END-TO-END OPTIMIZED IMAGE COMPRESSION)
% https://www.tensorflow.org/tutorials/generative/data_compression
% https://www.researchgate.net/profile/Asma-Salem-4/publication/319764377_Image_Compression_Using_Wavelet_and_Subband_Based_Transform/links/59bbe3d2458515e9cfc79d0d/Image-Compression-Using-Wavelet-and-Subband-Based-Transform.pdf
% https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/resources/lecture-31-change-of-basis-image-compression/
% https://arxiv.org/abs/1908.08988 (Neural Image Compression and Explanation)
% https://arxiv.org/abs/2011.03029 (CompressAI: a PyTorch library and evaluation platform for end-to-end compression research)
% https://heartbeat.comet.ml/a-2019-guide-to-deep-learning-based-image-compression-2f5253b4d811
% https://scelesticsiva.github.io/assets/image_compression_report.pdf
% https://interdigitalinc.github.io/CompressAI/intro.html
% https://arxiv.org/abs/1802.01436 (Variational image compression with a scale hyperprior)
% 

\input{../../definitions}
\title{\SM{} - Spatial Transforms}

\maketitle

\tableofcontents

\section{Spatial decorrelation}
%{{{

Spatial transforms used in image and video compression exploit the
statistical correlation (and perceptual redundancy\footnote{We will
see this later in this course.}) that the pixels show as a consequence
of the spatial (2D) correlation. For example, some areas of an image
can occur more than once, and usually, neighbor pixels tend to have
similar values.

Spatial transforms are image-wise operators. This means that the
transform inputs an image of pixels and output a matrix of
coefficients, which generally express the resemblance between the
image and a set of basis function. For example, after using the
DCT~\cite{vruiz__DCT}, each (index) coefficient represents a different
frequency and its value, the amount of the corresponding basis found
in the image. In the case of the DWT~\cite{vruiz__DWT}, the index of
the coefficients ``speaks'' also about a spatial resolution and
position.

%}}}

\section{Benefits of spatial transforms}
%{{{

Spatial transforms provide:
\begin{enumerate}
\item \textbf{Energy concentration:} A small set of (usually
  low-frequency) coefficients (in general) represents most of the
  information (energy) of the image. This decreases the entropy and
  increases the range of the quantization step sizes, because the
  dynamic range of the coefficients is higher than the dynamic range
  of the pixels.
\item \textbf{Low/High frequency analysis:} Our visual system is more
  sensitive to the low frequencies (for this reason, the
  \href{https://en.wikipedia.org/wiki/Contrast_(vision)#Contrast_sensitivity}{contrast
    sensitiviy function} is not flat.
\item \textbf{Multiresolution:} Depending on the transform, it is
  possible to reconstruct the original image by resolution
  levels~\cite{vruiz__DWT}.
\end{enumerate}

%}}}

\section{Scalar quantization and rate/distortion optimization in the transform domain}
%{{{

Scalar quantization is efficient in the transform domain because the
coefficients are decorrelated. The next logical step (after
quantization) is the entropy coding of the quantization indexes. Here,
depending on how the coefficients are quantized we can trace different
RD curves (all of them starting (and finising) in the same
distortion). For example, if we compress each subband independently,
we must find the quantization step sizes that select the same slope in
the RD curve of each subband.

%}}}

\section{Learned transforms}
%{{{

Using machine learning techniques (for example, with an artificial
neural network), it is possible to build a machine-krafted transform,
specifically tuned for some type of images, or at least, capable of
determining specific features in the images.

%}}}

\section{Image partitioning}

Depending on the content of the image, it can be necessary to divide
the image into tiles or blocks, and apply the encoding to each block,
independently. Usually:
\begin{enumerate}
\item Tiles are used when the image is made up of very different areas
  (for example, text and natural images). Tiles are usually
  rectangular but can have any size, and are usually defined attending
  to perceptual issues (for example, text is not well compressed by
  lossy configurations).
\item In general, blocks are smaller than tiles and usually
  squared. The block partition can be adaptive and should be found
  using RDO.
\end{enumerate}

\section{Resources}
%{{{

\begin{enumerate}
\item \href{https://github.com/Sistemas-Multimedia/VCF/blob/main/src/DWT2D.py}{2D-DWT in VCF}.
\item
  \href{https://github.com/vicente-gonzalez-ruiz/DCT/blob/master/docs/YCoCg_2D_DCT_SQ.ipynb}{Image
    Compression with YCoCg + 2D-DCT}.
\item
  \href{https://www.tensorflow.org/tutorials/generative/data_compression}{Learned
    data compression}.
\item
  \href{https://github.com/vicente-gonzalez-ruiz/learned_image_compression/blob/main/LIC.ipynb}{Learned
    Image Compression (LIC) using autoencoders}.
\item
  \href{https://github.com/fchollet/deep-learning-with-python-notebooks}{Companion
    Jupyter notebooks for the book ``Deep Learning with
    Python''}~\cite{chollet2021deep}.
\end{enumerate}

%}}}

\section{To-Do}
%{{{

\begin{enumerate}
\item Modify VCF to use the block-based 2D-DCT in the compression pipeline. Complexity 3.
\item Using RDO, determine the optimal block sizes in the DCT-based
  image compressor. Implement such codec in VCF. Complexity 4.
\item Modify VCF to use an autoencoder (at the image level) in the compression pipeline. Complexity 5. 
%\item Modify CVF to use SPIHT.
\end{enumerate}

%}}}

\section{References}
%{{{

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{projects,signal_processing,neural_nets}

%}}}

\begin{comment}

\section{Tight Laplacian Pyramid Transform (TLPT)}
%{{{

Pyramid frames were introduced in 1983 by Burt and Adelson. In some
way, they can be considered one of the precursors of the wavelet
octave band decompositions.

Technically, the LPT is a frame expansion, that generates an expanded
octave-band decomposition. The ratio of redundancy in the
decomposition $R\rightarrow 2$ with the number of levels.

Because the shift invariance, MC can be incorporated in the enhancememt layer.

The LP with orthogonal filter is a tight frame.

%}}}

\section{Critially Sampled LPT (CS-LPT)}
%{{{

Technically, the LPT is a frame expansion, that generates an expanded
octave-band decomposition. The ratio of redundancy in the
decomposition $R\rightarrow 2$ with the number of DWT levels.

The 2D-DWT can a used on sequences of images, by simply iterating as
it is described in the Algorithm~\ref{alg:MDWT}. $I$ is the number of
images in the sequence $V$.

\begin{pseudocode}{\text{MDWT}}{V}
  \label{alg:MDWT}
  \FOR i \GETS 0 \TO I-1 \DO
  V_i = \text{2D-DWT}(V_i)
\end{pseudocode}

%}}}

\section{Autoencoder Latent Representation}
%{{{

% Johannes Ballé, Valero Laparra, and Eero P. Simoncelli. 2017. End-to-end Optimized Image Compression. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017

In ANN-based image compression, an autoencoder can be used to find the
latent representation of an (input) image. The compressor is the first
part of the autoencoder and the decompressor is the second
part. During the compression, the latent representation is quantized
and entropy compressed.

%}}}

\end{comment}

