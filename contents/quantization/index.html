<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Sistemas Multimedia - Digital (Re-)Quantization</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'><a href='https://sistemas-multimedia.github.io/'>Sistemas Multimedia</a> - Digital
(Re-)Quantization</h2>
 <div class='author'><a href='https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es/universidad/departamentos/informatica'><span class='ecrm-1200'>Departamento de Informática</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es'><span class='ecrm-1200'>UAL</span></a></div><br />
<div class='date'><span class='ecrm-1200'>December 15, 2022</span></div>
   </div>
   <h3 class='likesectionHead' id='contents'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#what-is-quantization' id='QQ2-1-2'>What is quantization?</a></span>
<br />    <span class='sectionToc'>2 <a href='#what-is-digital-requantization' id='QQ2-1-3'>What is digital (re-)quantization?</a></span>
<br />    <span class='sectionToc'>3 <a href='#basic-terminology' id='QQ2-1-4'>Basic terminology</a></span>
<br />    <span class='sectionToc'>4 <a href='#a-classification-of-quantizers' id='QQ2-1-5'>A classification of quantizers</a></span>
<br />     <span class='subsectionToc'>4.1 <a href='#scalar-quantizers-sq-vs-vector-quantizers-vq' id='QQ2-1-6'>Scalar quantizers (SQ) VS Vector Quantizers (VQ)</a></span>
<br />     <span class='subsectionToc'>4.2 <a href='#uniform-vs-nonuniform-quantizers' id='QQ2-1-7'>Uniform VS non-uniform quantizers</a></span>
<br />     <span class='subsectionToc'>4.3 <a href='#static-vs-adaptive-quantizers' id='QQ2-1-8'>Static VS adaptive quantizers</a></span>
<br />    <span class='sectionToc'>5 <a href='#deazone-quantization' id='QQ2-1-9'>Deazone quantization</a></span>
<br />    <span class='sectionToc'>6 <a href='#lloydmax-quantization' id='QQ2-1-11'>Lloyd-Max quantization</a></span>
<br />    <span class='sectionToc'>7 <a href='#vector-quantization' id='QQ2-1-13'>Vector quantization</a></span>
<br />    <span class='sectionToc'>8 <a href='#the-ratedistortion-rd-curve' id='QQ2-1-15'>The Rate/Distortion (RD) curve</a></span>
<br />    <span class='sectionToc'>9 <a href='#todo' id='QQ2-1-16'>To-Do</a></span>
<br />    <span class='sectionToc'>10 <a href='#references' id='QQ2-1-17'>References</a></span>
   </div>
<!-- l. 11 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='what-is-quantization'><span class='titlemark'>1   </span> <a id='x1-20001'></a>What is quantization?</h3>
<!-- l. 13 --><p class='noindent'>In information theory <span class='cite'>[<a href='#Xvruiz__information_theory'>1</a>]</span>, quantization is any mapping process between two sets of
elements \(A\) and \(B\), where all the elements of \(A\) are associated to one (not necessarily the
                                                                  

                                                                  
same) element of \(B\), and happens that \(|A|&gt;|B|\), \(|\cdot |\) representing the order (the number of
elements) of a set.
</p><!-- l. 19 --><p class='indent'>   Notice that if \(|A|&gt;|B|\), quantization is an irreversible process because two o more
elements of \(A\) will be mapped to the same element of \(B\), and there is not way to find the
reverse mapping.
</p><!-- l. 23 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='what-is-digital-requantization'><span class='titlemark'>2   </span> <a id='x1-30002'></a>What is digital (re-)quantization?</h3>
<!-- l. 25 --><p class='noindent'>In digital quantization <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>, <a href='#Xvruiz__vector_quantization'>4</a>]</span>, the elements of \(A\) and \(B\) are digital samples of a signal <span class='cite'>[<a href='#Xvruiz__signal_quantization'>3</a>]</span>.
Since, by definition, a digital sample has been quantized to be converted from the
analog world to the digital one, we are actually appliying a re-quantization to the
signal. Again, such digital quantization implies a loss of information in the
re-quantized signal.
</p><!-- l. 34 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='basic-terminology'><span class='titlemark'>3   </span> <a id='x1-40003'></a>Basic terminology</h3>
<!-- l. 36 --><p class='noindent'>Several types of quantizers divide the range of possible values that the samples can
take into a collection of non-overlapped intervals. The values that define such
intervals are called <span class='ecti-1000'>decision levels </span>and the value that in the quantized domain
represents to all the input posible values that fall in a interval is called the
<span class='ecti-1000'>representation level </span>of the interval.
</p><!-- l. 43 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='a-classification-of-quantizers'><span class='titlemark'>4   </span> <a id='x1-50004'></a>A classification of quantizers</h3>
<!-- l. 45 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='scalar-quantizers-sq-vs-vector-quantizers-vq'><span class='titlemark'>4.1   </span> <a id='x1-60004.1'></a>Scalar quantizers (SQ) VS Vector Quantizers (VQ)</h4>
<!-- l. 47 --><p class='noindent'>When quantization maps single elments of \(A\) to single elements of \(B\), the quantizer is
said scalar <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>]</span>. When tuples of elements are mapped, vector quantization is being
used <span class='cite'>[<a href='#Xvruiz__vector_quantization'>4</a>]</span>.
</p><!-- l. 53 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='uniform-vs-nonuniform-quantizers'><span class='titlemark'>4.2   </span> <a id='x1-70004.2'></a>Uniform VS non-uniform quantizers</h4>
                                                                  

                                                                  
<!-- l. 55 --><p class='noindent'>In an uniform quantizer <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>]</span>, the size of all the intervals is equal to the quantization
step size, which is usually represented by \(\Delta \). In a non-uniform quantizer <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>]</span>, at
least one of the intervals is different to the rest. For example, a deadzone
quantizer <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>]</span> has a interval size for the representation level 0 that doubles
the size of the rest of intervals. For this reason, a deadzone quantizer is a
non-uniform quantizer. Another example of a non-uniform quantizer is the
Lloyd-Max quantizer because it divides the range of input values in a set of
intervals whose size is inversely proportional to the probability of using such
interval.
</p><!-- l. 68 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='static-vs-adaptive-quantizers'><span class='titlemark'>4.3   </span> <a id='x1-80004.3'></a>Static VS adaptive quantizers</h4>
<!-- l. 70 --><p class='noindent'>Static quantizers do not modify the partitioning of the input signal’s dynamic range,
nor the representation level assigned to each interval. On the contrary, adaptive
quantizers adapt to the sequence of samples that are quantized. A Jayant quantizer is
a example of adaptative quantization.
</p><!-- l. 76 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='deazone-quantization'><span class='titlemark'>5   </span> <a id='x1-90005'></a>Deazone quantization</h3>
<!-- l. 78 --><p class='noindent'>Deadzone quantizers <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>]</span> are static quasi-uniform scalar quantizers. These
are used frequently in lossy compression systems because: (1) when the
quantization step size is a power of two, and (2) the input sample values are
integers<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-9001f1'></a>,
then the representation levels can be found by simply discarding low-significant bits
of the input samples (in other words, we only need to perform a bit-shift operation to
find the corresponding quantization index).
</p><!-- l. 88 --><p class='indent'>   Another reason that makes deadzone quantization popular in lossy encoding
systems is that tends to remove electronic noise more than other scalar quantizers
where the signal is weaker. If we supose that the signal has 0 average (the electronic
noise has 0 average and a flat spectrum) and that the deadzone is placed where the
SNR is smaller, we are basically replacing electronic noise by quantization noise.
Obviously, this does not improve the RD performance of the encoder, but the
perceived (subjective) quality is increased for the same bit-rate (if the electronic noise
is perceived as a source of distortion).
</p><!-- l. 99 --><p class='noindent'>
</p>
   <h4 class='likesubsectionHead' id='resources'><a id='x1-100005'></a>Resources</h4>
<!-- l. 100 --><p class='noindent'>
                                                                  

                                                                  
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-10002x1'><a href='https://github.com/Sistemas-Multimedia/VCF/blob/main/src/deadzone.py'>Deadzone Quantization in VCF</a>.</li></ol>
<!-- l. 106 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='lloydmax-quantization'><span class='titlemark'>6   </span> <a id='x1-110006'></a>Lloyd-Max quantization</h3>
<!-- l. 108 --><p class='noindent'>A Lloyd-Max quantizer <span class='cite'>[<a href='#Xvruiz__scalar_quantization'>2</a>]</span> minimizes the quantization noise given a signal with a
known probabilistic distribution (histogram) of the input samples and a number of
quantization intervals. As a result, the density of quantization intervals is higher
where the probability of the samples is higher, and viceversa.
</p><!-- l. 115 --><p class='indent'>   Notice that the histogram must be also known by the decoder to
“restore”<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-11001f2'></a>
the information.
</p><!-- l. 120 --><p class='noindent'>
</p>
   <h4 class='likesubsectionHead' id='resources1'><a id='x1-120006'></a>Resources</h4>
<!-- l. 122 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-12002x1'><a href='https://github.com/Sistemas-Multimedia/VCF/blob/main/src/LloydMax.py'>A partial implementation in VCF</a>.</li></ol>
<!-- l. 128 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='vector-quantization'><span class='titlemark'>7   </span> <a id='x1-130007'></a>Vector quantization</h3>
<!-- l. 130 --><p class='noindent'>Vector quantizers <span class='cite'>[<a href='#Xvruiz__vector_quantization'>4</a>]</span> input (usually squared, in the case of images) blocks of samples
and output a quantization index per block. In most of natural images, the spatial
correlation <span class='cite'>[<a href='#Xvruiz__visual_redundancy'>5</a>]</span> generates that some blocks of the image are similar to other blocks. If
this is true, we can compute a set of (block) centroids and use them to represent the
original blocks. As a result, we will obtain an matrix of quantization indexes that can
be entropy coded.
</p><!-- l. 139 --><p class='indent'>   Notice that VQ exploits the spatial correlation. For this reason, the encoding
performance of a vector quantizer is superior compared to a scalar quantizer
because the number of quantization indexes (indexes of the centroids) is
smaller.
                                                                  

                                                                  
</p><!-- l. 144 --><p class='noindent'>
</p>
   <h4 class='likesubsectionHead' id='resources2'><a id='x1-140007'></a>Resources</h4>
<!-- l. 146 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-14002x1'><a href='https://scikit-learn.org/stable/auto_examples/cluster/plot_face_compress.html#sphx-glr-auto-examples-cluster-plot-face-compress-py'>Vector Quantization Example</a>.
     </li>
<li class='enumerate' id='x1-14004x2'><a href='https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/gray_VQ/gray_VQ.ipynb'>Vector Quantization (in the 2D domain) of a gray-scale image</a>.
     </li>
<li class='enumerate' id='x1-14006x3'><a href='https://github.com/vicente-gonzalez-ruiz/image_vector_quantization_LBG'>Image compression using LBG</a>.</li></ol>
<!-- l. 154 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='the-ratedistortion-rd-curve'><span class='titlemark'>8   </span> <a id='x1-150008'></a>The Rate/Distortion (RD) curve</h3>
<!-- l. 156 --><p class='noindent'>The gray-scale values or the \(\text {RGB}\) components of an image (and therefore, of a sequence of
images) can be quantized and compressed using some entropy encoder, generating a
set of points in the RD space. Such set usually form the so called RD curve in terms
of RMSE (between the original image and its reconstruction) and the bit-rate
achieved by the entropy codec.
</p><!-- l. 163 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='todo'><span class='titlemark'>9   </span> <a id='x1-160009'></a>To-Do</h3>
<!-- l. 164 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-16002x1'>Modify  VCF  to  allow  the  use  of  Lloyd-Max  quantization  in  the
     compression pipeline. Notice that VCF already implements this quantizer,
     but compression pipeline has not been continued. You must implement a
     complete pipeline (at least for compressing images). Complexity 2.
                                                                  

                                                                  
     </li>
<li class='enumerate' id='x1-16004x2'>Modify VCF to allow the use of VQ (applied to the spatial domain) in
     the compression pipeline. Notice that VQ used in the spatial domain can
     significantly minimize the advantage of using a spatial transform. For this
     reason, it can be useful to implement also “fake” spatial transform where
     no transformation is performed at all. Complexity 3.</li></ol>
<!-- l. 178 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='references'><span class='titlemark'>10   </span> <a id='x1-1700010'></a>References</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xvruiz__information_theory'></a>V. González-Ruiz. <a href='https://vicente-gonzalez-ruiz.github.io/information_theory/'>Information Theory</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='Xvruiz__scalar_quantization'></a>V. González-Ruiz. <a href='https://vicente-gonzalez-ruiz.github.io/scalar_quantization/'>Scalar Quantization</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [3]<span class='bibsp'>   </span></span><a id='Xvruiz__signal_quantization'></a>V. González-Ruiz. <a href='https://vicente-gonzalez-ruiz.github.io/signal_quantization/'>Signal Quantization</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [4]<span class='bibsp'>   </span></span><a id='Xvruiz__vector_quantization'></a>V. González-Ruiz. <a href='https://vicente-gonzalez-ruiz.github.io/vector_quantization/'>Vector Quantization</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [5]<span class='bibsp'>   </span></span><a id='Xvruiz__visual_redundancy'></a>V. González-Ruiz. <a href='https://vicente-gonzalez-ruiz.github.io/visual_redundancy/'>Visual Redundancy</a>.
</p>
   </div>
   <div class='footnotes'><!-- l. 83 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>And negative integers are represented using two’s complement.</span></p>
<!-- l. 118 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>Remember that quantization is a irreversible process and therefore, never is restores the
</span><span class='ecrm-0800'>original signal (except if the signal is digital and</span> \(\Delta =1\)<span class='ecrm-0800'>).</span></p>                                                       </div>
 
</body> 
</html>