% Emacs, this is -*-latex-*-

% https://web.stanford.edu/class/ee398a/handouts/lectures/05-Quantization.pdf

\input{../../definitions}

\title{\SM{} - \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/quantization}{Digital (Re-)Quantization}}

\maketitle

\tableofcontents

\section{What is quantization?}

In information theory~\cite{vruiz__information_theory},
quantization~\cite{vruiz__signal_quantization,vruiz__scalar_quantization,vruiz__vector_quantization,vruiz__trellis_quantization}
is any mapping process between two sets of elements $A$ and $B$, where
all the elements of $A$ are associated with one (not necessarily the
same) element of $B$, and happens that $|A|>|B|$, $|\cdot|$
representing the order (the number of elements) of a set.

Notice that if $|A|>|B|$, quantization is an irreversible process
because two o more elements of $A$ will be mapped to the same element
of $B$, and there is no a way to find the reverse mapping.

\section{What is digital (re-)quantization?}

In digital
quantization~\cite{vruiz__scalar_quantization,vruiz__vector_quantization},
the elements of $A$ and $B$ are digital samples of a
signal~\cite{vruiz__signal_quantization}. Since, by definition, a
digital sample has been quantized to be converted from the analog
world to the digital one, we are actually applying a re-quantization
to the signal. Again, such digital quantization implies a loss of
information in the re-quantized signal.

\section{Basic terminology}

Several types of quantizers divide the range of possible values that
the samples can take into a collection of non-overlapped
intervals. The values that define such intervals are called
\emph{decision levels} and the value that in the quantized domain
represents to all the input possible values that fall in an interval is
called the \emph{representation level} of the interval.

\section{A classification of quantizers}

\subsection{Scalar quantizers (SQ) VS Vector Quantizers (VQ)}

When quantization maps single elements of $A$ to single elements of
$B$, the quantizer is said
\emph{scalar}~\cite{vruiz__scalar_quantization}. When tuples of
elements are mapped, VQ is being
used~\cite{vruiz__vector_quantization}.

\subsection{Uniform VS non-uniform quantizers}

In an uniform quantizer~\cite{vruiz__scalar_quantization}, the size of
all the intervals is equal to the quantization step size, which is
usually represented by $\Delta$.\footnote{In an uniform quantizer, the
distance between all the decision levels is $\Delta$.} In a
non-uniform quantizer~\cite{vruiz__scalar_quantization}, at least one
of the intervals is different to the rest. For example, a deadzone
quantizer~\cite{vruiz__scalar_quantization} has a interval size for
the representation level 0 that doubles the size of the rest of
intervals. For this reason, a deadzone quantizer is a non-uniform
quantizer. Another example of a non-uniform quantizer is a Lloyd-Max
quantizer because it divides the range of input values in a set of
intervals whose size is inversely proportional to the probability of
using such interval.

\subsection{Static VS adaptive quantizers}

Static quantizers do not modify the partitioning of the input signal's
dynamic range (the decision levels), nor the representation level
assigned to each interval. On the contrary, adaptive quantizers adapt
to the sequence of samples that are quantized during the quantization
process.\footnote{If the quantizer depends on the characteristics of
the signal but there are known \emph{a priori}, it should be
considered static.} A Jayant
quantizer~\cite{vruiz__scalar_quantization} is a example of adaptive
quantization.

\section{Deadzone quantization}

Deadzone quantizers~\cite{vruiz__scalar_quantization} are static
quasi-uniform scalar quantizers. These are used frequently in lossy
compression systems because when the quantization step size is a power
of two, and the input sample values are integers\footnote{And negative
integers are represented using two's complement.}, then the
representation levels can be found by simply discarding
low-significant bits of the input samples (in other words, we only
need to perform a bit-shift operation to find the corresponding
quantization index). This also means that it is possible to build a
progressive encoding system using a deadzone quantizer.

Another reason that makes deadzone quantization popular in lossy
encoding systems is that tends to remove electronic noise more than
other scalar quantizers where the signal is weaker. If we suppose that
the signal has 0 average\footnote{The electronic noise has 0 average
and a flat spectrum.} and that the deadzone is placed where the SNR is
smaller, we are basically replacing electronic noise by quantization
noise. Obviously, this does not improve the RD performance of the
encoder, but the perceived (subjective) quality is increased for the
same bit-rate.\footnote{Obviously, if the electronic noise is
perceived as a source of distortion}

\subsection*{Resources}
\begin{enumerate}
\item
  \href{https://github.com/Sistemas-Multimedia/VCF/blob/main/src/deadzone.py}{Deadzone
    Quantization in VCF}.
\end{enumerate}

\section{Lloyd-Max quantization}

A Lloyd-Max quantizer~\cite{vruiz__scalar_quantization} minimizes the
quantization noise given a signal with a known probabilistic
distribution (histogram) of the input samples and a number of
quantization intervals. As a result, the density of quantization
intervals is higher where the probability of the samples is higher, and
vice-versa.

Lloyd-Max quantizers are considered non-uniform quantizers. Notice
that the histogram must be also known by the decoder to
``restore''\footnote{Remember that quantization is a irreversible
process and therefore, never is restored the original signal (except
if $\Delta=1$).} the information.

\subsection*{Resources}

\begin{enumerate}
\item
  \href{https://github.com/Sistemas-Multimedia/VCF/blob/main/src/LloydMax.py}{A
    partial implementation in VCF}.
\end{enumerate}

\section{Vector quantization}

Vector quantizers~\cite{vruiz__vector_quantization} input
blocks\footnote{If we are removing spatial redundancy, the blocks are
usually squared tiles of pixels. If we are removing color redundancy,
the blocks are multicomponent pixels.} of samples and output a
quantization index per block. For example, in most of natural images,
the spatial correlation~\cite{vruiz__visual_redundancy} generates that
some blocks of the image are similar to other blocks. If this is true,
we can compute a set of centroids (blocks) and use them to represent
the original blocks. As a result, we will obtain a matrix of
quantization indexes that can be entropy coded.

Notice that VQ exploits the spatial correlation. For this reason, the
encoding performance of a vector quantizer is superior compared to a
scalar quantizer because the number of quantization indexes (indexes
of the centroids) is smaller.

\section*{Resources}

\begin{enumerate}
\item
  \href{https://scikit-learn.org/stable/auto_examples/cluster/plot_face_compress.html#sphx-glr-auto-examples-cluster-plot-face-compress-py}{Vector
    Quantization Example}.
\item
  \href{https://github.com/vicente-gonzalez-ruiz/vector_quantization/blob/main/docs/gray_VQ.ipynb}{Vector
    Quantization (in the 2D domain) of a gray-scale image}.
\item
  \href{https://github.com/vicente-gonzalez-ruiz/vector_quantization/blob/main/docs/spatial_color_VQ.ipynb}{Vector
    Quantization (in the 2D domain) of a color (RGB) image}.
  
\item \href{https://github.com/droidadroit/LBG}{Image compression using LBG}.
\end{enumerate}

\section{To-Do}
\begin{enumerate}
\item Modify VCF to allow the use of Lloyd-Max quantization in the
  compression pipeline. Notice that VCF already implements this
  quantizer, but the compression pipeline is unfinished. You must
  implement a complete pipeline (at least for compressing
  images). Complexity 2.
\item Modify VCF to allow the use of VQ (applied to the spatial
  domain) in the compression pipeline. Notice that VQ used in the
  spatial domain can significantly minimize the advantage of using a
  spatial transform. For this reason, it can be useful to implement
  also ``fake'' spatial transform where no transformation is performed
  at all. The same happens when VQ is used in the color
  domain. Complexity 4.
\end{enumerate}

\section{References}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{quantization,perception,information_theory}
