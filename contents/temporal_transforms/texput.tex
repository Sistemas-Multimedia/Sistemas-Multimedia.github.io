% Emacs, this is -*-latex-*-

% https://vcgit.hhi.fraunhofer.de/jvet
% https://www.etsist.upm.es/uploaded/392/02_Video_Compression_Basics_MPEG1_MPEG2_MPEG4.pdf

\input{../../definitions}
\title{\SM{} - \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/temporal_transforms}{Temporal Transforms}}

\maketitle
\tableofcontents

\section{Temporal correlation}
%{{{

In general, neighbour \emph{frames} (images) in (video)
\emph{sequences} exhibit a high temporal correlation that can be
exploited to increase the compression ratios. This correlation
generates a temporal redundancy that can be removed using a (temporal)
transformation.

A temporal transform inputs two o more frames\footnote{With pixels or
  coefficients, depending on the current domain of the frame. Notice,
  for example, that if the frame is in the DWT domain, we should refer
  to it as a ``decomposition'' instead of as a ``frame''.}, and
outputs at least one \emph{residual} (frame) in which the residual
pixels have a higher dynamic range but also a smaller entropy. This
potentially increases the compression ratios (in the case of video,
usually measures in kbps).

%}}}

\section{Motion compensation}
%{{{

Most video coding standards use
\href{https://en.wikipedia.org/wiki/Motion_compensation}{Motion
  Compensation (MC)} to generate the residual
frames~\cite{vruiz__MC}. Therefore, MC exploits the temporal
correlation and reduce the entropy of the residuals\footnote{The
  better the prediction, the lower the entropy of the
  residuals.}. Basically, MC consists in substracting to each original
frame a prediction (frame) build with the information that must be
also avaliable\footnote{In order to make a reversible process.} at the
decoder. Notice that, after using MC, the number of residual-pixels is
equal to the number of pixels in the compensated frame.\footnote{At
  least, when we compensate in the image domain.}

Usually, MC is only performed by the encoder (compress one. decompress
many).

%}}}

\section{Motion estimation}
%{{{

To compensate the motion we need first to estimate it using Motion
Estimation (ME) techniques~\cite{vruiz__ME}. Using the motion fiels
generated by the motion estimator, both the encoder and the decoder
generate the predictions that will de substracted (added in the case
of the decoder) from the predicted images~\cite{vruiz__MC}.

%}}}

\section{GOF-ing}

The RD performance of ME/MC depends on the amount of temporal
redundancy in the sequence. If such amount is low, it can be more
RD-efficient to interrupt the MC process. The set of consecutive
frames in which MC is active is usually known as a GOF\footnote{Some
  standards also use GOP (Group Of Pictures).} (Group of
Frames). Notice that (under the RD prism) the length of the GOFs is
variable and therefore, the GOF partition should be an adaptive
process.

However, in some contexts\footnote{Specifically, constant bit-rate
encodings.} it can be necessary to use a fixed GOP
partition~\cite{vruiz__MC}.

\section{Block-based MC and RDO}

The MC schemes used in most video coding standards compensate blocks
of pixels~\cite{vruiz__ME}. In this context, depending of the block
decision mode implemented in the RDO procedure\footnote{Obviously, the
  part of the RDO procedure that controls the block-type.}, blocks can
be of different type (I (intra), P (predicted), B
(bidirectionally-predicted) and S (skipped))~\cite{vruiz__MC}.

\section{Frame types}

Depending on the type of blocks used in the frames, we have different
types of frames: I, P and B~\cite{vruiz__MC}. For example, in the
intra coding mode, all the frames are I-type. In Motion Compensated
Temporal Filtering~\cite{vruiz__MCTF}, the frames are I or B.

\section{Resources}
\begin{enumerate}
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_block_ME.ipynb}{Full search block-based ME (Motion Estimation)}.
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_dense_ME.ipynb}{Full search dense (1x1) ME}.
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/farneback_ME.ipynb}{Farneb√§ck's motion estimation}.
\item \href{https://github.com/Sistemas-Multimedia/MRVC}{Multi-Resolution Video Coding (MRVC)}.
\end{enumerate}

\section{To-Do}
%{{{

\begin{enumerate}
\item Modify VCF to encode/decode a sequence of images using a
  III... scheme. Complexity 1.
\item Modify VCF to encode/decode a sequence of images using a
  IPP... scheme, without motion compensation. Complexity 2.
\item Modify VCF to encode/decode a sequence of images using a
  IPP... scheme, with motion compensation. Complexity 4.
\item Modify VCF to encode/decode a sequence of images using a
  IBB... scheme, with motion compensation. Complexity 5.
\end{enumerate}

%}}}
  
\section{References}
%{{{

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{image_pyramids,DWT,motion_estimation,video_compression}

%}}}
