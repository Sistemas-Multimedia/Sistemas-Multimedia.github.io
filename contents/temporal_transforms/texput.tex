% Emacs, this is -*-latex-*-

% https://vcgit.hhi.fraunhofer.de/jvet
% https://www.etsist.upm.es/uploaded/392/02_Video_Compression_Basics_MPEG1_MPEG2_MPEG4.pdf

\input{../../definitions}
\title{Temporal Transforms}

\maketitle
\tableofcontents

\section{Temporal correlation}
%{{{

In general, neighbor \emph{frames} (or images) in (video)
\emph{sequences} exhibit a high temporal correlation degree that can
be exploited to improve significantly the RD curves. This correlation
generates a temporal redundancy that can be removed using a (temporal)
transform.

A temporal transform inputs two or more frames\footnote{With pixels or
  coefficients, depending on the current domain in which the frame has
  been represented.}, and outputs at least one \emph{residual} (frame)
in which the residual pixels have a higher dynamic range but, in
general, also a lower entropy (see the spatial transform theory).

%}}}

\section{Motion Compensation (MC)}
%{{{

Most video coding standards use
\href{https://en.wikipedia.org/wiki/Motion_compensation}{Motion
  Compensation (MC)} to generate the residual
frames~\cite{vruiz__MC}. MC exploits the temporal correlation and
reduces the entropy of the residuals\footnote{The better the
  prediction, the lower the entropy of the residuals.}. Basically, MC
consists in subtracting from each original frame a prediction (frame)
built with the information that must be also avaliable\footnote{In
  order to make a reversible process.} at the decoder. Notice that,
after using MC, the number of residual pixels is equal to the number
of pixels in the compensated frame.\footnote{At least, when we
  compensate in the image domain.}

%}}}

\section{Motion Estimation (ME)}
%{{{

To compensate the motion we need first to estimate\footnote{In most of
  the situations, the determination of the true motion of the objects
  in a real scene is a ill-posed problem because it is impossible to
  find it using only a sequence of 2D images. A different situation is
  when we use al least 2 cameras.} it using Motion Estimation (ME)
techniques~\cite{vruiz__ME}. Using the motion fields generated by the
motion estimator, both the encoder and the decoder generate the
predictions that will be added (by the
decoder) from the predicted images~\cite{vruiz__MC}. However, notice
that in most of the video coding standards, ME is only performed by
the encoder because it is a costly operation, and for this reason, the
motion vector fields must be transmitted to the decoder. This responds
to the idea of ``compress one, decompress many''.

%}}}

\section{GOF-ing}

The RD performance of ME/MC depends on the amount of temporal
redundancy in the sequence. If such an amount is low, it can be more
RD-efficient to interrupt the (ME/)MC process. The set of consecutive
frames in which MC is active is usually known as a GOF\footnote{Some
  standards also use GOP (Group Of Pictures).} (Group of
Frames). Notice that (under the RD prism) the length of the GOFs is
variable, and therefore, the GOF partition should be an adaptive
process controlled by a RDO algorithm.

However, in some contexts\footnote{Specifically, constant bit-rate
  encodings.} it may be necessary to use a fixed GOP
partition~\cite{vruiz__MC}. For example, if we want to give the option
to the users to move fast forward or backward along the sequence, we
need to set some given GOF size. Another reason to use a defined GOF
size is to limit the propagation of decoding errors (for example,
because in a streaming session we have not received some data). When a
new GOF starts, the propagation of such errors is stopped.

\section{Block-based MC and RDO}

The MC schemes used in most video coding standards compensate blocks
of pixels~\cite{vruiz__ME}. In this context, depending of the block
decision mode implemented in the RDO procedure\footnote{Obviously, the
  part of the RDO procedure that controls the block-type.}, blocks can
be of different type (I (intra), P (predicted), B (bidirectionally
predicted) and S (skipped))~\cite{vruiz__MC}. A I-block is used when
we do not found enough temporal correlation between frames and from a
RD perspective, it is more advantagous to use
\emph{intra-coding}. When we found one or more reference blocks to
perform a good prediction, we are using
\emph{predictive-coding}. Notice that the number of reference blocks
can be higher than two, a number also controlled by RDO. In the
intra-coding mode, all the frames are I-type because otherwise we
could not reset the propagation errors. In Motion Compensated Temporal
Filtering~\cite{vruiz__MCTF}, the frames are I or B.

\section{Frame types}

Depending on the type of blocks used in the frames, we have different
types of frames: I, P, and B~\cite{vruiz__MC}. In a I-frame, all
blocks are I-type. In a P frame, I- and P-type blocks can be found. In
a B-frame all types of blocks can be used.

\section{Resources}
\begin{enumerate}
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_block_ME.ipynb}{Full search block-based ME (Motion Estimation)}.
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/full_search_dense_ME.ipynb}{Full search dense (1x1) ME}.
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_estimation/blob/main/src/motion_estimation/farneback_ME.ipynb}{Farneb√§ck's motion estimation}.
\item \href{https://github.com/vicente-gonzalez-ruiz/motion_compensation/blob/master/introducing_IPPP.ipynb}{Introducing the Low-delay (IPP...) Mode}.
\item \href{https://github.com/Sistemas-Multimedia/MRVC}{Multi-Resolution Video Coding (MRVC)}.
\end{enumerate}

\section{To-Do}
%{{{

\begin{enumerate}
\item Create a new module \texttt{III.py} where the image
  compression provided by \texttt{2D-DCT.py} or
  \texttt{2D-DWT.py}. Use a command line parameter to chose between
  these image codecs. Complexity 5.
\item Create a video codec similar to the previous one, but using an
  ``IPP...''  scheme without ME (or assuming that all the motion
  vectors are zero). RDO (Rate/Distortion Optimization) should be
  considered to determine the block type. Complexity 10.
\item Create a video codec similar to the previous one, but using ME
  and MC controlled by RDO (the block-type should be decided using a
  RD criteria). Complexity 12.
\item Create a video codec similar to the previous one, but using an
  ``IBB...'' scheme. Complexity 15.
\item Create a video codec similar to the previous one, but using an
  MCTF scheme. Notice that in this case, the reference frames are
  pre-defined (and usually are always 2). Complexity 14.
\end{enumerate}

%}}}
  
\section{References}
%{{{

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{image_pyramids,DWT,motion_estimation,video_compression}

%}}}
