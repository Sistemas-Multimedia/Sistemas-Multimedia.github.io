% Emacs, this is -*-latex-*-

\input{../../definitions}

\title{\SM{} -  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/data_scalability}{Code-stream Scalabilty}}

\maketitle
\tableofcontents

\section{What means code-stream scalability?}
%{{{

Image and video codecs represent multidimensional signals, and this
makes possible to decode such information in several ways. When the
encoding scheme allows this, we say that the code-stream generated by
such scheme is scalable.

Scalability is interesting in several contexts and it has been
developed my most of the image and video encoding standards.

%}}}

\section{Temporal scalability}

%{{{

Temporal scalability~\cite{vruiz__video_scalability} provides
flexibity with the number of decoded frames in the case of video
coding.\footnote{Notice that the concept of temporal scalability
  cannot be applied to image coding.}

\subsection{GOF-level scalabilty}
GOF-splitting provides basic temporal scalability (GOFs can be decoded
independently), and this is used in video streaming services (such as
YouTube) and video players to move along time using fast-forward and
fast-backward modes,
  
Notice that in this context, the maximum temporal scalabilty is
achieved when we use the intra-coding mode (III...), which provides
total temporal scalability.

\subsection{Frame-level scalabilty using MCTF}

Random-access modes can provide dyadic temporal scalability in each
GOF if only B-type frames are used and they are generated using Motion
Compensated Temporal Filtering (MCTF)~\cite{vruiz__MCTF}.

%}}}

\section{Spatial scalability in image coding}

%{{{ 

Compressed images can be partially decoded, resulting in a
reconstruction with a smaller resolution or in a reconstruction of a
WOI (Window Of Interest). Such forms of scalability are used in
interactive streaming to minimize the latency and to avoid sending
resolutions that some devices cannot display.

An example of spatial scalability using JPEG2000 can be found in the
\href{https://www.jhelioviewer.org/}{JHelioviewer service}.

\subsection{Using the LPT (Laplacian Pyramid Transform)}

\href{https://en.wikipedia.org/wiki/Pyramid_(image_processing)#Laplacian_pyramid}{Laplacian
  pyramids} are 2D multiresolution structures that be used to provide
spatial scalability in image coding. The main issue to solve here is
the data redundancy overhead of the LPT domain.

\subsection{Using the DWT (Discrete Wavelet Transform)}

2D-DWT domains are 2D multiresolution structures that enable spatial
scalability, and in this case, compared to LPT, the data redundancy
overhead is avoided. JPEG2000 is based on the DWT.

%}}}

\section{Spatial scalability in video coding}

%{{{

In the case of video, spatial scalabilty provides 2D multiresolution
rendering using only one code-stream.

Another

Closely related with temporal and spatial scal

Spatial scalaiblty in video is usally generated using the LPT because
the DWT domain is not shift invariant (invariant to the
displacement). The concept here is to apply MC~\cite{vruiz__MC} to
each level of the laplacian pyramid.

Similarly to image scalability, videos can be partially decoded to
obtain a version with a smaller resolution. This is used in video
streaming to avoid interruptions during the playing of the videos by
switching between resolutions, in video databases to save memory, and
in the rendering of the videos in displays with different resolution.

\subsection{Using the LPT}

The LPT domain is shift invariant and therefore, it is straightforward
the use of most ME/MC techniques in this spatially scalable
representation scheme. Notice, however, that this domain is redundant
compared to the original one.

\subsection{Using the DWT}

The DWT domain is not redundant, but the shift invariant feature is
not satisfied. To solve this problem, the DWT subbands must be
interpolated to restore the lost phases, In this overcomplete domain,
ME/MC algorithms work but the used phase of the predicted images must
be represented in the code-stream.

%}}}

\section{Quality scalability in image coding}

If we have used a layered-based encoding system and we know the RD
points generated by each layer of each subband, we can sort the points
by their slope and use the progression of layers to easely select hown
many quality layers should be used satisfiying some maximum distorion
of bit-rate. This is done, for example, in JPEG2000.

\section{Quality scalability in video coding}

\section{Simulcast VS Adaptive bit-rate streaming VS data-scalability}

%{{{ 

Although both terms can be confused,
\href{https://en.wikipedia.org/wiki/Simulcast}{simulcast} is an
streaming technique and data-scalability is a coding technique.

Simulcast (used, for example, in the
\hrefhttps://en.wikipedia.org/wiki/DVB}{DVB},
\href{https://en.wikipedia.org/wiki/ATSC_standards}{ATSC} and
\href{https://en.wikipedia.org/wiki/ISDB}{ISDB}) is the process of the
parallel trasmitting of media with different resolutions and/or
qualities, and this is usually deployed using different code-streams
at the sender side, although it could be also done using only one
scalable code-stream in spatial resolution.

Adaptive bit-rate streaming allows to adapt the transmission bit-rate
in a point-to-point communication (of digital media) to the available
capacity of the link (which is typically time-variying). This
technique is used, for example, in the
\href{https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP}{DASH
  standard}, which is used, for example, in YouTube.

%}}}

\section{Adaptive bit-rate streaming VS data-scalability}




\section{To-Do}
\begin{enumerate}
\item The $L$-levels DWT provides $L+1$ spatial resolution levels of
  an image. Modify the VCF pipeline to include this
  functionality. Complexity 2.
\item The $2^n\times 2^n$-DCT domain can be decoded by resolution
  levels using a inverse $2^m\times 2^m$-DCT where $m=0,1,\cdots,n$,
  to the lower frequency subbands (notice that the inverse
  $0\times 0$-DCT does not perform any computation). Implement in VCF
  such image decoder. Complexity 4.
\item In video coding, we can obtain spatial scalability if we build a
  laplacian pyramid of the frames and compress each level of the
  sequence using a normal video encoder. Notice that we can use the
  reconstructed sequence at the spatial level $l$ to improve the
  predictions for the level $l-1$. Incorporate this functionality to
  VCF. Complexity 6.
\item The spatial resolution level $l$ of the reconstructed video can
  be used (after interpolation) to estimate the motion at the $l-1$
  level\footnote{Obviously, expecting worse motion fields that if we
    estimate them at the encoder because, in the decoder, the
    available information has been reduced due to lossy coding.},
  making the transmission of motion fields unnecessary for resolution
  level $l-1$. Explore this in VCF. Complexity 7.
\end{enumerate}

\section{References}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{text_compression}
