% Emacs, this is -*-latex-*-

\input{../../definitions}

\title{\SM{} -  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/data_scalability}{Code-stream Scalabilty}}

\maketitle
\tableofcontents

\section{What means code-stream scalability?}
%{{{

Image and video codecs represent multidimensional signals, and this
makes possible to decode such information in several ways. When the
encoding scheme allows this, we say that the code-stream generated by
such scheme is scalable.

Scalability is interesting in several contexts and it has been
developed my most of the image and video encoding standards.

As a general remark, data-scalability in media coding implies some
loss of RD efficiency.

%}}}

\section{Temporal scalability}

%{{{

Temporal scalability~\cite{vruiz__video_scalability} provides
flexibity with the number of decoded frames in the case of video
coding.\footnote{Notice that the concept of temporal scalability
  cannot be applied to image coding.}

\subsection{GOF-level scalabilty}
GOF-splitting provides basic temporal scalability (GOFs can be decoded
independently), and this is used in video streaming services (such as
YouTube) and video players to move along time using fast-forward and
fast-backward modes,
  
Notice that in this context, the maximum temporal scalabilty is
achieved when we use the intra-coding mode (III...), which provides
total temporal scalability.

\subsection{Frame-level scalabilty using MCTF}

Random-access modes can provide dyadic temporal scalability in each
GOF if only B-type frames are used and they are generated using Motion
Compensated Temporal Filtering (MCTF)~\cite{vruiz__MCTF}.

%}}}

\section{Spatial scalability in image coding}

%{{{ 

Compressed images can be partially decoded, resulting in a
reconstruction with a smaller resolution or in a reconstruction of a
WOI (Window Of Interest). Such forms of scalability are used in
interactive streaming to minimize the latency and to avoid sending
resolutions that some devices cannot display.

An example of spatial scalability using JPEG2000 can be found in the
\href{https://www.jhelioviewer.org/}{JHelioviewer service}.

\subsection{Using the LPT (Laplacian Pyramid Transform)}

\href{https://en.wikipedia.org/wiki/Pyramid_(image_processing)#Laplacian_pyramid}{Laplacian
  pyramids} are 2D multiresolution structures that be used to provide
spatial scalability in image coding. The main issue to solve here is
the data redundancy overhead of the LPT domain.

\subsection{Using the DWT (Discrete Wavelet Transform)}

2D-DWT domains are 2D multiresolution structures that enable spatial
scalability, and in this case, compared to LPT, the data redundancy
overhead is avoided. JPEG2000 is based on the DWT.

%}}}

\section{Spatial scalability in video coding}

%{{{

In the case of video, spatial scalabilty provides 2D multiresolution
rendering using only one code-stream. This possibility is usually
generated using the LPT because the DWT domain is not shift invariant
(invariant to the displacement).\footnote{The DWT domain is not
  redundant, but the shift invariant feature is not satisfied. To
  solve this problem, the DWT subbands must be interpolated to restore
  the lost phases, In this overcomplete domain, ME/MC algorithms work
  but the used phase of the predicted images must be represented in
  the code-stream.} The concept here is to apply MC~\cite{vruiz__MC}
to each level of the laplacian pyramid.

Similarly to image scalability, a scalable video can be partially
decoded to obtain a version with a smaller resolution. This can be
used in video streaming to avoid interruptions during the playing of
the videos by switching between resolutions, in video databases to
save memory, and in the rendering of the videos in displays with
different resolutions.

%}}}

\section{Quality scalability in image coding}

%{{{ 

Quality scalability allows the possibility of adding or substracting
more or less visual information, depending on the amount of rendered
code-stream. Spatial and temporal resolutions remain constant.

\subsection{Using the DCT}

Some DCT-based image coding standards, such as JPEG, allows a
progressive decoding, where an increasing number of coefficients or
bit-planes of those coefficients are rendered. Notice that, if 11 is
the number of bit-planes required to represent the coefficients, a
total of $11\times 64\times 64$ quality levels is possible.

\subsection{Using the DWT}

The idea of bit-plane encoding in the DWT domain is used in
JPEG2000. Compared to JPEG, the number of quality levels is much
higher, because in this case, we can have up to $R\times C\times B$,
where $R$ is the number of rows, $C$ the number of columns, and $B$
the number of bit-planes in the DWT domain. In JPEG2000, the
code-stream that represents a quality level is called quality
layer. It holds that, all the code-stream that belongs to the quality
layer $L$ generates points in the RD curve that are on the left of the
RD-points that are generated by the layer $L+1$.

\section{Quality scalability in video coding}

In the case of video, most video standards provide quality scalability
through applying MC to succesive refinements of the reconstructed
sequence, at the maximum spatial resolution. This idea can be easely
understood if we imagine a spatially scalable code-stream generated
with the LPT, but in this case all the levels of the
pyramid\footnote{Notice that in this case, we should use the term
  ``block'' instead of ``pyramid''.} have the same spatial
resolution.

%}}}

\section{Simulcast VS Adaptive bit-rate streaming VS data-scalability}

%{{{ 

Although both terms can be confused,
\href{https://en.wikipedia.org/wiki/Simulcast}{simulcast} is an
streaming technique and data-scalability is a coding technique.

Simulcast (used, for example, in the
\hrefhttps://en.wikipedia.org/wiki/DVB}{DVB},
\href{https://en.wikipedia.org/wiki/ATSC_standards}{ATSC} and
\href{https://en.wikipedia.org/wiki/ISDB}{ISDB}) is the process of the
parallel trasmitting of media with different resolutions and/or
qualities, and this is usually deployed using different code-streams
at the sender side, although it could be also done using only one
scalable code-stream in spatial resolution.

Adaptive bit-rate streaming allows to adapt the transmission bit-rate
in a point-to-point communication (of digital media) to the available
capacity of the link (which is typically time-variying). This
technique is used, for example, in the
\href{https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP}{DASH
  standard}, which is used, for example, in YouTube.

%}}}

\section{Adaptive bit-rate streaming VS data-scalability}




\section{To-Do}
\begin{enumerate}
\item The $L$-levels DWT provides $L+1$ spatial resolution levels of
  an image. Modify the VCF pipeline to include this
  functionality. Complexity 2.
\item The $2^n\times 2^n$-DCT domain can be decoded by resolution
  levels using a inverse $2^m\times 2^m$-DCT where $m=0,1,\cdots,n$,
  to the lower frequency subbands (notice that the inverse
  $0\times 0$-DCT does not perform any computation). Implement in VCF
  such image decoder. Complexity 4.
\item In video coding, we can obtain spatial scalability if we build a
  laplacian pyramid of the frames and compress each level of the
  sequence using a normal video encoder. Notice that we can use the
  reconstructed sequence at the spatial level $l$ to improve the
  predictions for the level $l-1$. Incorporate this functionality to
  VCF. Complexity 6.
\item The spatial resolution level $l$ of the reconstructed video can
  be used (after interpolation) to estimate the motion at the $l-1$
  level\footnote{Obviously, expecting worse motion fields that if we
    estimate them at the encoder because, in the decoder, the
    available information has been reduced due to lossy coding.},
  making the transmission of motion fields unnecessary for resolution
  level $l-1$. Explore this in VCF. Complexity 7.
\end{enumerate}

\section{References}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{text_compression}
