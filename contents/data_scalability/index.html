<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Sistemas Multimedia - Code-stream Scalabilty</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'><a href='https://sistemas-multimedia.github.io/'>Sistemas Multimedia</a> - <a href='https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/tree/master/contents/data_scalability'>Code-stream Scalabilty</a></h2>
 <div class='author'><a href='https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875'><span class='ecrm-1200'>Vicente González Ruiz</span></a> <span class='ecrm-1200'>- </span><a href='https://cms.ual.es/UAL/universidad/departamentos/informatica/index.htm'><span class='ecrm-1200'>Depto Informática</span></a> <span class='ecrm-1200'>- </span><a href='https://www.ual.es'><span class='ecrm-1200'>UAL</span></a></div><br />
<div class='date'><span class='ecrm-1200'>January 24, 2023</span></div>
   </div>
   <h3 class='likesectionHead' id='contents'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#what-means-codestream-scalability' id='QQ2-1-2'>What means code-stream scalability?</a></span>
<br />    <span class='sectionToc'>2 <a href='#temporal-scalability-vruizvideoscalability' id='QQ2-1-3'>Temporal scalability [4]</a></span>
<br />     <span class='subsectionToc'>2.1 <a href='#goflevel-scalabilty' id='QQ2-1-4'>GOF-level scalabilty</a></span>
<br />     <span class='subsectionToc'>2.2 <a href='#framelevel-scalabilty-using-mctf' id='QQ2-1-5'>Frame-level scalabilty using MCTF</a></span>
<br />    <span class='sectionToc'>3 <a href='#spatial-scalability-in-image-coding-vruizjpeg' id='QQ2-1-6'>Spatial scalability in image coding [1]</a></span>
<br />     <span class='subsectionToc'>3.1 <a href='#using-the-lpt-laplacian-pyramid-transform' id='QQ2-1-7'>Using the LPT (Laplacian Pyramid Transform)</a></span>
<br />     <span class='subsectionToc'>3.2 <a href='#using-the-dwt-discrete-wavelet-transform-vruizjpeg' id='QQ2-1-8'>Using the DWT (Discrete Wavelet Transform) [1]</a></span>
<br />    <span class='sectionToc'>4 <a href='#spatial-scalability-in-video-coding-vruizvideoscalability' id='QQ2-1-9'>Spatial scalability in video coding [4]</a></span>
<br />    <span class='sectionToc'>5 <a href='#quality-scalability-in-image-coding-vruizjpeg' id='QQ2-1-10'>Quality scalability in image coding [1]</a></span>
<br />     <span class='subsectionToc'>5.1 <a href='#using-the-dct' id='QQ2-1-11'>Using the DCT</a></span>
<br />     <span class='subsectionToc'>5.2 <a href='#using-the-dwt-vruiztransformcoding' id='QQ2-1-12'>Using the DWT [<span class='ecbx-1000'>?</span>]</a></span>
<br />    <span class='sectionToc'>6 <a href='#quality-scalability-in-video-coding-vruizvideoscalability' id='QQ2-1-13'>Quality scalability in video coding [4]</a></span>
<br />    <span class='sectionToc'>7 <a href='#simulcast-vs-adaptive-bitrate-streaming-vs-datascalability' id='QQ2-1-14'>Simulcast VS Adaptive bit-rate streaming VS data-scalability</a></span>
<br />    <span class='sectionToc'>8 <a href='#todo' id='QQ2-1-15'>To-Do</a></span>
<br />    <span class='sectionToc'>9 <a href='#references' id='QQ2-1-16'>References</a></span>
   </div>
<!-- l. 10 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='what-means-codestream-scalability'><span class='titlemark'>1   </span> <a id='x1-20001'></a>What means code-stream scalability?</h3>
                                                                  

                                                                  
<!-- l. 13 --><p class='noindent'>Image and video codecs represent multidimensional signals, and this makes possible
to decode such information in several ways. When the code-stream allows this, we say
that the code-stream generated by such scheme is scalable.
</p><!-- l. 18 --><p class='indent'>   Scalability is interesting in several contexts and it has been developed my most of
the image and video encoding standards.
</p><!-- l. 21 --><p class='indent'>   As a general remark, data-scalability in media coding implies some loss of RD
efficiency.
</p><!-- l. 26 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='temporal-scalability-vruizvideoscalability'><span class='titlemark'>2   </span> <a id='x1-30002'></a>Temporal scalability <span class='cite'>[<a href='#Xvruiz__video_scalability'>4</a>]</span></h3>
<!-- l. 30 --><p class='noindent'>In video coding, temporal scalability provides flexibity with the number of decoded
frames.<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-3001f1'></a>
</p><!-- l. 34 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='goflevel-scalabilty'><span class='titlemark'>2.1   </span> <a id='x1-40002.1'></a>GOF-level scalabilty</h4>
<!-- l. 35 --><p class='noindent'>GOF-splitting provides basic temporal scalability (GOFs can be decoded
independently), and this is used in video streaming services (such as YouTube)
and video players to move along time using fast-forward and fast-backward
modes.
</p><!-- l. 40 --><p class='indent'>   Notice that in this context, the maximum temporal scalabilty is achieved
when we use the intra-coding mode (III...), which provides total temporal
scalability.
</p><!-- l. 44 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='framelevel-scalabilty-using-mctf'><span class='titlemark'>2.2   </span> <a id='x1-50002.2'></a>Frame-level scalabilty using MCTF</h4>
<!-- l. 46 --><p class='noindent'>Random-access modes can provide dyadic temporal scalability in each GOF if only
B-type frames are used and they are generated using Motion Compensated Temporal
Filtering (MCTF) <span class='cite'>[<a href='#Xvruiz__MC'>3</a>, <a href='#Xvruiz__MCTF'>2</a>]</span>.
</p><!-- l. 52 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='spatial-scalability-in-image-coding-vruizjpeg'><span class='titlemark'>3   </span> <a id='x1-60003'></a>Spatial scalability in image coding <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span></h3>
<!-- l. 56 --><p class='noindent'>Compressed images can be partially decoded, resulting in a reconstruction with a
smaller resolution or in a reconstruction of a WOI (Window Of Interest) <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span>. Such
forms of scalability are used in interactive streaming to minimize the latency and to
avoid sending resolutions that some devices cannot display.
                                                                  

                                                                  
</p><!-- l. 62 --><p class='indent'>   An example of spatial scalability using JPEG2000 <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span> can be found in the
<a href='https://www.jhelioviewer.org/'>JHelioviewer service</a>.
</p><!-- l. 66 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='using-the-lpt-laplacian-pyramid-transform'><span class='titlemark'>3.1   </span> <a id='x1-70003.1'></a>Using the LPT (Laplacian Pyramid Transform)</h4>
<!-- l. 69 --><p class='noindent'><a href='https://en.wikipedia.org/wiki/Pyramid_(image_processing)#Laplacian_pyramid'>Laplacian pyramids</a> are 2D multiresolution structures that be used to provide spatial
scalability in image coding. The main issue to solve here is the data redundancy
overhead of the LPT domain.
</p><!-- l. 73 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='using-the-dwt-discrete-wavelet-transform-vruizjpeg'><span class='titlemark'>3.2   </span> <a id='x1-80003.2'></a>Using the DWT (Discrete Wavelet Transform) <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span></h4>
<!-- l. 75 --><p class='noindent'>2D-DWT domains are 2D multiresolution structures that enable spatial scalability,
and in this case, compared to LPT, the data redundancy overhead is avoided.
JPEG2000 <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span> is based on the DWT.
</p><!-- l. 82 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='spatial-scalability-in-video-coding-vruizvideoscalability'><span class='titlemark'>4   </span> <a id='x1-90004'></a>Spatial scalability in video coding <span class='cite'>[<a href='#Xvruiz__video_scalability'>4</a>]</span></h3>
<!-- l. 86 --><p class='noindent'>In the case of video, spatial scalabilty provides 2D multiresolution rendering using
only one (partially decoded) code-stream. This possibility is usually generated using
the LPT because the DWT domain is not shift invariant (invariant to the
displacement).<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-9001f2'></a>
The concept here is to apply MC <span class='cite'>[<a href='#Xvruiz__MC'>3</a>]</span> to each level of the laplacian pyramid.
</p><!-- l. 97 --><p class='indent'>   Spatial Scalability can be used in video streaming to avoid interruptions during
the playing of the videos by switching between resolutions, in video databases to
save memory, and in the rendering of the videos in displays with different
resolutions.
</p><!-- l. 104 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='quality-scalability-in-image-coding-vruizjpeg'><span class='titlemark'>5   </span> <a id='x1-100005'></a>Quality scalability in image coding <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span></h3>
<!-- l. 108 --><p class='noindent'>Quality scalability allows the possibility of adding or substracting more or less visual
information, depending on the amount of rendered code-stream. Spatial and temporal
resolutions remain constant.
                                                                  

                                                                  
</p><!-- l. 112 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='using-the-dct'><span class='titlemark'>5.1   </span> <a id='x1-110005.1'></a>Using the DCT</h4>
<!-- l. 114 --><p class='noindent'>Some DCT-based image coding standards, such as JPEG, allows a progressive
decoding, where an increasing number of coefficients or bit-planes of those coefficients
are rendered. Notice that, if 11 is the number of bit-planes required to represent the
coefficients, a total of \(11\times 64\times 64\) quality levels is possible.
</p><!-- l. 120 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='using-the-dwt-vruiztransformcoding'><span class='titlemark'>5.2   </span> <a id='x1-120005.2'></a>Using the DWT <span class='cite'>[<span class='ecbx-1000'>?</span>]</span></h4>
<!-- l. 122 --><p class='noindent'>The idea of bit-plane encoding in the DWT domain is used in JPEG2000 <span class='cite'>[<a href='#Xvruiz__JPEG2000'>1</a>]</span>.
Compared to JPEG, the number of quality levels is much higher, because in this
case, we can have up to \(R\times C\times B\), where \(R\) is the number of rows, \(C\) the number of columns, and \(B\)
the number of bit-planes in the DWT domain. In JPEG2000, the code-stream that
represents a quality level is called quality layer. It holds that, all the code-stream
that belongs to the quality layer \(L\) generates points in the RD curve that
are on the left of the RD-points that are generated by the layer \(L+1\). In other
words, the quality layers are sorted by their contribution to the quality of the
reconstruction.
</p><!-- l. 134 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='quality-scalability-in-video-coding-vruizvideoscalability'><span class='titlemark'>6   </span> <a id='x1-130006'></a>Quality scalability in video coding <span class='cite'>[<a href='#Xvruiz__video_scalability'>4</a>]</span></h3>
<!-- l. 136 --><p class='noindent'>In the case of video, most video standards provide quality scalability through
applying MC to succesive refinements of the reconstructed sequence, at the maximum
spatial resolution. This idea can be easely understood if we imagine a spatially
scalable code-stream generated with the LPT, but in this case all the levels of the
pyramid<span class='footnote-mark'><a href='#fn3x0' id='fn3x0-bk'><sup class='textsuperscript'>3</sup></a></span><a id='x1-13001f3'></a>
have the same spatial resolution.
</p><!-- l. 147 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='simulcast-vs-adaptive-bitrate-streaming-vs-datascalability'><span class='titlemark'>7   </span> <a id='x1-140007'></a>Simulcast VS Adaptive bit-rate streaming VS data-scalability</h3>
<!-- l. 151 --><p class='noindent'>Although both terms can be confused, <a href='https://en.wikipedia.org/wiki/Simulcast'>simulcast</a> is an streaming technique and
data-scalability is a coding technique.
</p><!-- l. 155 --><p class='indent'>   Simulcast (used, for example, in the <a href='https://en.wikipedia.org/wiki/DVB'>DVB</a>, <a href='https://en.wikipedia.org/wiki/ATSC_standards'>ATSC</a> and <a href='https://en.wikipedia.org/wiki/ISDB'>ISDB</a>) is the process of the
parallel trasmitting of media with different resolutions and/or qualities,
and this is usually deployed using different code-streams at the sender side,
although it could be also done using only one scalable code-stream in spatial
resolution.
                                                                  

                                                                  
</p><!-- l. 164 --><p class='indent'>   Adaptive bit-rate streaming allows to adapt the transmission bit-rate in a
point-to-point communication (of digital media) to the available capacity of the link
(which is typically time-variying). This technique is used, for example, in the <a href='https://en.wikipedia.org/wiki/Dynamic_Adaptive_Streaming_over_HTTP'>DASH
standard</a>, which is used, for example, in YouTube.
</p><!-- l. 173 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='todo'><span class='titlemark'>8   </span> <a id='x1-150008'></a>To-Do</h3>
<!-- l. 174 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-15002x1'>The \(L\)-levels DWT provides \(L+1\) spatial resolution levels of an image. Modify
     the VCF pipeline to include this functionality. Complexity 2.
     </li>
<li class='enumerate' id='x1-15004x2'>The \(2^n\times 2^n\)-DCT domain can be decoded by resolution levels using a inverse
     \(2^m\times 2^m\)-DCT where \(m=0,1,\cdots ,n\), to the lower frequency subbands (notice that the inverse
     \(0\times 0\)-DCT does not perform any computation). Implement in VCF such image
     decoder. Complexity 4.
     </li>
<li class='enumerate' id='x1-15006x3'>In video coding, we can obtain spatial scalability if we build a laplacian
     pyramid of the frames and compress each level of the sequence using a
     normal video encoder. Notice that we can use the reconstructed sequence
     at the spatial level \(l\) to improve the predictions for the level \(l-1\). Incorporate
     this functionality to VCF. Complexity 6.
     </li>
<li class='enumerate' id='x1-15008x4'>The spatial resolution level \(l\) of the reconstructed video can be used (after
     interpolation) to estimate the motion at the \(l-1\) level<span class='footnote-mark'><a href='#fn4x0' id='fn4x0-bk'><sup class='textsuperscript'>4</sup></a></span><a id='x1-15009f4'></a>,
     making the transmission of motion fields unnecessary for resolution level
     \(l-1\). Explore this in VCF. Complexity 7.</li></ol>
                                                                  

                                                                  
<!-- l. 198 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='references'><span class='titlemark'>9   </span> <a id='x1-160009'></a>References</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xvruiz__JPEG2000'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/JPEG2000'>The JPEG2000 Standard</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='Xvruiz__MCTF'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/motion_compensated_temporal_filtering'>Motion Compensated Temporal Filtering (MCTF)</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [3]<span class='bibsp'>   </span></span><a id='Xvruiz__MC'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/motion_compensation'>Motion Compensation</a>.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [4]<span class='bibsp'>   </span></span><a id='Xvruiz__video_scalability'></a>V. González-Ruiz. <a href='https://github.com/vicente-gonzalez-ruiz/video_scalability'>Video Scalability</a>.
</p>
   </div>
   <div class='footnotes'><!-- l. 32 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>Notice that the concept of temporal scalability cannot be applied to image coding.</span></p>
<!-- l. 94 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>The DWT domain is not redundant, but the shift invariant feature is not satisfied. To solve
</span><span class='ecrm-0800'>this problem, the DWT subbands must be interpolated to restore the lost phases, In this
</span><span class='ecrm-0800'>overcomplete domain, ME/MC algorithms work but the used phase of the predicted images must be
</span><span class='ecrm-0800'>represented in the code-stream.</span></p>
<!-- l. 142 --><p class='indent'>     <span class='footnote-mark'><a href='#fn3x0-bk' id='fn3x0'><sup class='textsuperscript'>3</sup></a></span><span class='ecrm-0800'>Notice that in this case, we should use the term “block” instead of “pyramid”.</span></p>
<!-- l. 193 --><p class='noindent'><span class='footnote-mark'><a href='#fn4x0-bk' id='fn4x0'><sup class='textsuperscript'>4</sup></a></span><span class='ecrm-0800'>Obviously, expecting worse motion fields that if we estimate them at the encoder because,
</span><span class='ecrm-0800'>in the decoder, the available information has been reduced due to lossy coding.</span></p>                  </div>
 
</body> 
</html>