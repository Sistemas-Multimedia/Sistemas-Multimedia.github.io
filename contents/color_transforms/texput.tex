% Emacs, this is -*-latex-*-

% https://www.youtube.com/watch?v=ZCDF9f1Wo0Q ( Self-Organizing Maps for Color Quantization (python) )
% https://stackoverflow.com/questions/57817645/how-do-i-re-train-an-existing-k-means-clustering-model
% https://www.deeplearningbook.org/
% https://www.researchgate.net/profile/Wenpeng-Ding/publication/242268750_Rate-distortion_optimized_color_quantization_for_compound_image_compression_-_art_no_65082Q/links/5448579f0cf2f14fb8142446/Rate-distortion-optimized-color-quantization-for-compound-image-compression-art-no-65082Q.pdf?origin=publication_detail (RATE-DISTORTION OPTIMIZED COLOR QUANTIZATION FOR COMPOUND IMAGE COMPRESSION)
% https://pyclustering.github.io/docs/0.8.2/html/da/d22/classpyclustering_1_1cluster_1_1kmeans_1_1kmeans.html#details
% https://ieeexplore.ieee.org/document/839021 (Centroid neural network for unsupervised competitive learning)
% https://github.com/tranleanh/centroid-neural-networks
% https://towardsai.net/p/l/centroid-neural-network-and-vector-quantization-for-image-compression
% https://pub.towardsai.net/centroid-neural-network-an-efficient-and-stable-clustering-algorithm-b2fa8cbb2a27
% https://towardsai.net/p/l/centroid-neural-network-for-clustering-with-numpy
% https://matthew-parker.rbind.io/post/2021-01-16-pytorch-keras-clustering/
% https://theswissbay.ch/pdf/Gentoomen%20Library/Information%20Theory/Compression/
% https://scikit-learn-extra.readthedocs.io/en/stable/modules/cluster.html
%

\input{../../definitions}
\title{\href{https://sistemas-multimedia.github.io/contents/color_transforms/}{Color Transforms}}

\maketitle
\tableofcontents

\section{Spectral decorrelation}

Most image and video compressors exploit the statistical correlation
(and also perceptual redundacy\footnote{This will be explained latter
  in this course.})  between the $\text{RGB}$ color
\emph{components}\footnote{A component of a pixel in the $\text{RGB}$
  domain refer to one of the values $\text{R}$ (red), $\text{G}$
  (green) and $\text{B}$ (blue) coordinates in the $\text{RGB}$ color
  3D space.}  of the pixels, using a color transform.

Color transforms are pixel-wise operators. As a result, each pixel is
represented in a different (color) domain where (usually) three new
\emph{coefficients}\footnote{Most part of the transforms, including
the color ones, analyze the signal information from a frequency
perspective, generating the so called coefficients whose index in the
transform domain is related to a different frequency of the signal.}
express the same\footnote{In general, the color transforms can be
considered lossless, although this is only true if fixed-point
arithmetic is used.} information.

\section{Luma and chromas}

Most color transforms are designed to split the color information of a
pixel into \emph{luminance} (or simply \emph{luma}) and
\emph{chrominance} (\emph{chroma}). The luma is basically the low
frequency\footnote{It is worth understanding that the frequency
  concept in the color transform domain is not related to the
  frequency concept in the original pixel domain. For example, the
  $\text{R}$ component or a pixel represents the amount of red in the
  pixel, and in the visible spectrum we are refering to frequencies
  that are lower than the frequency that the $\text{G}$ and $\text{B}$
  components represent. However, in a color transformed domain, the
  luma measures the brightness level of the pixel, and we cannot found
  a subband of frequencies in the visible spectrum that can represent
  such information because we are using a different representation
  domain.} information of the color of the pixel, and the chroma
(logically) the high frequency information.

For example, in
\href{https://en.wikipedia.org/wiki/JPEG#JPEG_codec_example}{JPEG} and
\href{https://en.wikipedia.org/wiki/Advanced_Video_Coding#Fidelity_range_extensions_and_professional_profiles}{H.264/AVC}
the color information of each pixel is transformed from the
$\text{RGB}$ color space to the $\text{YCrCb}$ color space, and in
\href{https://en.wikipedia.org/wiki/JPEG_XR#Description}{JPEG XR}, the
destination color space is $\text{YCoCg}$. In these luma/chroma-based
color spaces, (the symbol) $\text{Y}$ represents the luma
(coefficient) of the pixel. The other two coefficients form the
chroma. Note that the chrominance of a pixel is determined by two
chromas.

\subsection{Components, channels, coefficients and subbands}

In image and video coding, most color transforms map 3 (color)
\emph{components} ($\text{RGB}$) into 3 \emph{coefficients}. It is
common to call to the same component(-index) of all the pixels of an
image: \emph{channel} (for eample, the $\text{R}$-channel). In most
bibliography, the same coefficient(-index) of all the coefficients of
a transformed image is denoted by a \emph{subband} (for example, the
$Y$-subband).

\section{Benefits of color transforms}

Color transforms applied to natural visual information generally have
two key advantages:
\begin{enumerate}
\item \textbf{Energy concentration:} In general, transforms ``move''
  the energy\footnote{In general, the information provided by the
    signals.} between subbands, accumulating most of the energy in a
  reduced number of them (aspect related to the so-called coding gain
  of the transform~\cite{vruiz__transform_coding}). In our case, where
  the transformations are between color spaces, in the transform
  domain, most of the energy is concentrated in the $\text{Y}$
  subband. As a consequence of this, usually, \textbf{the
    entropy~\cite{vruiz__information_theory} is decreased} and
  \textbf{the dynamic range of the signal is increased}. The first
  fact means that we can encode the same information using less
  bit-rate, and the second, that we can use a higher range of
  quantization step
  sizes~\cite{vruiz__scalar_quantization,sayood2017introduction},
  increasing also the number of feasible points in the RD
  curve~\cite{vruiz__information_theory}.
\item \textbf{Luma/chroma perceptual analysis:} Our visual system is
  more sensitive in terms of spatial resolution to the luma (``black
  and white'') information than to the chroma (``color'') information,
  which basically means that we can quantize more the
  chroma\footnote{Notice again, that we will study this effect in a
    posterior session.} without generating perceptual distortion.
\end{enumerate}

\section{Scalar quantization in the color transform domain}

If the color transform is
\href{https://en.wikipedia.org/wiki/Orthogonal_transformation}{orthogonal},
(that is, the luma and the cromas are independent features of the
signal\footnote{The luna does not define the chroma and viceversa.}),
the quantization noise generated in the subbands is additive respect
to the reconstructed signal~\cite{burger2016digital}. Therefore, from
a pure RD point of view, the quantization step sizes for each subband
should be selected using the same RD slope in all subbands (see the
notebook
\href{https://github.com/vicente-gonzalez-ruiz/color_transforms/blob/main/docs/RGB/RGB_SQ.ipynb}{Scalar
  Quantization of RGB images}. Notice that this implies to compute the
RD curves.

Therefore, taking a generic luma-chroma transform $\text{YUV}$, we
expect that
\begin{equation}
  \lambda_{\text{Y}} \approx \lambda_{\text{U}} \approx \lambda_{\text{V}}
  \label{eq:optimal_lambda}
\end{equation}
for the quantization step sizes
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{U}} = \Delta_{\text{V}},
  \label{eq:optimal_delta}
\end{equation}
and therefore the Rate-Distortion Optimization
(RDO)~\cite{vruiz__information_theory} can be ignored. In the notebook
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/contents/RGB_SQ/RGB_SQ.ipynb}{Scalar
  Quantization of RGB images} we can explore (at least visually) the
grade of compilance of Eq.~\eqref{eq:optimal_lambda}.

\subsection*{Resources}
\begin{enumerate}
\item \href{https://github.com/Sistemas-Multimedia/VCF/blob/main/notebooks/YCrCb.ipynb}{YCrCb.ipynb}: Notebook showing the use of YCrCb.py.
\item \href{https://github.com/Sistemas-Multimedia/VCF/blob/main/notebooks/YCoCg.ipynb}{YCoCg.ipynb}: Notebook showing the use of YCoCg.py.
\item \href{https://github.com/Sistemas-Multimedia/VCF/blob/main/notebooks/YCoCg.ipynb}{color-DCT.ipynb}: Notebook showing the use of color-DCT.py.
\item \href{https://github.com/vicente-gonzalez-ruiz/vector_quantization/blob/main/docs/RGB_VQ.ipynb}{Vector
    Quantization (in the color domain) of a RGB image}.
\item \href{https://github.com/vicente-gonzalez-ruiz/vector_quantization/blob/main/docs/spatial_color_VQ.ipynb}{Vector
  Quantization (in the 2D domain) of a color (RGB) image}.
\item \href{https://github.com/vicente-gonzalez-ruiz/color_transforms/blob/main/docs/3DCT/3DCT_over_RGB.ipynb}{Removing RGB redundancy with the DCT}.
\item \href{https://github.com/vicente-gonzalez-ruiz/color_transforms/blob/main/docs/YCoCg/YCoCg_over_RGB.ipynb}{Removing RGB redundancy with the $\text{YCoCg}$ transform}.
\item \href{https://github.com/vicente-gonzalez-ruiz/color_transforms/blob/main/docs/YCrCb/YCrCb_over_RGB.ipynb}{Removing RGB redundancy with the $\text{YCrCb}$ transform}.
\end{enumerate}
  
\section{References}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{maths,data_compression,signal_processing,DWT,image_compression,image_processing,information_theory,quantization}
