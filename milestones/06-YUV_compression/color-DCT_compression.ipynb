{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/06-YUV_compression/color-DCT_compression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color-DCT image compression\n",
    "\n",
    "Removing redundancy in the color domain with the [DCT](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.dct.html).\n",
    "\n",
    "The DCT is orthonormal (orthongonal + unitary (energy preserving transform)), and as it happens with other energy compacting transforms, the gain of some subbands (color-DCT components in our case) will be higher (the coefficients in such subbands will be larger) compared to other subbands. Because the quantization error generated by an uniform quantizer is independent of the signal amplitude (the value of the color-DCT components), the SNR will be higher in those subbands with a higher gain.\n",
    "\n",
    "Moreover, as a consequence of that the number of high energy coefficients tends to be small (depending among other factors on the signal, of course) and the rest of coefficients are going to be zero-ed by the quantizer, if we apply a entropy compressor in the transform domain, the compression ratio compared to not using any transform should increase if we comparee such ratio to using the same entropy method applied directly over the RGB domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "#plt.rcParams['text.usetex'] = True\n",
    "#plt.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}'] #for \\text command\n",
    "import pylab\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import os\n",
    "!ln -sf ~/quantization/deadzone_quantizer.py .\n",
    "!ln -sf ~/quantization/midtread_quantizer.py .\n",
    "!ln -sf ~/quantization/midrise_quantizer.py .\n",
    "!ln -sf ~/quantization/distortion.py .\n",
    "!ln -sf ~/quantization/information.py .\n",
    "!ln -sf ~/MRVC/src/color_DCT.py .\n",
    "!ln -sf ~/MRVC/src/debug.py .\n",
    "!ln -sf ~/MRVC/src/image_3.py .\n",
    "!ln -sf ~/MRVC/src/image_1.py .\n",
    "!ln -sf ../common.py .\n",
    "import deadzone_quantizer as deadzone\n",
    "import midtread_quantizer as midtread\n",
    "import midrise_quantizer as midrise\n",
    "import color_DCT\n",
    "import distortion\n",
    "import information\n",
    "import image_3 as RGB_image\n",
    "import image_1 as gray_image\n",
    "import colored\n",
    "import common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix of the RGB image to be quantized.\n",
    "\n",
    "home = os.environ[\"HOME\"]\n",
    "fn = home + \"/MRVC/sequences/lena_color/\"\n",
    "#fn = home + \"/MRVC/sequences/stockholm/\"\n",
    "image_dtype = np.uint8 # For 8 bpp/component images\n",
    "#image_dtype = np.uint16 # For 16 bpp/component images\n",
    "\n",
    "DCT_components = ['0', '1', '2']\n",
    "\n",
    "# Number of quantization steps.\n",
    "N_Q_steps = 8\n",
    "#Q_steps = [256*i/N_Q_steps for i in range(N_Q_steps + 1, 0, -1)]\n",
    "Q_steps = [2**i for i in range(8, 0, -1)]\n",
    "print(Q_steps)\n",
    "\n",
    "#quantizer = midtread\n",
    "quantizer = deadzone\n",
    "#quantizer = midrise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_img = RGB_image.read(fn).astype(image_dtype)\n",
    "common.show(RGB_img, fn + \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (RGB -> ColorDCT) transform of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "DCT_type = 3\n",
    "norm = \"ortho\" # Orthonormal: orthogonal + unitary (unit gain in both directions of the transform)\n",
    "#norm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def color_DCT(RGB_img):\n",
    "    DCT_img = np.empty_like(RGB_img).astype(np.float)\n",
    "    for y in range(RGB_img.shape[0]):\n",
    "        for x in range(RGB_img.shape[1]):\n",
    "            DCT_img[y, x] = dct(RGB_img[y, x], type=DCT_type, norm=norm)\n",
    "    return DCT_img\n",
    "\n",
    "def color_IDCT(DCT_img):\n",
    "    RGB_img = np.empty_like(DCT_img)#.astype(image_dtype)\n",
    "    for y in range(DCT_img.shape[0]):\n",
    "        for x in range(DCT_img.shape[1]):\n",
    "            RGB_img[y, x] = idct(DCT_img[y, x], type=DCT_type, norm=norm)\n",
    "    return RGB_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DCT_img = color_DCT(RGB_img)\n",
    "DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "print(DCT_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show_gray(DCT_img[..., 0], fn + \"000 (DCT0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show_gray(DCT_img[..., 1], fn + \"000 (DCT1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show_gray(DCT_img[..., 2], fn + \"000 (DCT2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy of the DCT components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT0_avg_energy = information.average_energy(DCT_img[..., 0])\n",
    "DCT1_avg_energy = information.average_energy(DCT_img[..., 1])\n",
    "DCT2_avg_energy = information.average_energy(DCT_img[..., 2])\n",
    "print(f\"Average energy DCT_img[..., 0] = {int(DCT0_avg_energy)}\")\n",
    "print(f\"Average energy DCT_img[..., 1] = {int(DCT1_avg_energy)}\")\n",
    "print(f\"Average energy DCT_img[..., 2] = {int(DCT2_avg_energy)}\")\n",
    "total_DCT_avg_energy = DCT0_avg_energy + DCT1_avg_energy + DCT2_avg_energy\n",
    "print(f\"Total average energy (computed by adding the energies of the DCT coefficients {int(DCT0_avg_energy)} + {int(DCT1_avg_energy)} + {int(DCT2_avg_energy)} = {int(total_DCT_avg_energy)}\")\n",
    "print(f\"Total RGB average energy (computed directly from the RGB image) = {int(information.average_energy(RGB_img)*3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the forward DCT is energy preserving (unitary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_recons_img = color_DCT.to_RGB(DCT_img)\n",
    "print(f\"Total RGB average energy (computed from the reconstructed RGB image) = {int(information.average_energy(RGB_recons_img)*3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same can be said of the backward transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (RGB <-> ColorDCT) transform error\n",
    "\n",
    "The DCT transform is irreversible. In general, only integer arithmetic operations guarantees reversibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show(RGB_recons_img, fn + \"000.png (DCT recons)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(RGB_img, RGB_recons_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RGB_img.max(), RGB_img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RGB_recons_img.max(), RGB_recons_img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show(RGB_img - RGB_recons_img.astype(image_dtype), \"Reconstruction error (rounding error) color-DCT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative gains of the synthesis filters\n",
    "\n",
    "The synthesis filters gains are important because the quantization steps of each DCT component should be adjusted in order to effectively provide the desired number of [bins](http://www.winlab.rutgers.edu/~crose/322_html/quantization.pdf) (different dequantized values) in each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(val):\n",
    "    DCT0_delta = np.array([val, 0, 0])\n",
    "    RGB_DCT0_delta = idct(DCT0_delta, type=DCT_type, norm=norm)\n",
    "    RGB_energy_DCT0_delta = information.energy(RGB_DCT0_delta)\n",
    "    \n",
    "    DCT1_delta = np.array([0, val, 0])\n",
    "    RGB_DCT1_delta = idct(DCT1_delta, type=DCT_type, norm=norm)\n",
    "    RGB_energy_DCT1_delta = information.energy(RGB_DCT1_delta)\n",
    "    \n",
    "    DCT2_delta = np.array([0, 0, val])\n",
    "    RGB_DCT2_delta = idct(DCT2_delta, type=DCT_type, norm=norm)\n",
    "    RGB_energy_DCT2_delta = information.energy(RGB_DCT2_delta)\n",
    "    \n",
    "    zero = np.array([0, 0, 0])\n",
    "    RGB_zero = idct(zero, type=DCT_type, norm=norm)\n",
    "    RGB_energy_zero = information.energy(RGB_zero)\n",
    "    \n",
    "    print(f\"{val}^2 = {val*val}\")\n",
    "    \n",
    "    print(f\"Energy of {DCT0_delta} in the RGB domain ({RGB_DCT0_delta}) = {RGB_energy_DCT0_delta}\")\n",
    "    print(f\"Energy of {DCT1_delta} in the RGB domain ({RGB_DCT1_delta}) = {RGB_energy_DCT1_delta}\")\n",
    "    print(f\"Energy of {DCT2_delta} in the RGB domain ({RGB_DCT2_delta}) = {RGB_energy_DCT2_delta}\")\n",
    "    print(f\"Energy of {zero} in the RGB domain ({RGB_zero}) = {RGB_energy_zero}\")\n",
    "    \n",
    "    max_ = max(RGB_energy_DCT0_delta, RGB_energy_DCT1_delta, RGB_energy_DCT2_delta)\n",
    "    DCT0_relative_gain = RGB_energy_DCT0_delta / max_\n",
    "    DCT1_relative_gain = RGB_energy_DCT1_delta / max_\n",
    "    DCT2_relative_gain = RGB_energy_DCT2_delta / max_\n",
    "    print(f\"Relative gain of DCT0 component = {DCT0_relative_gain}\")\n",
    "    print(f\"Relative gain of DCT1 component = {DCT1_relative_gain}\")\n",
    "    print(f\"Relative gain of DCT2 component = {DCT2_relative_gain}\")\n",
    "    \n",
    "print_info(255)\n",
    "print()\n",
    "print_info(1)\n",
    "print()\n",
    "print_info(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gain of each DCT inverse filter is 1. Therefore, the optimal quantization pattern is $\\Delta_{\\text{DCT0}} = \\Delta_{\\text{DCT1}} = \\Delta_{\\text{DCT2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude shift in the DCT domain\n",
    "\n",
    "To decide how to quantize, it is necessary to known how the amplitudes of the original image are *translated* to the transform domain. A good choice to find out this is to transform noise. In our case, lets use a random image with ([normal](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) [Gaussian noise](https://en.wikipedia.org/wiki/Gaussian_noise) with mean 128, DCT-it, and check where the transformed noise has its mean in each component. Notice that, by definition, the noise cannot be decorrelated by transforms, and therefore, the noise is simply transfered to the transform domain. Thus, depending on where the transformed noise has mean, we can decide if the signal must be shifted before or after the transform. Notice that the input signal to a dead-zone quantizer must have 0 mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc = mean, scale=standard deviation, size=number of samples\n",
    "RGB_noise = np.random.normal(loc=0, scale=10, size=512*512*3).reshape(512,512,3)#.astype(image_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show(RGB_noise, \"Gaussian RGB noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_noise = color_DCT.from_RGB(RGB_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show_gray(DCT_noise[..., 0], \"Gaussian DCT0 noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show_gray(DCT_noise[..., 1], \"Gaussian DCT1 noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.show_gray(DCT_noise[..., 2], \"Gaussian DCT2 noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DCT does not modify the mean of the signal when it has 0 mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple quantization in the DCT domain ($\\Delta_{\\text{DCT0}} = \\Delta_{\\text{DCT1}} = \\Delta_{\\text{DCT2}}$)\n",
    "Notice that, because the transform is orthogonal, the distortion can be measured in both, the RGB and the DCT domains, and that when the quantization steps are high enough, a 128-mean reconstructed RGB image should be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCT_same_delta_RD_curve_DCTdistortion(RGB_img, Q_steps, quantizer):\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    RGB_img[..., 0] -= np.average(RGB_img[..., 0])\n",
    "    RGB_img[..., 1] -= np.average(RGB_img[..., 1])\n",
    "    RGB_img[..., 2] -= np.average(RGB_img[..., 2])\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)#.astype(np.int16)\n",
    "    points = []\n",
    "    #common.show(DCT_img,'')\n",
    "    for Q_step in Q_steps:\n",
    "        DCT_y, k = quantizer.quan_dequan(DCT_img, Q_step)\n",
    "        #common.show(DCT_y)\n",
    "        print(np.max(DCT_y), np.min(DCT_y), np.average(DCT_y), DCT_y.dtype)\n",
    "        BPP = common.bits_per_color_pixel((k + 128).astype(np.uint8), str(Q_step) + '_')\n",
    "        print(\"Used quantization indexes:\", np.unique((k + 128).astype(np.uint8)))\n",
    "        RMSE = distortion.RMSE(DCT_img, DCT_y) # Uncomment this line for measuring the distortion in the DCT domain\n",
    "        points.append((BPP, RMSE))\n",
    "        print(f\"q_step={Q_step}, rate={BPP} bits/pixel, distortion={RMSE}\")\n",
    "    return points\n",
    "\n",
    "DCT_same_delta_RD_points_DCTdistortion = DCT_same_delta_RD_curve_DCTdistortion(RGB_img, Q_steps, quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def DCT_same_delta_RD_curve_RGBdistortion(RGB_img, Q_steps, quantizer):\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    avg0 = np.average(RGB_img[..., 0])\n",
    "    avg1 = np.average(RGB_img[..., 1])\n",
    "    avg2 = np.average(RGB_img[..., 2])\n",
    "    RGB_img[..., 0] -= avg0\n",
    "    RGB_img[..., 1] -= avg1\n",
    "    RGB_img[..., 2] -= avg2\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)#.astype(np.int16)\n",
    "    points = []\n",
    "    common.show(RGB_img,'')\n",
    "    #DCT_img -= (215-128)\n",
    "    for Q_step in Q_steps:\n",
    "        DCT_y, k = quantizer.quan_dequan(DCT_img, Q_step)\n",
    "        #common.show(DCT_y)\n",
    "        print(np.max(DCT_y), np.min(DCT_y), np.average(DCT_y), DCT_y.dtype)\n",
    "        #common.show(DCT_y, '')\n",
    "        BPP = common.bits_per_color_pixel((k + 128).astype(np.uint8), str(Q_step) + '_')\n",
    "        print(\"Used quantization indexes:\", np.unique((k + 128).astype(np.uint8)))\n",
    "        #RGB_y = color_IDCT(DCT_y + (215-128))                    # Uncomment these lines for measuring\n",
    "        RGB_y = color_DCT.to_RGB(DCT_y) # Uncomment these lines for measuring\n",
    "        #RGB_y[..., 0] += avg0\n",
    "        #RGB_y[..., 1] += avg1\n",
    "        #RGB_y[..., 2] += avg2\n",
    "        RMSE = distortion.RMSE(RGB_img, RGB_y) # the distortion in the RGB domain.\n",
    "        common.show(RGB_y, '')\n",
    "        #_distortion = distortion.RMSE(DCT_img, DCT_y) # Uncomment this line for measuring the distortion in the DCT domain\n",
    "        points.append((BPP, RMSE))\n",
    "        print(f\"q_step={Q_step}, rate={BPP} bits/pixel, distortion={RMSE}\")\n",
    "    return points\n",
    "\n",
    "DCT_same_delta_RD_points_RGBdistortion = DCT_same_delta_RD_curve_RGBdistortion(RGB_img, Q_steps, quantizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the RD curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DCT_same_delta_RD_points_DCTdistortion), c='r', marker='.', label=\"$\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$ (Distortion in DCT domain)\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*DCT_same_delta_RD_points_RGBdistortion), c='b', marker='.', label=\"$\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$ (Distortion in RGB domain)\", linestyle=\"dotted\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distortion can be measured in both domains, DCT and RGB. This is true because the DCT is orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with quantizing directly in the RGB domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_points = []\n",
    "with open(f'../05-RGB_compression/RGB.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        RGB_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RGB_points), c='b', marker='o', label=\"Quantization in the RGB domain\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*DCT_same_delta_RD_points_DCTdistortion), c='r', marker='x', label=\"$\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$\", linestyle=\"dotted\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The color-DCT removes the color redundancy, generating three components that are more compressible than the original RGB channels. This effect is more significant a low bit-rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal RD curve (measuring distortion in the color-DCT domain)\n",
    "Works because the color-DCT is orthogonal.\n",
    "\n",
    "As we did in the RGB domain, we will try to apply RDO in the color-DCT domain, to find out if a better RD curve than using $\\Delta_{\\text{DCT0}} = \\Delta_{\\text{DCT1}} = \\Delta_{\\text{DCT2}}$ can be obtained. However, as also happened with the RGB domain, the DCT components are independent (the DCT is orthogonal) and additive. Therefore, apart from generating a RD curve with more points, we should not expect to improve it.\n",
    "\n",
    "Notice that the distortion can be measured in both domains, color-DCT and RGB, because the transform is orthogonal.\n",
    "\n",
    "Therefore, such subbands should be encoded first in a progressive representation of the image (to obtain a RD curve) in the transform domain.\n",
    "\n",
    "To find such progressive quantization steps patterns (that in the case of the color-DCT has 3 dimensions, one for each color-DCT component) we will use (again, as we did to compress the images in the RGB domain) a RDO (Rate/Distortion Optimization) algorithm based on sorting the patterns by the slopes of the RD points in the corresponding affected subbands (remember that between two consecutive patterns, only one quantization step can replaced by the next smaller value).  \n",
    "\n",
    "The method `DCT_same_delta_RD_curve(img, Q_steps, quantizer)` generates a RD curve where each point is the result of using $\\Delta_{\\text{DCT0}} = \\Delta_{\\text{DCT1}} = \\Delta_{\\text{DCT2}}$. However, a better (at least with more points) RD curve can be generated with:\n",
    "\n",
    "1. Convert the image from RGB to DCT{0,1,2}.\n",
    "2. The RD curve of each DCT channel is computed, for a number of quantization steps, measuring the distortion in the RGB domain. We will quantize one component at each iteration and the rest of components will be unquantized. This is necessary to ensure that the low-pass component (DCT0) is always considered in each reconstruction. Otherwise, the distortion (at least using the RMSE) will not be estimated correctly.\n",
    "3. Compute the slope of each segment of the RD curve. Except for the most left point, the slopes are computed as the average between the slopes of the straight lines that connect to the corresponding point.\n",
    "4. For each quantization step, sort the RD points by their slope.\n",
    "5. Recompute the optimal RD curve using the quantization steps provided by the sorted RD points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD curve of each color-DCT component\n",
    "We consider only the rate and the distortion of the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_DCT_RD_curve_per_component(RGB_img, Q_steps, Q, components):\n",
    "    N_components = len(components)\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    for c in range(N_components):\n",
    "        avg = np.average(RGB_img[..., c])\n",
    "        RGB_img[..., c] -= avg\n",
    "        print(f\"channel={c} average={avg}\")\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "    DCT_img_copy = DCT_img.copy()\n",
    "    RD_points = []\n",
    "    for c in range(N_components):\n",
    "        RD_points.append([])\n",
    "    for Q_step in Q_steps:\n",
    "        DCT_k = Q.quantize(DCT_img, Q_step)\n",
    "        for component_index in range(N_components):\n",
    "            component_name = components[component_index]\n",
    "            DCT_y = np.zeros_like(DCT_img)\n",
    "            DCT_y = DCT_img_copy.copy()\n",
    "            DCT_y[..., component_index] = Q.dequantize(DCT_k[..., component_index], Q_step)\n",
    "            #print(Q_step, DCT_k[..., component_index].max(), DCT_k[..., component_index].min(), information.entropy(DCT_k[..., component_index]))\n",
    "            BPP = common.bits_per_gray_pixel(DCT_k[..., component_index] + 128, str(Q_step) + '_' + component_name + '_' + str(components[component_index]))\n",
    "            print(\"Used quantization indexes:\", np.unique(DCT_k[..., component_index] + 128))\n",
    "            #RGB_y = color_DCT.to_RGB(DCT_y)\n",
    "            #_distortion = distortion.RMSE(RGB_img, RGB_y)\n",
    "            RMSE = distortion.RMSE(DCT_img[..., component_index], DCT_y[..., component_index])\n",
    "            #common.show(RGB_y, components[component_index] + ' ' + str(Q_step))\n",
    "            RD_points[component_index].append((BPP, RMSE, component_name, Q_step))\n",
    "            print(f\"component_index={components[component_index]} q_step={Q_step}, rate={BPP} bits/pixel, distortion={RMSE}\")\n",
    "    return RD_points\n",
    "DCT_RD_curve_per_component = color_DCT_RD_curve_per_component(RGB_img, Q_steps, quantizer, DCT_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in range(3):\n",
    "#    DCT_RD_curve_per_component[c] = [DCT_RD_curve_per_component[c][0]] + DCT_RD_curve_per_component[c]\n",
    "#    DCT_RD_curve_per_component[c][0] = (0, -DCT_RD_curve_per_component[c][0][1], f'{c}', 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DCT_RD_curve_per_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points(points):\n",
    "    filtered_points = []\n",
    "    points_iterator = iter(points)\n",
    "    prev = next(points_iterator)\n",
    "    for curr in points_iterator:\n",
    "        if prev[0] >= curr[0]:\n",
    "            print(f\"deleted {prev}\")\n",
    "        else:\n",
    "            filtered_points.append(prev)\n",
    "        prev = curr\n",
    "    filtered_points.append(prev)\n",
    "    return filtered_points\n",
    "\n",
    "for c in range(3):\n",
    "    DCT_RD_curve_per_component[c] = filter_points(DCT_RD_curve_per_component[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_RD_curve_per_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the curve of each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[0]]), c='r', marker='.', label=\"$\\mathrm{DCT0}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[1]]), c='g', marker='.', label=\"$\\mathrm{DCT1}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[2]]), c='b', marker='.', label=\"$\\mathrm{DCT2}}$\", linestyle=\"dashed\")\n",
    "#pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[0][1:]]), c='r', marker='.', label=\"$\\mathrm{DCT0}}$\", linestyle=\"dashed\")\n",
    "#pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[1][1:]]), c='g', marker='.', label=\"$\\mathrm{DCT1}}$\", linestyle=\"dashed\")\n",
    "#pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[2][1:]]), c='b', marker='.', label=\"$\\mathrm{DCT2}}$\", linestyle=\"dashed\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE in RGB domain\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each curve shows the impact of variying the quantization step, in the corresponding component. Moreover, since the color-DCT is orthonormal, the gain of each component is 1. Therefore, the relative position of the curves shows the contribution (remember that if we are using the RMSE as the distortion metric and for this reason, me are basically measuring energy) of each component to the quality of the reconstructed image. Considering all this information, we should use the following progression of quantization steps patterns:\n",
    "1. `[256, 256, 256]` -> Constant gray image.\n",
    "2. `[128, 256, 256]` -> Grayscale image.\n",
    "3. `[ 64, 256, 256]` -> A higher quality image.\n",
    "4. `[128, 128, 128]` -> Same color image.\n",
    "5. `[ 64, 128, 128]` -> A higher quality color image.\n",
    "6. `[ 32, 128, 128]` -> ...\n",
    "7. `[ 16, 128, 128]` -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def color_DCT_optimal_curve(RGB_img, RD_points_per_component):\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    RGB_img[..., 0] -= np.average(RGB_img[..., 0])\n",
    "    RGB_img[..., 1] -= np.average(RGB_img[..., 1])\n",
    "    RGB_img[..., 2] -= np.average(RGB_img[..., 2])\n",
    "    points = []\n",
    "    Q_steps_per_component = [256, 256, 256] # This should generate a black image (the average of each component is 0).\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "    k = np.empty_like(DCT_img)\n",
    "    DCT_y = np.empty_like(DCT_img)\n",
    "    gains = [RD_points_per_component[0][0][1],\n",
    "             RD_points_per_component[1][0][1],\n",
    "             RD_points_per_component[2][0][1]]\n",
    "    max_gain = max(gains)\n",
    "    where = np.argmax(gains)\n",
    "    Q_steps_indexes = [0, 0, 0]\n",
    "    prev_Q_steps_indexes = [0, 0, 0]\n",
    "    #Q_steps_indexes[where] += 1\n",
    "    while Q_steps_per_component != [4, 4, 4]:\n",
    "        Q_steps_per_component = [256, 256, 256]\n",
    "        for i in range(3):\n",
    "            Q_steps_per_component[i] >>= Q_steps_indexes[i]\n",
    "        print(f\"{Q_steps_indexes} Quantization steps pattern: {Q_steps_per_component}\")\n",
    "        for component_index, Q_step in zip([0, 1, 2], Q_steps_per_component):\n",
    "            DCT_y[..., component_index], k[..., component_index] = quantizer.quan_dequan(DCT_img[..., component_index], Q_step)\n",
    "        BPP = common.bits_per_color_pixel((k + 128).astype(np.uint8), str(Q_steps_per_component) + '_')\n",
    "        print(\"Used quantization indexes:\", np.unique((k + 128).astype(np.uint8)))\n",
    "        RMSE = distortion.RMSE(DCT_img, DCT_y)\n",
    "        points.append((BPP, RMSE))\n",
    "        print(f\"rate={BPP} bits/pixel, distortion={RMSE}\")\n",
    "        Q_steps_indexes[where] += 1\n",
    "        slopes = []\n",
    "        print(\"Considering\")\n",
    "        for c in range(3):\n",
    "            if len(RD_points_per_component[c]) > (Q_steps_indexes[c] + 1):\n",
    "                delta_BPP = RD_points_per_component[c][Q_steps_indexes[c] + 1][0] - RD_points_per_component[c][Q_steps_indexes[c]][0]\n",
    "                delta_RMSE = RD_points_per_component[c][Q_steps_indexes[c]][1] - RD_points_per_component[c][Q_steps_indexes[c] + 1][1]            #print(prev_Q_steps_indexes, Q_steps_indexes, RD_points_per_component[c][prev_Q_steps_indexes[0]], RD_points_per_component[c][Q_steps_indexes[0]])\n",
    "                print(f\"delta_BPP={delta_BPP}\")\n",
    "                if delta_BPP > 0:\n",
    "                    slope = delta_RMSE/delta_BPP\n",
    "                else:\n",
    "                    slope = 0\n",
    "                slopes.append(slope)\n",
    "            else:\n",
    "                slopes.append(0)\n",
    "        print(f\"slopes={slopes}\")\n",
    "        where = np.argmax(slopes)\n",
    "        prev_Q_steps_indexes = Q_steps_indexes.copy()\n",
    "    return points\n",
    "\n",
    "DCT_optimal_RD_points = color_DCT_optimal_curve(RGB_img, DCT_RD_curve_per_component)\n",
    "DCT_optimal_RD_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the slope of each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slopes(RD_points):\n",
    "    counter = 0\n",
    "    RD_slopes = []\n",
    "    points_iterator = iter(RD_points)\n",
    "    next(points_iterator)\n",
    "    for i in points_iterator:\n",
    "        BPP = i[0] # Rate \n",
    "        delta_BPP = BPP - RD_points[counter][0]\n",
    "        RMSE = i[1] # Distortion\n",
    "        delta_RMSE = RMSE - RD_points[counter][1] \n",
    "        if delta_BPP > 0:\n",
    "            slope = abs(delta_RMSE/delta_BPP)\n",
    "        else:\n",
    "            slope = 0\n",
    "        component = i[2]\n",
    "        Q_step = i[3]\n",
    "        print((slope, i), delta_RMSE, delta_BPP)\n",
    "        RD_slopes.append((slope, component, Q_step))\n",
    "        counter += 1\n",
    "    return RD_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DCT0_slopes = common.compute_slopes(DCT_RD_curve_per_component[0])\n",
    "#DCT1_slopes = common.compute_slopes(DCT_RD_curve_per_component[1])\n",
    "#DCT2_slopes = common.compute_slopes(DCT_RD_curve_per_component[2])\n",
    "DCT0_slopes = compute_slopes(DCT_RD_curve_per_component[0])\n",
    "DCT1_slopes = compute_slopes(DCT_RD_curve_per_component[1])\n",
    "DCT2_slopes = compute_slopes(DCT_RD_curve_per_component[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT0_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT1_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT2_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the curves\n",
    "Remove those RD points that do not belong to the convex-hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT0_slopes = common.filter_slopes(DCT0_slopes)\n",
    "DCT0_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT1_slopes = common.filter_slopes(DCT1_slopes)\n",
    "DCT1_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT2_slopes = common.filter_slopes(DCT2_slopes)\n",
    "DCT2_slopes = common.filter_slopes(DCT2_slopes)\n",
    "DCT2_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the slopes at each quantization step\n",
    "Notice that the TPs (Truncation Points) generated in a component must be used in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_slopes = DCT0_slopes + DCT1_slopes + DCT2_slopes\n",
    "sorted_slopes = sorted(all_slopes, key=lambda x: x[0])[::-1]\n",
    "sorted_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the optimal RD curve\n",
    "And finally, let's compute the RD curve (remember that the previous points are only an estimation of the order in which the quantization steps should be increased in each component to build the RD curve, not the real RD curve that measures the distortion in the RGB domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCT_optimal_curve(RGB_img, sorted_slopes, quantizer, components):\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    RGB_img[..., 0] -= np.average(RGB_img[..., 0])\n",
    "    RGB_img[..., 1] -= np.average(RGB_img[..., 1])\n",
    "    RGB_img[..., 2] -= np.average(RGB_img[..., 2])\n",
    "    points = []\n",
    "    Q_steps_per_component = [256, 256, 256] # This should generate a black image (the average of each component is 0).\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "    k = np.empty_like(DCT_img)\n",
    "    DCT_y = np.empty_like(DCT_img)\n",
    "    for i in sorted_slopes:\n",
    "        print(i)\n",
    "        component, Q_step = i[1], i[2]\n",
    "        Q_steps_per_component[components.index(component)] = Q_step\n",
    "        for c, Q_step in zip(components, Q_steps_per_component):\n",
    "            component_index = components.index(c)\n",
    "            DCT_y[..., component_index], k[..., component_index] = quantizer.quan_dequan(DCT_img[..., component_index], Q_step)\n",
    "        rate = common.bits_per_color_pixel((k + 128).astype(np.uint8), str(Q_steps_per_component) + '_')\n",
    "        print(\"Used quantization indexes:\", np.unique((k + 128).astype(np.uint8)))\n",
    "        #y_RGB = YCrCb.to_RGB(y + 128)\n",
    "        #RGB_y = color_DCT.to_RGB(DCT_y)               # Uncomment to compute distortion\n",
    "        #_distortion = distortion.RMSE(RGB_img, RGB_y)  # in the RGB domain.\n",
    "        _distortion = distortion.RMSE(DCT_img, DCT_y)  # Uncomment to compute distortion in the DCT domain.\n",
    "        #common.show(y_RGB, f\"Q_step={Q_steps_per_component}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"Q_step={Q_steps_per_component}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "\n",
    "\n",
    "DCT_optimal_RD_points = DCT_optimal_curve(RGB_img, sorted_slopes, quantizer, DCT_components)\n",
    "DCT_optimal_RD_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DCT_same_delta_RD_points_RGBdistortion), c='b', marker='o', label=\"$\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*DCT_optimal_RD_points), c='r', marker='x', label=\"Optimal\", linestyle=\"dotted\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('color_DCT.txt', 'w') as f:\n",
    "    for item in DCT_optimal_RD_points:\n",
    "        f.write(f\"{item[0]}\\t{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConclusiÃ³n\n",
    "The performance of the simple quantization solution ($\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$) is very close to the optimal one. This is normal because the DCT is orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal RD curve (measuring distortion in the RGB domain)\n",
    "Useful when the transform is not orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD curve of each DCT component\n",
    "\n",
    "Notice that the distortion has been measured in the RGB domain and that the components are not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_DCT_RD_curve_per_component_(RGB_img, Q_steps, Q, components):\n",
    "    N_components = len(components)\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    for c in range(N_components):\n",
    "        avg = np.average(RGB_img[..., c])\n",
    "        RGB_img[..., c] -= avg\n",
    "        print(f\"channel={c} average={avg}\")\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "    DCT_img_copy = DCT_img.copy()\n",
    "    RD_points = []\n",
    "    for c in range(N_components):\n",
    "        RD_points.append([])\n",
    "    for Q_step in Q_steps:\n",
    "        DCT_k = Q.quantize(DCT_img, Q_step)\n",
    "        for component_index in range(N_components):\n",
    "            component_name = components[component_index]\n",
    "            DCT_y = np.zeros_like(DCT_img)\n",
    "            DCT_y = DCT_img_copy.copy()\n",
    "            DCT_y[..., component_index] = Q.dequantize(DCT_k[..., component_index], Q_step)\n",
    "            #print(Q_step, DCT_k[..., component_index].max(), DCT_k[..., component_index].min(), information.entropy(DCT_k[..., component_index]))\n",
    "            rate = common.bits_per_gray_pixel(DCT_k[..., component_index], str(Q_step) + '_' + component_name + '_' + str(components[component_index]))\n",
    "            RGB_y = color_DCT.to_RGB(DCT_y)\n",
    "            _distortion = distortion.RMSE(RGB_img, RGB_y)\n",
    "            #common.show(RGB_y, components[component_index] + ' ' + str(Q_step))\n",
    "            RD_points[component_index].append((rate, _distortion, component_name, Q_step))\n",
    "            print(f\"component_index={components[component_index]} q_step={Q_step:>3}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return RD_points\n",
    "           \n",
    "def color_DCT_RD_curve_per_component(RGB_img, Q_steps, Q, components):\n",
    "    N_components = len(components)\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    for c in range(N_components):\n",
    "        avg = np.average(RGB_img[..., c])\n",
    "        RGB_img[..., c] -= avg\n",
    "        print(f\"channel={c} average={avg}\")\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "    DCT_img_copy = DCT_img.copy()\n",
    "    RD_points = []\n",
    "    for c in range(N_components):\n",
    "        RD_points.append([(0, 100000, c, 512)])\n",
    "        #RD_points.append([])\n",
    "    for Q_step in Q_steps:\n",
    "        for component_index in range(N_components):\n",
    "            component_name = components[component_index]\n",
    "            #DCT_k = np.zeros_like(DCT_img)\n",
    "            DCT_k = DCT_img_copy.copy()\n",
    "            DCT_y = DCT_img_copy.copy()\n",
    "            DCT_k[..., component_index] = Q.quantize(DCT_img[..., component_index], Q_step)\n",
    "            DCT_y[..., component_index] = Q.dequantize(DCT_k[..., component_index], Q_step)\n",
    "            #print(Q_step, DCT_k[..., component_index].max(), DCT_k[..., component_index].min(), information.entropy(DCT_k[..., component_index]))\n",
    "            BPP = common.bits_per_gray_pixel(DCT_k[..., component_index].astype(np.uint8), str(Q_step) + '_' + component_name + '_' + str(components[component_index]))\n",
    "            RGB_y = color_DCT.to_RGB(DCT_y)\n",
    "            RMSE = distortion.RMSE(RGB_img, RGB_y)\n",
    "            #common.show(RGB_y, components[component_index] + ' ' + str(Q_step))\n",
    "            RD_points[component_index].append((BPP, RMSE, component_name, Q_step))\n",
    "            print(f\"component_index={components[component_index]} q_step={Q_step}, rate={BPP} bits/pixel, distortion={RMSE}\")\n",
    "    return RD_points\n",
    "\n",
    "DCT_RD_curve_per_component = color_DCT_RD_curve_per_component(RGB_img, Q_steps, quantizer, DCT_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DCT_RD_curve_per_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the curve of each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "#pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[0]]), c='r', marker='.', label=\"$\\mathrm{DCT0}}$\", linestyle=\"dashed\")\n",
    "#pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[1]]), c='g', marker='.', label=\"$\\mathrm{DCT1}}$\", linestyle=\"dashed\")\n",
    "#pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[2]]), c='b', marker='.', label=\"$\\mathrm{DCT2}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[0][1:]]), c='r', marker='.', label=\"$\\mathrm{DCT0}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[1][1:]]), c='g', marker='.', label=\"$\\mathrm{DCT1}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*[(i[0], i[1]) for i in DCT_RD_curve_per_component[2][1:]]), c='b', marker='.', label=\"$\\mathrm{DCT2}}$\", linestyle=\"dashed\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE in RGB domain\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this plot represents the impact in the RGB domain of quantizing each component, keeping the rest unquantized. Therefore, the most important component from a RD point of view is DCT0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the slope of each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slopes(RD_points):\n",
    "    counter = 0\n",
    "    RD_slopes = []\n",
    "    points_iterator = iter(RD_points)\n",
    "    next(points_iterator)\n",
    "    for i in points_iterator:\n",
    "        BPP = i[0] # Rate \n",
    "        delta_BPP = BPP - RD_points[counter][0]\n",
    "        RMSE = i[1] # Distortion\n",
    "        delta_RMSE = RMSE - RD_points[counter][1] \n",
    "        if delta_BPP > 0:\n",
    "            slope = abs(delta_RMSE/delta_BPP)\n",
    "        else:\n",
    "            slope = 0\n",
    "        component = i[2]\n",
    "        Q_step = i[3]\n",
    "        print((slope, i), delta_RMSE, delta_BPP)\n",
    "        RD_slopes.append((slope, component, Q_step))\n",
    "        counter += 1\n",
    "    return RD_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DCT0_slopes = common.compute_slopes(DCT_RD_curve_per_component[0])\n",
    "#DCT1_slopes = common.compute_slopes(DCT_RD_curve_per_component[1])\n",
    "#DCT2_slopes = common.compute_slopes(DCT_RD_curve_per_component[2])\n",
    "DCT0_slopes = compute_slopes(DCT_RD_curve_per_component[0])\n",
    "DCT1_slopes = compute_slopes(DCT_RD_curve_per_component[1])\n",
    "DCT2_slopes = compute_slopes(DCT_RD_curve_per_component[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT0_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT1_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT2_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the curves\n",
    "Remove those RD points that do not belong to the convex-hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT0_slopes = common.filter_slopes(DCT0_slopes)\n",
    "DCT0_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT1_slopes = common.filter_slopes(DCT1_slopes)\n",
    "DCT1_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT2_slopes = common.filter_slopes(DCT2_slopes)\n",
    "DCT2_slopes = common.filter_slopes(DCT2_slopes)\n",
    "DCT2_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the slopes at each quantization step\n",
    "Notice that the TPs (Truncation Points) generated in a component must be used in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_slopes = DCT0_slopes + DCT1_slopes + DCT2_slopes\n",
    "sorted_slopes = sorted(all_slopes, key=lambda x: x[0])[::-1]\n",
    "sorted_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the optimal RD curve\n",
    "And finally, let's compute the RD curve (remember that the previous points are only an estimation of the order in which the quantization steps should be increased in each component to build the RD curve, not the real RD curve that measures the distortion in the RGB domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCT_optimal_curve(RGB_img, sorted_slopes, quantizer, components):\n",
    "    RGB_img = RGB_img.astype(float)\n",
    "    RGB_img[..., 0] -= np.average(RGB_img[..., 0])\n",
    "    RGB_img[..., 1] -= np.average(RGB_img[..., 1])\n",
    "    RGB_img[..., 2] -= np.average(RGB_img[..., 2])\n",
    "    points = []\n",
    "    Q_steps_per_component = [256, 256, 256] # This should generate a black image (the average of each component is 0).\n",
    "    DCT_img = color_DCT.from_RGB(RGB_img)\n",
    "    k = np.empty_like(DCT_img)\n",
    "    DCT_y = np.empty_like(DCT_img)\n",
    "    for i in sorted_slopes:\n",
    "        print(i)\n",
    "        component, Q_step = i[1], i[2]\n",
    "        Q_steps_per_component[components.index(component)] = Q_step\n",
    "        for c, Q_step in zip(components, Q_steps_per_component):\n",
    "            component_index = components.index(c)\n",
    "            DCT_y[..., component_index], k[..., component_index] = quantizer.quan_dequan(DCT_img[..., component_index], Q_step)\n",
    "        rate = common.bits_per_color_pixel(k.astype(np.uint8), str(Q_steps_per_component) + '_')\n",
    "        #y_RGB = YCrCb.to_RGB(y + 128)\n",
    "        #RGB_y = color_DCT.to_RGB(DCT_y)               # Uncomment to compute distortion\n",
    "        #_distortion = distortion.RMSE(RGB_img, RGB_y)  # in the RGB domain.\n",
    "        _distortion = distortion.RMSE(DCT_img, DCT_y)  # Uncomment to compute distortion in the DCT domain.\n",
    "        #common.show(y_RGB, f\"Q_step={Q_steps_per_component}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "        points.append((rate, _distortion))\n",
    "        print(f\"Q_step={Q_steps_per_component}, rate={rate:>7} bits/pixel, distortion={_distortion:>6.1f}\")\n",
    "    return points\n",
    "\n",
    "DCT_optimal_RD_points = DCT_optimal_curve(RGB_img, sorted_slopes, quantizer, DCT_components)\n",
    "DCT_optimal_RD_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DCT_same_delta_RD_points_RGBdistortion), c='b', marker='o', label=\"$\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*DCT_optimal_RD_points), c='r', marker='x', label=\"Optimal\", linestyle=\"dotted\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('color_DCT.txt', 'w') as f:\n",
    "    for item in DCT_optimal_RD_points:\n",
    "        f.write(f\"{item[0]}\\t{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConclusiÃ³n\n",
    "The performance of the simple quantization solution ($\\Delta_{\\mathrm{DCT0}} = \\Delta_{\\mathrm{DCT1}} = \\Delta_{\\mathrm{DCT2}}$) is very close to the optimal one. This is normal because the DCT is orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to quantizing directly in the RGB domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_points = []\n",
    "with open(f'../05-RGB_compression/RGB.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        RGB_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RGB_points), c='b', marker='o', label=\"Quantization in the RGB domain\", linestyle=\"dashed\")\n",
    "pylab.plot(*zip(*DCT_optimal_RD_points), c='r', marker='x', label=\"Quantization in the color-DCT domain\", linestyle=\"dotted\")\n",
    "pylab.title(\"Rate/Distortion\")\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "pylab.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
