\input{../../definitions}
\title{\SM{} - Study Guide - Milestone 10: IPP... Coding in the Image Domain}

\maketitle

\tableofcontents

\section{Description}

\subsection{Intra (I) video coding}

In the III... (or Intra video) coding, the
\href{https://sistemas-multimedia.github.io/milestones/07-DCT/}{2D
  block-DWT}, the
\href{https://sistemas-multimedia.github.io/milestones/08-DWT/}{2D
  DWT}, or any other spatial transform, is used on sequences of frames
(images) to exploit the spatial correlation. This is achieved by
simply iterating the spatial decorrelation as it is described in the
Algorithm~\ref{alg:III_coding}~\cite{taubman2002jpeg2000}, where $V$
in the input sequence and $S$ controls the number of SRLs (Spatial
Resolution Levels)\footnote{Notice that at least one SRL is always
available for each image or video sequence}. The synthesis transform
is computed using the Algorithm~\ref{alg:III_decoding}. In the
Fig.~\ref{fig:III} there is an example of the decomposition generated
for three frames $V_0$, $V_1$ and $V_2$.

\begin{myalg}{III-coding}{$\mathbf{V}$ /* original video sequence */, $S$ /* Number of extra levels */}{$\mathbf{O}$ /* transformed video sequence */}
  \label{alg:III_coding}
  \begin{enumerate}
  \item ${\mathbf O}=\{\}$ /* empty sequence */.
  \item for ${\mathbf V}_i\in {\mathbf V}$:
    \begin{enumerate}
    \item ${\mathbf O}_i\leftarrow\text{2D-T}^{S}({\mathbf V}_i)$ /* 2D analysis spatial transform */.
    \end{enumerate}
  \end{enumerate}
\end{myalg}

\begin{myalg}{III-decoding}{$\mathbf{O}$ /* transformed video sequence */, $S$ /* Number of extra levels */}{$\mathbf{V}$ /* original video sequence */}
  \label{alg:III_decoding}
  \begin{enumerate}
  \item ${\mathbf V}=\{\}$ /* empty sequence */.
  \item for ${\mathbf O}_i\in {\mathbf O}$:
    \begin{enumerate}
    \item ${\mathbf V}_i\leftarrow\text{2D-T}^{-S}({\mathbf O}_i)$ /* 2D synthesis spatial transform */.
    \end{enumerate}
  \end{enumerate}
\end{myalg}

\begin{figure}
  \centering
  \myfig{graphics/forward_MDWT}{6cm}{600}
  \caption{Decomposition generated by 1-levels ($S=1$) 2D-DWT and the 2x2-DCT (block size is equal to $S+1$).}
  \label{fig:III}
\end{figure}

\subsection{Motion compensation prediction (P) video coding}
III... video coding is fast and good for video edition, but the
compression ratios are poor because the temporal correlation is not
removed. IPP... video coding (also called inter-coding) uses MC
(Motion Compensation) to exploit the temporal correlation in frame
sequences. IPP... encoders split the sequence into
\href{https://en.wikipedia.org/wiki/Group_of_pictures}{GOPs (Groups of
  Frames)}, where the first frame of each GOP is a I-type frame, and
the rest of frames of the GOP are P-type. P-frames are
motion-compensated frames and usually the reference frame is the
previous one, in the temporal order.

\subsection{Types of macro-blocks}
A P-type frame is created in two steps:
\begin{enumerate}
\item The frame is divided into non-overlapping blocks (typically of
  $16\times 16$ pixels), that in this context we will call,
  macro-blocks.
\item A prediction frame is generated using a field of motion vectors
  (one vector per matro-block) and a reference.
\item The prediction frame is substracted to the predicted frame,
  generating a prediction-error frame.
\end{enumerate}
In general, most of the time this procedure success in temporally
decorrelate the frames. However, it can also happen that when the
reference(s) frame(s) is very different from the predicted one, the
prediction-error frame has a higher entropy than the original
(predicted) one.

In order to minimize this inconvenient, most video coding standards
use the following types of macro-blocks:
\begin{enumerate}
\item I (intra): if the macro-block is not compensated.
\item P (predicted): if the macro-blocks is compensated.
\item B (bidirectionally predicted): if the macro-block is compensated
  using an anterior and a posterior frame.
\item S (skipped): if the macro-block is substituted by reference one
  (no substraction is performed).
\end{enumerate}
The decision of the type of each macro-block is performed at the
compressor, and this information is signaled in the code-stream. An
visual example of the decision of the type of the macro-blocks is
shown in the Figure~\ref{fig:macroblocks}.

\begin{figure}
  \centering
  \myfig{graphics/macroblocks}{6cm}{600}
  \caption{Types of macro-blocks.}
  \label{fig:macroblocks}
\end{figure}

\subsection{Macro-block type decision}
Ideally, the type (also called, mode) of the macro-blocks is decided
considering all the posibilities (I, P, B, or S) and selecting the
most beneficial one from a RD perpective, i.e., selecting the
alternative that minimizes the RD cost. This RDO is performed at the
macro-block level.

\subsection{Codec}
\begin{figure}
  \centering
    \svg{graphics/codec}{1100}
  \caption{A inter/intra video codec.}
\label{fig:IPP_codec}
\end{figure}

The Figure~\ref{fig:IPP_codec} describes an inter/intra video codec,
that corresponds to:

\begin{equation}
  {\mathbf W} = \text{color-T}({\mathbf V}_k),
  \tag{a}
\end{equation}

\begin{equation}
   {\mathbf W}_{k-1} = Z^{-1}({\mathbf W}, k-1),
  \tag{b}
\end{equation}
and by definition, $Z^{-1}({\mathbf W}, -1) = 0$,

\begin{equation}
  \overset{(k-1)\rightarrow k}{\mathbf M} = \text{ME}({\mathbf W}_{k-1}, {\mathbf W}_k),
  \tag{c}
\end{equation}
where ME stands for Motion Estimation, and by definition,
$\overset{(-1)\rightarrow 0}{{\mathbf M}}=0$,

\begin{equation}
  \overset{(k-1)\rightarrow k}{\mathbf M} = \overset{(k-1)\rightarrow k}{\mathbf M} \text{(lossless~coding)},
  \tag{d}
\end{equation}

\begin{equation}
  \overset{(k-1)\rightarrow k}{\mathbf M} = \overset{(k-1)\rightarrow k}{\mathbf M} \text{(lossless~decoding)},
  \tag{e}
\end{equation}

\begin{equation}
  {\mathbf E}_k = {\mathbf W}_k - \overset{\wedge}{{\mathbf W}}_k,
  \tag{f}
\end{equation}
where the symbol $-$ represents to the pixel-wise substraction,

\begin{equation}
  \overset{\sim}{{\mathbf E}_k} = \text{QE}({\mathbf E}_k),
  \tag{g}
\end{equation}
where QE$(\cdot)$ represents the lossy compression of the
prediction error texture data,

\begin{equation}
  \overset{\sim}{\mathbf E}_k = \text{DQ}^{-1}(\overset{\sim}{\mathbf E}_k),
  \tag{h}
\end{equation}
where DQ$^{-1}(\cdot)$ represents the decompression of the prediction
error texture data,

\begin{equation}
  \overset{\sim}{\mathbf W}_k \leftarrow \overset{\sim}{\mathbf E}_k + \overset{\wedge}{\mathbf W}_k,
  \tag{i}
\end{equation}
and notice that if $\overset{\wedge}{\mathbf W}_k=0$, then
$\overset{\sim}{\mathbf E}_k = \overset{\sim}{\mathbf W}_k$,

\begin{equation}
  \overset{\wedge}{\mathbf W}_k = \text{P}(\overset{\sim}{\mathbf W}_{k-1}, \overset{(k-1)\rightarrow k}{\mathbf M}),
  \tag{j}
\end{equation}
where P$(\cdot,\cdot)$ is a motion compensated predictor, and

\begin{equation}
   \overset{\wedge}{\mathbf W}_{k-1} = Z^{-1}(\overset{\wedge}{\mathbf W}, k-1),
  \tag{k}
\end{equation}
where by definition, $Z^{-1}(\overset{\wedge}{\mathbf W}, -1) = 0$, and

\begin{equation}
   {\mathbf V} = \text{color-T}^{-1}({\mathbf W}_k),
  \tag{l}
\end{equation}
is the inverse color transform.

Notice that if $\overset{\wedge}{{\mathbf W}}_k$ is similar to
${\mathbf W}_k$, then ${\mathbf E}_k$ will be approximately zero, and
therefore, easely compressed. Another interesting aspect to highlight
is that the encoder replicates de decoder in order to use the
reconstructed images as reference and avoid the drift error.

\section{What do I have to do?}

Run the notebook \href{https://github.com/Sistemas-Multimedia/MRVC/blob/master/src/image_IPP.ipynb}{image\_IPP.ipynb}. Use a different video (see
this
\href{https://github.com/Sistemas-Multimedia/MRVC/tree/master/sequences}{directory}). Check
the improvement of IPP... coding over III... coding. Visualize the
reconstructed sequence using \href{https://ffmpeg.org/ffplay.html}{\texttt{ffplay}}.

\section{Timming}

\section{Deliverables}

\section{Resources}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{image-pyramids,DWT,motion-estimation,HEVC,JPEG2000}
