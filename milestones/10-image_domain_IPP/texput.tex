\input{../../definitions}
\title{\SM{} - Study Guide - Milestone 10: IPP... Coding in the Image Domain}

\maketitle

\tableofcontents

\section{Description}

\subsection{Intra (I) video coding}

In the III... (or Intra video) coding, the
\href{https://sistemas-multimedia.github.io/milestones/07-DCT/}{2D
  block-DWT}, the
\href{https://sistemas-multimedia.github.io/milestones/08-DWT/}{2D
  DWT}, or any other spatial transform, is used on sequences of frames
(images) to exploit the spatial correlation. This is achieved by
simply iterating the spatial decorrelation as it is described in the
Algorithm~\ref{alg:III_coding}~\cite{taubman2002jpeg2000}, where $V$
in the input sequence and $S$ controls the number of SRLs (Spatial
Resolution Levels)\footnote{Notice that at least one SRL is always
available for each image or video sequence}. The synthesis transform
is computed using the Algorithm~\ref{alg:III_decoding}. In the
Fig.~\ref{fig:III} there is an example of the decomposition generated
for three frames $V_0$, $V_1$ and $V_2$.

\begin{myalg}{III-coding}{$\mathbf{V}$ /* original video sequence */, $S$ /* Number of extra levels */}{$\mathbf{O}$ /* transformed video sequence */}
  \label{alg:III_coding}
  \begin{enumerate}
  \item ${\mathbf O}=\{\}$ /* empty sequence */.
  \item for ${\mathbf V}_i\in {\mathbf V}$:
    \begin{enumerate}
    \item ${\mathbf O}_i\leftarrow\text{2D-T}^{S}({\mathbf V}_i)$ /* 2D analysis spatial transform */.
    \end{enumerate}
  \end{enumerate}
\end{myalg}

\begin{myalg}{III-decoding}{$\mathbf{O}$ /* transformed video sequence */, $S$ /* Number of extra levels */}{$\mathbf{V}$ /* original video sequence */}
  \label{alg:III_decoding}
  \begin{enumerate}
  \item ${\mathbf V}=\{\}$ /* empty sequence */.
  \item for ${\mathbf O}_i\in {\mathbf O}$:
    \begin{enumerate}
    \item ${\mathbf V}_i\leftarrow\text{2D-T}^{-S}({\mathbf O}_i)$ /* 2D synthesis spatial transform */.
    \end{enumerate}
  \end{enumerate}
\end{myalg}

\begin{figure}
  \centering
  \myfig{graphics/forward_MDWT}{6cm}{600}
  \caption{Decomposition generated by 1-levels ($S=1$) 2D-DWT and the 2x2-DCT (block size is equal to $S+1$).}
  \label{fig:III}
\end{figure}

\subsection{Motion compensation prediction (P) video coding}

III... video coding is fast and good for video edition, but the
compression ratios are poor because the temporal correlation is not
removed. IPP... video coding uses MC (Motion Compensation) to exploit
the temporal correlation in frame sequences. IPP... encoders split the
sequence into
\href{https://en.wikipedia.org/wiki/Group_of_pictures}{GOPs (Groups of
  Frames)}, where the first frame of each GOP is a I-type frame, and
the rest of frames of the GOP are P-type. P-frames are
motion-compensated frames and usually the reference frame is the
previous one, in the temporal order.

It's time to test the performance of the ME/MC process previously
described. We will encode a sequence of frames $\{W_k\}$ using the
pattern IPP..., which means that the first frame will be intra-coded
(I-type frame) and the rest of frames of the GOF (Group Of
\href{https://en.wikipedia.org/wiki/Group_of_pictures}{Frames}) will
be predicted-coded (P-type frame), respect to the previous one.

\begin{figure}
  \centering
    \svg{graphics/codec}{1100}
  \caption{A simple IPP... image codec.}
\label{fig:IPP_codec}
\end{figure}

IPP... coding can be done by the codec shown in the
Fig.~\ref{fig:IPP_codec}, where (for the case of the YCoCg transform):

\begin{equation}
  V_k \leftarrow \text{C}(W_k) =
  \begin{bmatrix}
    \frac{1}{4} &  \frac{1}{2}  &  \frac{1}{4} \\ 
    \frac{1}{2} &            0  & -\frac{1}{2} \\
    -\frac{1}{4} &  \frac{1}{2}  & -\frac{1}{4}
  \end{bmatrix}
  \begin{bmatrix}
    W_k.\text{R} \\
    W_k.\text{G} \\
    W_k.\text{B}
  \end{bmatrix}
  , \tag{a}
\end{equation}

\begin{equation}
  Z^{-1}(V_k) = V_{k-1},
  \tag{b}
\end{equation}
and by definition, $Z^{-1}(V_{-1}) = 0$,

\begin{equation}
  \overset{k\rightarrow k-1}{V} \leftarrow \text{M}(V_k, V_{k-1}),
  \tag{c}
\end{equation}
where M stands for Motion Estimation, and by definition,
$\overset{0\rightarrow (-1)}{V}=0$,

\begin{equation}
  \overset{\sim}{\overset{k\rightarrow k-1}{V}} \leftarrow \text{E}_{\overset{\rightarrow}{V}}(\overset{k\rightarrow k-1}{V}),
  \tag{d}
\end{equation}
where E$_{\overset{\rightarrow}{V}}(\cdot)$ represents the lossy
  compression of the motion data,

\begin{equation}
  \overset{\sim}{\overset{k\rightarrow k-1}{V}} \leftarrow \text{D}_{\overset{\rightarrow}{V}}(\overset{\sim}{\overset{k\rightarrow k-1}{V}}),
  \tag{e}
\end{equation}
where D$_{\overset{\rightarrow}{V}}(\cdot)$ represents the 
decompression of the motion data,

\begin{equation}
  E_k \leftarrow V_k - \overset{\wedge}{{V}}_k,
  \tag{f}
\end{equation}
where the symbol $-$ represents to the pixel-wise substraction,

\begin{equation}
  \overset{\sim}{E_k} \leftarrow \text{E}_{E}(E_k),
  \tag{g}
\end{equation}
where E$_{E}(\cdot)$ represents the lossy compression of the
prediction error texture data,

\begin{equation}
  \overset{\sim}{E}_k \leftarrow \text{D}_{E}(\overset{\sim}{E}_k),
  \tag{h}
\end{equation}
where D$_{E}(\cdot)$ represents the decompression of the prediction
error texture data,

\begin{equation}
  \overset{\sim}{V}_k \leftarrow \overset{\sim}{E}_k + \overset{\wedge}{V}_k,
  \tag{i}
\end{equation}
and notice that if $\overset{\wedge}{V}_k=0$, then
$\overset{\sim}{E}_k = \overset{\sim}{V}_k$,

\begin{equation}
  \overset{\wedge}{V}_k \leftarrow \text{P}(\overset{\sim}{\overset{k\rightarrow k-1}{V}}, \overset{\sim}{V}_{k-1}),
  \tag{j}
\end{equation}
where P$(\cdot,\cdot)$ is a motion compensated predictor.

Notice that if $\overset{\wedge}{{V}}_k$ is similar to $V_k$, then
$E_k$ will be approximately zero, and therefore, easely
compressed. Another interesting aspect to highlight is that the
encoder replicates de decoder in order to use the reconstructed images
as reference and avoid the drift error.

\section{What do I have to do?}

Run the notebook \href{https://github.com/Sistemas-Multimedia/MRVC/blob/master/src/image_IPP.ipynb}{image\_IPP.ipynb}. Use a different video (see
this
\href{https://github.com/Sistemas-Multimedia/MRVC/tree/master/sequences}{directory}). Check
the improvement of IPP... coding over III... coding. Visualize the
reconstructed sequence using \href{https://ffmpeg.org/ffplay.html}{\texttt{ffplay}}.

\section{Timming}

\section{Deliverables}

\section{Resources}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{image-pyramids,DWT,motion-estimation,HEVC,JPEG2000}
