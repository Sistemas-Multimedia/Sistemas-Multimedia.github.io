{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/10-ME/full_search_block_ME.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full search block-based ME (Motion Estimation)\n",
    "The predicted frame is divided into blocks and each one is characterized by a motion vector using exhaustive search. This guarantees reaching the global optimal (the best motion field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "!ln -sf ~/MRVC/src/image_3.py .\n",
    "import image_3\n",
    "!ln -sf ~/MRVC/src/image_1.py .\n",
    "import image_1\n",
    "!ln -sf ~/MRVC/src/YCoCg.py .\n",
    "import YCoCg as YUV\n",
    "!ln -sf ~/MRVC/src/motion.py .\n",
    "!ln -sf ~/MRVC/src/config.py .\n",
    "import motion\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "plt.rcParams['text.usetex'] = True\n",
    "!ln -sf ~/quantization/information.py .\n",
    "import information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 1).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1.show(R, \"reference $R$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_1.show(P, \"predicted $P$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top circle moves to the right and the bottom circle moves to the left. Therefore, if we want to generate the predicted frame (bottom) from the reference one (top), all the top MVs (Motion Vectors) related to the circle should be (x=1, y=0), and all the bottom MVs (-1, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def full_search_block_based_ME(P, R, block_side=16, max_abs_motion=8):\n",
    "    \n",
    "    def local_search(by, bx):\n",
    "        errors_by_search_area = np.empty((2*max_abs_motion + 1, 2*max_abs_motion + 1))\n",
    "        for ry in range(-max_abs_motion, max_abs_motion + 1):\n",
    "            for rx in range(-max_abs_motion, max_abs_motion + 1):\n",
    "                R_block = extended_R[by*block_side + ry + max_abs_motion:\n",
    "                                    (by + 1)*block_side + ry + max_abs_motion,\n",
    "                                    bx*block_side + rx + max_abs_motion:\n",
    "                                    (bx + 1)*block_side + rx + max_abs_motion]\n",
    "                #show_frame(R_block, f\"R ({by} {bx} {ry} {rx} {by*block_side + ry + max_abs_motion}:{(by + 1)*block_side + ry + max_abs_motion}, {bx*block_side + rx + max_abs_motion}:{(bx + 1)*block_side + rx + max_abs_motion})\")\n",
    "                P_block = P[by*block_side : (by + 1)*block_side, bx*block_side : (bx + 1)*block_side]\n",
    "                #show_frame(P_block, f\"P ({by*block_side}:{(by + 1)*block_side},{bx*block_side}:{(bx + 1)*block_side})\")\n",
    "                #errors_in_search_area = np.abs(R_block - P_block)\n",
    "                #error_by_block = np.sum(errors_in_search_area)\n",
    "                error = R_block.astype(np.float32) - P_block\n",
    "                errors_in_search_area = error*error\n",
    "                error_by_block = np.average(errors_in_search_area)\n",
    "                #show_frame(errors_in_search_area, f\"by={by} bx={bx} ry={ry} rx={rx} error={error_by_block}\")\n",
    "                errors_by_search_area[ry + max_abs_motion, rx + max_abs_motion] = error_by_block\n",
    "                #show_frame(errors_by_search_area, \"errors\")\n",
    "        mv_index = np.argmin(errors_by_search_area)\n",
    "        if errors_by_search_area[max_abs_motion, max_abs_motion] == errors_by_search_area[0, 0]:\n",
    "            MV_y, MV_x = 0, 0\n",
    "        else:\n",
    "            MV_y = mv_index // (2*max_abs_motion + 1) - max_abs_motion\n",
    "            MV_x = mv_index  % (2*max_abs_motion + 1) - max_abs_motion\n",
    "        #print(\"index=\", mv_index, \"y=\", MV_y, \"x=\", MV_x)\n",
    "        #print(errors_by_search_area.astype(np.int))\n",
    "        return MV_y, MV_x\n",
    "\n",
    "    assert max_abs_motion > 0\n",
    "    extended_R = cv.copyMakeBorder(R, max_abs_motion, max_abs_motion, max_abs_motion, max_abs_motion, cv.BORDER_REPLICATE) \n",
    "    extended_R[max_abs_motion : R.shape[0] + max_abs_motion,\n",
    "               max_abs_motion : R.shape[1] + max_abs_motion] = R\n",
    "    #show_frame(extended_R, \"extended R\")\n",
    "    blocks_in_y = P.shape[0]//block_side\n",
    "    blocks_in_x = P.shape[1]//block_side\n",
    "    MVs = np.zeros((blocks_in_y, blocks_in_x, 2), dtype=np.int8)\n",
    "    #print(blocks_in_y, blocks_in_x)\n",
    "    for by in range(blocks_in_y):\n",
    "        for bx in range(blocks_in_x):\n",
    "            MV_y, MV_x = local_search(by, bx)\n",
    "            MVs[by, bx] = (MV_x, MV_y)\n",
    "    return MVs\n",
    "\n",
    "block_side = 32\n",
    "max_abs_motion = 1\n",
    "MVs = full_search_block_based_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(P.shape[0]//block_side):\n",
    "    for x in range(P.shape[1]//block_side):\n",
    "        print(MVs[y, x], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate the MVs\n",
    "The predictor expects a dense motion field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "print(_MVs.shape)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hat_P = motion.make_prediction(R, _MVs)\n",
    "image_1.show(R, \"reference ${\\mathbf R}$\")\n",
    "image_1.show(P, \"predicted $P$\")\n",
    "image_1.show(hat_P, \"prediction $\\hat{P}$\")\n",
    "image_1.show(P-hat_P, \"prediction error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with moving circles (max_abs_motion=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 2).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1.show(R, \"reference ${\\mathbf R}$\")\n",
    "image_1.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 4\n",
    "MVs = full_search_block_based_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)\n",
    "motion.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hat_P = motion.make_prediction(R, _MVs)\n",
    "image_1.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "image_1.show(P-hat_P, \"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 0).astype(np.int16))[...,0]\n",
    "P = YUV.from_RGB(image_3.read(\"/home/vruiz/MRVC/sequences/moving_circles/\", 4).astype(np.int16))[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1.show(R, \"reference ${\\mathbf R}$\")\n",
    "image_1.show(P, \"predicted ${\\mathbf P}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 8\n",
    "MVs = full_search_block_based_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion.show_vectors(MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)\n",
    "motion.show_vectors(_MVs[::1, ::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = motion.make_prediction(R, _MVs)\n",
    "image_1.show(hat_P, \"prediction $\\hat{\\mathbf P}$\")\n",
    "image_1.show(P-hat_P, \"prediction error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with a real image\n",
    "A tile of Stockholm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... but first without using ME\n",
    "Notice that we work only with a tile of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_Y = slice(100,356)\n",
    "slice_X = slice(100,612)\n",
    "prefix = \"/home/vruiz/MRVC/sequences/stockholm/\"\n",
    "R = image_3.read(prefix, 0)[slice_Y, slice_X]\n",
    "P = image_3.read(prefix, 1)[slice_Y, slice_X]\n",
    "image_3.show(R, \"reference ${\\mathbf R}$\")\n",
    "entropy = information.entropy(P.flatten())\n",
    "image_3.show(P, \"predicted ${\\mathbf P}$\" + f\" entropy={entropy:1.2f} bits/component\")\n",
    "predicted_entropy = entropy\n",
    "P_R = np.clip(P.astype(np.int16) - R + 128, 0, 255)\n",
    "entropy = information.entropy(P_R.flatten())\n",
    "image_3.show(P_R.astype(np.uint8), \"(No ME) $({\\mathbf P} - {\\mathbf R})$\" + f\" entropy={entropy:1.2f} bits/component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and now using BBME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_side = 16\n",
    "max_abs_motion = 8\n",
    "MVs = full_search_block_based_ME(P, R, block_side=block_side, max_abs_motion=max_abs_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = information.entropy(MVs.flatten())\n",
    "motion_entropy = entropy\n",
    "motion.show_vectors(MVs[::1, ::1], title=\"${\\mathbf V}$\" + f\", {block_side}x{block_side} ME\" + f\", entropy={entropy:1.2f} bits/component\" +  f\", {MVs.shape[0]}x{MVs.shape[1]} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape[0]/block_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape[1]/block_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "zoom_MVs = np.empty((P.shape[0], P.shape[1], 2), dtype=np.float32)\n",
    "print(_MVs.shape)\n",
    "zoom_MVs[..., 0] = ndimage.zoom(MVs[..., 0], P.shape[0]/MVs.shape[0], order=0)\n",
    "zoom_MVs[..., 1] = ndimage.zoom(MVs[..., 1], P.shape[0]/MVs.shape[0], order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_P = motion.make_prediction(R, zoom_MVs)\n",
    "image_3.show(hat_P, \"$\\hat{\\mathbf P}$\" + f\", {block_side}x{block_side} ME\")\n",
    "P_hat_P = P - hat_P + 128\n",
    "entropy = information.entropy(P_hat_P.flatten())\n",
    "residue_entropy = entropy\n",
    "image_3.show(P_hat_P.astype(np.uint8), \"${\\mathbf P} - \\hat{\\mathbf P}$\" + f\", {block_side}x{block_side} ME\" + f\", entropy={entropy:1.2f} bits/component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entropy of the predicted frame:                 \", f\"{predicted_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy of the residue frame:                   \", f\"{residue_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy reduction in the texture:               \", f\"{predicted_entropy - residue_entropy:1.3f}\", \"bits/component\")\n",
    "print(\"Entropy of the components of the motion vectors:\", f\"{motion_entropy:1.3f}\", \"bits/component\")\n",
    "texture_length = residue_entropy * P.size\n",
    "motion_length = motion_entropy * MVs.size\n",
    "total_length = texture_length + motion_length\n",
    "total_entropy = total_length / P.size\n",
    "print(\"Entropy the texture + motion vectors:           \", f\"{total_entropy:1.3f}\", \"bits/component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate (visually) the ME on other sequences (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
