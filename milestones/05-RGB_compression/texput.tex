\input{../../definitions}
\title{\SM{} - Study Guide - Milestone 5: Compression of RGB (Red, Green, and Blue) images}

\maketitle

\tableofcontents

\section{Description}
\href{https://en.wikipedia.org/wiki/Visual_system}{Humans} are quite
efficient recognizing the information stored in images (and frames of
a video), even when this information has been degraded or partially
lost. \href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{Quantization}~\cite{sayood2017introduction,vetterli2014foundations}
is a technique that can remove the visual information that is less
relevant for us, and implies a
\href{https://en.wikipedia.org/wiki/Lossy_compression}{lossy coding},
which provides
\href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression
  ratios} usually at least one order of magnitude higher than using
\href{https://en.wikipedia.org/wiki/Lossless_compression}{lossless
  coding}.

In this milestone we will quantize an image in the
\href{https://en.wikipedia.org/wiki/RGB_color_model}{RGB\footnote{Red,
    Green and Blue: the primary colors.} color domain}. RGB is an
additive color system, which means that all colors \emph{start} with
black and are created by adding some intensity of the primary
colors~\cite{burger2016digital}. A digital
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{\textbf{quantizer}}
(typically denoted by $\text{Q}$) is an
\href{https://en.wikipedia.org/wiki/Data_compression}{encoding system}
that inputs a sequence of (digital) samples
${\mathbf x}=\{{\mathbf x}_i\}$ and outputs a sequence of quantization
indexes ${\mathbf k}$ (see the Fig.~\ref{fig:Q}). The inverse system,
called a \textbf{dequantizer} (denoted by $\text{Q}^{-1}$), recovers
an approximate version of ${\mathbf x}$ that we will denote by
$\tilde{{\mathbf x}}$, whose similitude with ${\mathbf x}$ inversely
depends on the quantization step $\Delta$. %Notice that
%although $\Delta$ is an input parameter to the quantizer, it has not
%been considered in the figure to keep it simpler.

We define the quantization error\footnote{Also called quantization
noise.}
\begin{equation}
  {\mathbf e}_i = {\mathbf x}_i - \tilde{{\mathbf x}}_i.
\end{equation}
This signal should be minimized in order to reduce the distortion
generated by the quantization.

\begin{figure}
  \centering
  \myfig{graphics/Q}{3cm}{300}
  \caption{Scalar quantization and dequantization of a signal.}
  \label{fig:Q}
\end{figure}

Quantizers can be classifies into:
\begin{enumerate}
\item \textbf{Scalar quantizers}: those that produce a quantization
  index ${\mathbf k}_i$ by each input sample ${\mathbf x}_i$.
\item \textbf{Vector quantizers}: that process the input by blocks of
  samples, called vectors, producing a quantization index by vector.
  Usually, the length of the quantization index is much shorter than
  the length of the vector, generating the compression. Vector
  Quantization (VQ) can remove auto-correlation in the encoded signal
  and therefore, is more efficient than Scalar Quantization
  (SQ). Unfortunately, the computational requirements of VQ are, by
  far, much higher than the needed by SQ. If we also consider that
  there are other techniques (such as transform coding, that we will
  see later) that are able to decorrelate the samples requiring less
  computational resources than VQ, we can understand why SQ has been
  selected, for example, in
  most \href{https://en.wikipedia.org/wiki/Image_compression}{image}
  and \href{https://en.wikipedia.org/wiki/Video_coding_format}{video
  codecs}.
\end{enumerate}

Quantizers can also be classified in:
\begin{enumerate}
\item \textbf{Uniform quantizers}: those in which $\Delta$ is
  idependent on the amplitude of the samples.
\item \textbf{Non-unifom quantizers}: on the contrary, when $\Delta$
  depends (directly or indirectly) on the amplitude of the samples. An
  example is a
  \href{https://en.wikipedia.org/wiki/Companding}{companded
    quantizer}.
\end{enumerate}

Non-uniform quantizers can be:
\begin{enumerate}
\item \textbf{Static quantizers}: if $\Delta$ is known \emph{a
priori}.
\item \textbf{Adaptive quantizers}: when $\Delta$ is adapted to
  minimize the quantization error, depending ``on-the-fly'' on the
  characteristics\footnote{Depending, for example, on the
    \href{https://en.wikipedia.org/wiki/Probability_density_function}{PDF}
    of the signal.} of the signal.
\end{enumerate}

Moreover, all quantizers can be classified into:
\begin{enumerate}
\item \textbf{Mid-tread quantizers}, if $\tilde{{\mathbf x}}_i$ can be ${\mathbf 0}$.
\item \textbf{Mid-rised quantizers}, if $\tilde{{\mathbf x}}_i$ never is ${\mathbf 0}$,
  even if ${\mathbf x}_i=0$.
\end{enumerate}

Finally, quantizers can be classified as:
\begin{enumerate}
\item \textbf{Dead-zone quantizers}, that are characterized by a QS of
  length $2\Delta$ for ${\mathbf x}_i=0$. Deadzone quantizers tends to
  remove the
  \href{https://en.wikipedia.org/wiki/Noise_(electronics)}{electronic
    noise} (that usually has an small amplitude compared to the input
  signal ${\mathbf x}$).\footnote{Notice that dead-zone quantizers
  should not be consdered uniform, and that all dead-zone quantizers,
  by definition, are mid-tread.}
\item \textbf{No dead-zone quantizers}, when the dead-zone does not
  exist.
\end{enumerate}

Notice that the dead-zone is placed where the SNR is smaller, because
the energy of the signal is very close to 0.

\begin{comment}
\begin{figure}
  \centering
  \myfig{io_map_mr}{5cm}{500}
  \caption{Input/output mapping of a mid-riser quantizer with $\Delta=2$.}
  \label{fig:iomap_mr}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_mr}{5cm}{500}
  \caption{Quantization error of a mid-riser quantizer with $\Delta=2$.}
  \label{fig:qe_mr}
\end{figure}

\begin{figure}
  \centering
  \myfig{io_map_mt}{5cm}{500}
  \caption{Input/output map of a mid-tread quantizer with $\Delta=2$.}
  \label{fig:iomap_mt}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_mt}{5cm}{500}
  \caption{Quantization error of a mid-tread quantizer with $\Delta=2$.}
  \label{fig:qe_mt}
\end{figure}

\begin{figure}
  \centering
  \myfig{io_map_dz}{5cm}{500}
  \caption{Input/output map of a dead-zone quantizer with $\Delta=2$.}
  \label{fig:iomap_dz}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_dz}{5cm}{500}
  \caption{Quantization error of a dead-zone quantizer with $\Delta=2$.}
  \label{fig:qe_dz}
\end{figure}
\end{comment}

The \href{https://github.com/vicente-gonzalez-ruiz/quantization/blob/master/digital_quantization.ipynb}{notebook} describes the behaviour of some scalar quantizers.
%Figs.~\ref{fig:iomap_mr}, \ref{fig:qe_mr}, \ref{fig:iomap_mt},
%\ref{fig:qe_mt}, \ref{fig:iomap_dz}, and \ref{fig:qe_dz} describe the
%behaviour of 3 different quantizers.  Use this
%\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-RGB_quantization/digital_quantization.ipynb}{notebook}
%to gain more insights about quantization.

\subsection{More insights about SQ and VQ used on RGB images}
SQ would be an optimal solution only if the image colors are uniformly
distributed within
\href{https://en.wikipedia.org/wiki/RGB_color_model}{the RGB
  cube}. However, the typical color distribution in natural images is
anything but uniform, with some regions of the color space being
densely populated and many colors entirely missing. In this case,
scalar quantization is not optimal because the interesting colors may
not be sampled with suﬃcient density while at the same time colors are
represented that do not appear in the image at
all~\cite{burger2016digital}.

On the other hand, VQ does not treat the individual color components
separately as does scalar quantization, but each color vector
${\mathbf C}_i = ({\mathbf R}_i, {\mathbf G}_i, {\mathbf B}_i )$ (or
pixel) in the image is treated as a single entity. Starting from a set
of original color tuples ${\mathbf C} = \{c_1, c_2, \ldots ,c_m\}$,
the task of vector quantization is:
\begin{enumerate}
\item to ﬁnd a set of $n$ representative color vectors
  ${\mathbf C}' = \{c'_1, c'_2 ,\ldots , c'_n \}$, and
\item to replace each original color ${\mathbf C}_i$ by one of the new
  color vectors ${\mathbf C}'_j\in {\mathbf C}'$, where $n$ is usually
  predetermined ($n < m$) and the resulting deviation from the
  original image shall be minimal. This is a combinatorial
  optimization problem in a rather large search space, which usually
  makes it impossible to determine a global optimum in adequate
  time. This is the reason why VQ methods only compute a ``local''
  optimum at best~\cite{burger2016digital}. Anyway, VQ is used in
  \href{https://en.wikipedia.org/wiki/Palette_(computing)}{``palletized''
    images}.
\end{enumerate}

Another key aspect to take into consideration is that the problem
previously mentioned about the under-optimality when quantizing
directly in the RGB domain can be minimized when the values of each
color component are decorrelated (using for example a color transform
as we will see in a future milestone), requesting less computation
than VQ.

\subsection{Quantization in the RGB domain}
Supposing that we are using a static uniform dead-zone quantizer, a
color RGB image can be quantized, component (sometimes also refered by
\href{https://en.wikipedia.org/wiki/Color_image}{channel} in the case
of the RGB images) by component, using QSs $\Delta_{\text{R}}$,
$\Delta_{\text{G}}$, and $\Delta_{\text{B}}$. A reasonable question
that arises here is: given a target bit-rate $R$ for the compressed
frame, how the QSs should be chosen to minimize the distortion? At
this point we can consider two different optimization perspectives. In
the first one, we consider strictly visual considerations, and
obviously, any alternative different from
\begin{equation}
  \Delta_{\text{R}} = \Delta_{\text{G}} = \Delta_{\text{B}}
  \label{eq:simple_Q}
\end{equation}
will produce some alteration in the color (also called the
``chroma'') of the reconstructed frame.

In the second perspective, only a pure
\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{Rate/Distortion
  (RD) performance} is considered. From a RD point of view, the best
combination of quantization steps is those that optimizes
(makes closer to the origin of coordinates) the RD curve. A RD curve
represents the trade-off between the distortion (typically the
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{Root
  Mean Square Error (RMSE)}) and the bit-rate (therefore, RMSE versus
bit/pixel).

\begin{figure}
  \centering
  \myfig{graphics/RD_slopes}{3cm}{300}
  \caption{Two RD curves with different shape.}
  \label{fig:RD_slopes}
\end{figure}

Normal RD curves are convex (see Fig.~\ref{fig:RD_slopes}), which
means that if $\lambda_i$ is the slope of the curve measured at the
$i$-th point of the curve (starting at the lowest bit-rate), it
usually hold that
\begin{equation}
  \lambda_i > \lambda_{i+1}.
\end{equation}
where $\lambda$ quantifies the trade-off between decreasing the
distortion\footnote{For this reason, the slopes are negative.} while
the bit-rate increases. Notice that, the higher the slope, the higher
the benefit in terms of RD. If we suppose now that the contribution to
the quality of each component is additive, that is
\begin{equation}
  D = D_{\text{R}} + D_{\text{G}} + D_{\text{B}},
\end{equation}
where $D$ denotes distortion, then the optimal QSs must satisfy
that~\cite{vetterli1995wavelets,sayood2017introduction}
\begin{equation}
  \lambda_{\text{R}} = \lambda_{\text{G}} = \lambda_{\text{B}}.
  \label{eq:optimal_quantization}
\end{equation}

To see this, lets suppose that we have used, for example, a set of QSs
so that $\lambda_{\text{R}}/2 = \lambda_{\text{G}} =
\lambda_{\text{B}},$ and that we still have room for more bits to
encode the frame. In this situation, the maximum benefit would be
obtained if and only if we decrease $\Delta_{\text{R}}$, because the
slope for the red component doubles the slope of the other
curves. Therefore, the optimal QSs are obtained when
Eq.~\ref{eq:optimal_quantization} is true. This can be seen in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-RGB_compression/RGB_compression.ipynb}{notebook}.

As it has been indicated, the previous quantization steps pattern (see
Equation~\ref{eq:simple_Q}) can be used to find the optimal RD curve
that relates distortion versus bit-rate. However, it is important to
realize that such relation between the quantization steps can be
determined because the contribution to the distortion satisfy two key
properties:
\begin{enumerate}
\item The contributions of the components are independent, and
  therefore, the total distortion is a linear combination of
  individual distortions.
\item The constribution to the distortion of each component is exactly
  the same.
\end{enumerate}

\begin{comment}
Thus, the optimal QSs should
operate in the curves with the same RD slope,
\begin{equation}
  \lambda_{\text{R}} = \lambda_{\text{G}} = \lambda_{\text{B}},
  \label{eq:optimal_quantization}
\end{equation}
for a given total bit-rate $R$, which implies that the contribution of
each component (the ratio between quality and bit-rate) to the quality
of $\tilde{x}$ has been highest
possible~\cite{vetterli1995wavelets,sayood2017introduction}.

Unfortunately, the previous procedure implies the computation of the
RD curve for each component, which is a time-consuming operation. For
this reason, and supposing that the statistics of each component are
similar and therefore, each component is going to generate a RD curve
with the same slopes for the same QSs, we can suppose that
Eq.~\ref{eq:simple_Q} satisfies Eq.~\ref{eq:optimal_quantization}.
\end{comment}

\section{What do I have to do?}
\begin{enumerate}
\item Please, using this
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-RGB_compression/RGB_quantization.ipynb}{notebook}
  try to find a QSs configuration where Eq.~\ref{eq:simple_Q} is not
  optimal (or at least there is a different configuration of QSs
  better that this equation).
\item Do you think that our lifes would be easier, to compress a RGB
  image, if we had an gray-image (lossy) compressor that allows to
  select the quantization step by its slope?
\end{enumerate}
%\begin{enumerate}
%\item Please, modify this
%  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-quantization/performance.ipynb}{notebook}
%  in order to use the
%  \href{https://docs.opencv.org/master/d4/da8/group__imgcodecs.html}{TIFF
%    and JPEG 2000 image formats} instead of PNG. Compare the RD
%  curves.
%\item In the previous
%  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-quantization/performance.ipynb}{notebook}
%  the three color channels, R, G, and B has been quantized using the
%  same QS ($\Delta_{\text{R}} = \Delta_{\text{G}} =
%  \Delta_{\text{B}}$). Do you think that this strategy minimizes the
%  quantization error?
%\item Compare the estimation provided by the entropy with the
%  DEFLATE's bit-rates.
%\end{enumerate}

\section{Timming}

Please, finish this milestone before the next class session.

\section{Deliverables}

None.

\section{Resources}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{data-compression,signal-processing,DWT,image-processing}
