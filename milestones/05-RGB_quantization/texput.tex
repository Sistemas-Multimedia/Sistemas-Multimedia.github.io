\input{../../definitions}
\title{\SM{} - Study Guide - Milestone 5: Quantizing in the RGB Domain}

\maketitle

\tableofcontents

\section{Description}
\href{https://en.wikipedia.org/wiki/Visual_system}{Humans} are quite
efficient recognizing the information stored in images (and frames of
a video), even when this information has been degraded or (partially)
lost. \href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{Quantization}~\cite{sayood2017introduction,vetterli2014foundations}
is a technique that can remove the part of the visual information that
is less relevant for us, and implies
\href{https://en.wikipedia.org/wiki/Lossy_compression}{lossy coding},
which provides
\href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression
  ratios} usually at least one order of magnitude higher than using
\href{https://en.wikipedia.org/wiki/Lossless_compression}{lossless
  coding}.

In this milestone we will quantize a frame in the
\href{https://en.wikipedia.org/wiki/RGB_color_model}{RGB\footnote{Red,
  Green and Blue: the primary colors.} color domain}. RGB is an additive color system, which means that all colors start with black and are created by adding the primary colors~\cite{burger2016digital}. A
\href{https://en.wikipedia.org/wiki/Quantization_(signal_processing)}{\textbf{quantizer}}
(typically denoted by $\text{Q}$) is an
\href{https://en.wikipedia.org/wiki/Data_compression}{encoding system}
that inputs a sequence of (digital) samples $x=\{x_i\}$ and outputs a
sequence of quantization indexes $k$ (see the Fig.~\ref{fig:Q}). The
inverse system, called a \textbf{dequantizer} (denoted by
$\text{Q}^{-1}$), recovers an approximate version of $x$ that we will
denote by $\tilde{x}$, whose similarity with $x$ inversely depends on
a frame quantization step (QS) $\Delta$. Notice that although $\Delta$
is an input parameter to the quantizer, it has not been considered in
the figure to keep it simpler.

We define the quantization error\footnote{Also called quantization
noise.}
\begin{equation}
  e_i = x_i - \tilde{x}_i,
\end{equation}
that obviously, should be minimized.

\begin{figure}
  \centering
  \myfig{graphics/Q}{3cm}{300}
  \caption{Scalar quantization and dequantization of a signal.}
  \label{fig:Q}
\end{figure}

Quantizers can be classifies into:
\begin{enumerate}
\item \textbf{Scalar quantizers}: those that produce a quantization
  index $k_i$ by each input sample $x_i$.
\item \textbf{Vector quantizers}: that process the input by blocks of
  samples, called vectors, producing a quantization index by vector,
  and usually, the length of the quantization index y much shorter
  than the length of the vector. Vector Quantization (VQ) can remove
  correlation and therefore, are more efficient that Scalar
  Quantization (SQ). Unfortunately, the computational requirements of VQ
  are, by far, higher than the needed by SQ. If we also consider that
  there are other techniques (such as transform coding) that are able
  to decorrelate the samples with less computation than VQ, we can
  understand why SQ has been selected, for example, in
  most \href{https://en.wikipedia.org/wiki/Video_coding_format}{video
  codecs}.
\end{enumerate}

Quantizers, also, can be classified as:
\begin{enumerate}
\item \textbf{Uniform quantizers}: those in which $\Delta$ is
  idependent on the amplitude of the samples.
\item \textbf{Non-unifom quantizers}, on the contrary, when $\Delta$
  depends (directly or indirectly) on the amplitude of the samples. An
  example is a
  \href{https://en.wikipedia.org/wiki/Companding}{companded
    quantizer}.
\end{enumerate}

Non-uniform quantizers can be:
\begin{enumerate}
\item \textbf{Static quantizers}: if $\Delta$ is known \emph{a
priori}.
\item \textbf{Adaptive quantizers}: when $\Delta$ is adapted to
  minimize the quantization error, depending ``on-the-fly'' on the
  characteristics\footnote{Depending, for example, on the
    \href{https://en.wikipedia.org/wiki/Probability_density_function}{PDF}
    of the signal.} of the signal.
\end{enumerate}

All quantizers can be classified into:
\begin{enumerate}
\item \textbf{Mid-tread quantizers}, if $\tilde{x}_i$ can be $0$.
\item \textbf{Mid-rised quantizers}, if $\tilde{x}_i$ never is $0$,
  even if $x_i=0$.
\end{enumerate}

Finally, quantizers can be classified as:
\begin{enumerate}
\item \textbf{Dead-zone quantizers}, that are characterized by a QS of
  length $2\Delta$ for $x_i=0$. Deadzone quantizers tends to remove
  the
  \href{https://en.wikipedia.org/wiki/Noise_(electronics)}{electronic
    noise} (that usually has an small amplitude compared to the input
  signal $x$). Notice that dead-zone quantizers should not be
  consdered uniform, and that all dead-zone quantizers, by definition,
  are mid-tread.
\item \textbf{No dead-zone quantizers}, when the dead-zone does not
  exist.
\end{enumerate}

\begin{figure}
  \centering
  \myfig{iomap_mr}{5cm}{500}
  \caption{Input/output map of a mid-riser quantizer with $\Delta=2$.}
  \label{fig:iomap_mr}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_mr}{5cm}{500}
  \caption{Quantization error of a mid-riser quantizer with $\Delta=2$.}
  \label{fig:qe_mr}
\end{figure}

\begin{figure}
  \centering
  \myfig{iomap_mt}{5cm}{500}
  \caption{Input/output map of a mid-tread quantizer with $\Delta=2$.}
  \label{fig:iomap_mt}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_mt}{5cm}{500}
  \caption{Quantization error of a mid-tread quantizer with $\Delta=2$.}
  \label{fig:qe_mt}
\end{figure}

\begin{figure}
  \centering
  \myfig{iomap_dz}{5cm}{500}
  \caption{Input/output map of a dead-zone quantizer with $\Delta=2$.}
  \label{fig:iomap_dz}
\end{figure}

\begin{figure}
  \centering
  \myfig{qe_dz}{5cm}{500}
  \caption{Quantization error of a dead-zone quantizer with $\Delta=2$.}
  \label{fig:qe_dz}
\end{figure}

Figs.~\ref{fig:iomap_mr}, \ref{fig:qe_mr}, \ref{fig:iomap_mt},
\ref{fig:qe_mt}, \ref{fig:iomap_dz}, and \ref{fig:qe_dz} describe the
behaviour of 3 different quantizers.  Use this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-quantization/digital_quantization.ipynb}{notebook}
to gain more insights about quantization.

Scalar quantization is an optimal solution only if the image colors
are uniformly distributed within
\href{https://en.wikipedia.org/wiki/RGB_color_model}{the RGB
  cube}. However, the typical color distribution in natural images is
anything but uniform, with some regions of the color space being
densely populated and many colors entirely missing. In this case,
scalar quantization is not optimal because the interesting colors may
not be sampled with suﬃcient density while at the same time colors are
represented that do not appear in the image at
all~\cite{burger2016digital}.

On the other hand, vector quantization does not treat the individual
color components separately as does scalar quantization, but each
color vector $C_i = (R_i, G_i, B_i )$ or pixel in the image is treated
as a single entity. Starting from a set of original color tuples $C
= \{c_1, c_2, \ldots ,c_m\}$, the task of vector quantization is:
\begin{enumerate}
\item to ﬁnd a set of $n$ representative color vectors $C' = \{c'_1,
  c'_2 ,\ldots , c'_n \}$ and
\item to replace each original color $C_i$ by one of the new color
  vectors $C'_j\in C'$, where $n$ is usually predetermined ($n < m$)
  and the resulting deviation from the original image shall be
  minimal. This is a combinatorial optimization problem in a rather
  large search space, which usually makes it impossible to determine a
  global optimum in adequate time. This is the reason why VQ methods
  only compute a ``local'' optimum at best~\cite{burger2016digital}.
\end{enumerate}

Another key aspect to take into consideration is that the problem
previously mentioned about the under-optimality of quantizing directly
in the RGB domain can be minimized when the values of each color
component are decorrelated (using for example a spatial transform as
we will see in a future milestone), requesting much less computational
resources than VQ.

\subsection{Quantization in the RGB domain}
Supposing that we will use a static uniform dead-zone quantizer, a
color RGB image can be quantized component
(\href{https://en.wikipedia.org/wiki/Color_image}{channel}) by
component, using QSs $\Delta_{\text{R}}$, $\Delta_{\text{G}}$, and
$\Delta_{\text{B}}$. A reasonable question that arises here is: given
a target bit-rate $R$ for the compressed frame, how the QSs should be
chosen to minimize the distortion?  At this point we can consider two
different optimization perspectives. In the first one, we consider
strictly visual considerations, and obviously, any alternative
different from
\begin{equation}
  \Delta_{\text{R}} = \Delta_{\text{G}} = \Delta_{\text{B}}
  \label{eq:simple_Q}
\end{equation}
will produce some alteration in the color (also called the
``chroma'') of the reconstructed frame.

In the second one, only a pure
\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{Rate/Distortion
  (RD) performance} is considered. From a RD perspective, the best
combination of QSs is those that optimizes (makes closer to the origin
of coordinates) the RD curve. A RD curve expresses the distortion
(typically the
\href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{Root
  Mean Square Error (RMSE)}) as a function of the bit-rate. In the
case of encoding a RGB image, we have 3 RD curves, one for each
component. Thus, for example, the RD curve for the red channel measures,
for different QSs, the distortion of reconstructing only the red
channel as a function of the bit-rate generated for the corresponding
QS.

\begin{figure}
  \centering
  \myfig{graphics/RD_slopes}{3cm}{300}
  \caption{Two RD curves with different shape.}
  \label{fig:RD_slopes}
\end{figure}

Normal RD curves are convex (see Fig.~\ref{fig:RD_slopes}), which
means that if $\lambda_i$ is the slope of the curve measured at the
$i$-th point of the curve (starting at the lowest bit-rate), it always
hold that
\begin{equation}
  \lambda_i > \lambda_{i+1}.
\end{equation}
$\lambda$ quantifies the trade-off between decreasing the distortion
(the slopes are always negative) while the bit-rate increases (the
higher the slope, the higher the benefit). If we suppose now that the
contribution to the quality of each channel are additive, that is
\begin{equation}
  D = D_{\text{R}} + D_{\text{G}} + D_{\text{B}},
\end{equation}
where $D$ denotes distortion, then the optimal QSs must satisfy
that~\cite{vetterli1995wavelets,sayood2017introduction}
\begin{equation}
  \lambda_{\text{R}} = \lambda_{\text{G}} = \lambda_{\text{B}}.
  \label{eq:optimal_quantization}
\end{equation}

To see this, lets suppose that we have used, for example, a set of QSs
so that $\lambda_{\text{R}}/2 = \lambda_{\text{G}}
= \lambda_{\text{B}},$ and that we still have room for spending more
bits to encode the frame. In this situation, the maximum benefit would
be obtained if and only if we decrease $\Delta_{\text{R}}$, because
the slope for the red channel doubles the slope of the other
curves. Therefore, the optimal QSs are obtained when
Eq.~\ref{eq:optimal_quantization} is true. This can be seen in
this \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-RGB_quantization/RGB_quantization.ipynb}{notebook}.

\begin{comment}
Thus, the optimal QSs should
operate in the curves with the same RD slope,
\begin{equation}
  \lambda_{\text{R}} = \lambda_{\text{G}} = \lambda_{\text{B}},
  \label{eq:optimal_quantization}
\end{equation}
for a given total bit-rate $R$, which implies that the contribution of each channel (the ratio between
quality and bit-rate) to the quality of $\tilde{x}$ has been highest
possible~\cite{vetterli1995wavelets,sayood2017introduction}.

Unfortunately, the previous procedure implies the computation of the
RD curve for each channel, which is a time-consuming operation. For
this reason, and supposing that the statistics of each channel are
similar and therefore, each channel is going to generate a RD curve
with the same slopes for the same QSs, we can suppose that
Eq.~\ref{eq:simple_Q} satisfies Eq.~\ref{eq:optimal_quantization}.
\end{comment}

\section{What do I have to do?}
\begin{enumerate}
\item Please, using this
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-RGB_quantization/RGB_quantization.ipynb}{notebook}
  try to find a QSs configuration where Eq.~\ref{eq:simple_Q} is not
  optimal (or at least there is a different configuration of QSs
  better that this equation).
\item Do you think that our life would be easier if we had an image
  lossy compressor that allows to select the quantization step by its
  slope?
\end{enumerate}
%\begin{enumerate}
%\item Please, modify this
%  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-quantization/performance.ipynb}{notebook}
%  in order to use the
%  \href{https://docs.opencv.org/master/d4/da8/group__imgcodecs.html}{TIFF
%    and JPEG 2000 image formats} instead of PNG. Compare the RD
%  curves.
%\item In the previous
%  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/05-quantization/performance.ipynb}{notebook}
%  the three color channels, R, G, and B has been quantized using the
%  same QS ($\Delta_{\text{R}} = \Delta_{\text{G}} =
%  \Delta_{\text{B}}$). Do you think that this strategy minimizes the
%  quantization error?
%\item Compare the estimation provided by the entropy with the
%  DEFLATE's bit-rates.
%\end{enumerate}

\section{Timming}

Please, finish this milestone before the next class session.

\section{Deliverables}

None.

\section{Resources}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{data-compression,signal-processing,DWT,image-processing}
