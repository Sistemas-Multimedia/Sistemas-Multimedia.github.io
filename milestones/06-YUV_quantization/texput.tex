\input{../../definitions}
\title{\SM{} - Study Guide - Milestone 6: Removing Redundancy with a Color Transform}

\maketitle

\tableofcontents

\section{Description}

\subsection{Introduction}
Some part of the data in an image can be
\href{https://en.wikipedia.org/wiki/Data_redundancy}{redundant}
(removed without loss of information). In the case of a color image in
the RGB domain, the three components of each pixel, each one measuring
the energy in a different band of the
\href{https://en.wikipedia.org/wiki/Visible_spectrum}{visible
  spectrum}, can be
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlated}.

To estimate the
\href{https://en.wikipedia.org/wiki/Redundancy_(information_theory)}{redundancy}
we have basically two options:
\begin{enumerate}
\item To compute the
  \href{https://en.wikipedia.org/wiki/Entropy_(information_theory)}{0-order
    (memoryless source) entropy} of the signal: the higher the
  entropy, the lower the redudancy. In fact, if we suppose that the
  samples of the signal are uncorrelated, the 0-order entropy is an
  exact measure of the expected bit-rate achieved by an
  \href{https://en.wikipedia.org/wiki/Arithmetic_coding}{arithmetic
    encoder}. Unfortunately, the 0-order entropy is usually only a
  lower bound of the redundancy estimation.
\item A better way is to use an
  \href{https://en.wikipedia.org/wiki/Data_compression}{lossless
    compressor}: the higher the length of the compressed file compared
  to the length of the original file, the lower the
  redundancy.\footnote{If the length of the compressed file is equal or
  larger than the length of the original file, then, for the compressor
  that we are using, there is not redundancy in the original
  representation.} Notice, however, that although this estimation is
  more accurate than the 0-order entropy, in general, it depends on the
  encoding algorithm (different algoritms can provide different
  estimations).
\end{enumerate}

In this milestone, the intercomponent redundancy that may exist
between the color components of each pixel of an image is removed. The
\href{https://en.wikipedia.org/wiki/Color_space}{color spaces} that we
will compare are: (1)
\href{https://en.wikipedia.org/wiki/RGB_color_model}{$\text{RGB}$}
(the original one), (2) the
\href{https://en.wikipedia.org/wiki/YCbCr}{$\text{YCrCb}$}, and (3)
the \href{https://en.wikipedia.org/wiki/YCoCg}{$\text{YCoCg}$}. The
last two , which are \emph{luma}-based (luminance-based) color
domains, rely on the idea of separating the luminance component Y from
two \emph{chroma} components (red and blue in the case of
$\text{YCrCb}$, orange and green in the case of $\text{YCoCg}$) and,
instead of directly encoding the components, encoding components
diﬀerences. This has two main advantages~\cite{burger2016digital}:
\begin{enumerate}
\item Compatibility with legacy black and white systems is maintained
  while at the same time the bandwidth of the signal can be optimized
  by using diﬀerent transmission bandwidths for the brightness and the
  chroma components.
\item Since the \href{https://en.wikipedia.org/wiki/Visual_system}{HVS
  (Human Visual System)} is not able to perceive detail in the color
  components as well as it does in the intensity part of a video
  signal, the amount of information, and
  consequently \href{https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)}{bandwidth},
  used in the color channel can be reduced to approximately 1/4 of
  that used for the intensity component without a noticeable
  distortion. This \href{https://en.wikipedia.org/wiki/Bandwidth_(computing)}{fact
  is also used when compressing} digital still images and is why, for
  example, the \href{https://en.wikipedia.org/wiki/JPEG}{JPEG} codec
  converts RGB images to $\text{YCrCb}$.
\end{enumerate}

\subsection{Some words about transform coding}
Quantization is more effective (the lossy compression ratios are
higher) when the energy of the signal is accumulated in an small
number of samples because we can dedicate more bits to encode the more
energetic samples.\footnote{For example, if the energy of a channel is
low, quantization could completely makes zero such channel, but the
reconstruction of the image would be reasonable. The most part of
entropy codecs (and of course, PNG's DEFLATE) works much better with
sequences of zeros. Therefore, quantizing will improve the compression
ratios.}
\href{https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf}{Transform
  coding} can exploit
\href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation}
in \href{https://en.wikipedia.org/wiki/Signal}{signals} to concentrate
the
\href{https://en.wikipedia.org/wiki/Energy_(signal_processing)}{energy}
in a subset of samples.  All linear\footnote{Non-linear transform are
also possible, but their mathematical treatment is more complicated.}
transforms can be described as a
\href{https://en.wikipedia.org/wiki/Matrix_multiplication}{matrix-vector
  product}~\cite{strang4linear}
\begin{equation}
  \mathbf{y} = \mathbf{K}\mathbf{x},
  \label{eq:forward_transform_matrix_form}
\end{equation}
where $\mathbf{x}$ is the input signal, $\mathbf{K}$ is the analysis
transform matrix, and $\mathbf{y}$ is the output decomposition. Notice
that
\begin{equation}
  {\mathbf{y}}_i = \langle {\mathbf{K}}_i, {\mathbf{x}}_i\rangle,
\end{equation}
where ${\mathbf{K}}_i$ is the $i$-th row of $\mathbf{K}$, and
$\langle\cdot,\cdot\rangle$ denotes the
\href{https://mathworld.wolfram.com/InnerProduct.html}{inner
  product}. This basically means that ${\mathbf{y}}_i$ is proportional to the
\href{https://en.wikipedia.org/wiki/Similarity_(geometry)}{similarity}
between the input signal $\mathbf{x}$ and the
\href{https://en.wikipedia.org/wiki/Finite_impulse_response}{taps} of
the \href{https://en.wikipedia.org/wiki/Digital_filter}{filter}
${\mathbf{K}}_i$.\footnote{These
\href{https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf}{slides}
can help you with this key idea.} The inverse (synthesis) transform is
computed by
\begin{equation}
  \mathbf{x} = {\mathbf{K}}^{-1}\mathbf{y},
  \label{eq:backward_transform_matrix_form}
\end{equation}
where ${\mathbf{K}}^{-1}$ denotes to the inverse matrix of $\mathbf{K}$. For example, the
2x2-\href{https://en.wikipedia.org/wiki/Karhunen-Loeve_theorem}{KLT}~\cite{sayood2017introduction}
is defined by
\begin{equation}
  \begin{bmatrix}
    {\mathbf{y}}_0 \\
    {\mathbf{y}}_1
  \end{bmatrix}
  = 
  \begin{bmatrix} \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{-1}{\sqrt{2}} \end{bmatrix}
  \begin{bmatrix}
    {\mathbf{x}}_0 \\
    {\mathbf{x}}_1
  \end{bmatrix},
  \label{eq:KLT_transform}
\end{equation}
and it holds that
\begin{equation}
  \mathbf{K}={\mathbf{K}}^{-1}={\mathbf{K}}^{\text T},
  \label{eq:orthogonal_matrix}
\end{equation}
where ${\mathbf{K}}^{\text T}$ represents the transpose matrix of
$\mathbf{K}$.  Eq.~\ref{eq:orthogonal_matrix} is true for all
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}
transforms, and therefore
\begin{equation}
  \langle {\mathbf{K}}_i, {\mathbf{K}}_j\rangle = 0, \forall i\neq j.
\end{equation}

\subsection{The \href{https://en.wikipedia.org/wiki/YCbCr}{$\text{RGB/YCrCb}$ transform}}
%\subsubsection{Analysis and synthesis}
To convert a (color) pixel from the $\text{RGB}$ domain into the
$\text{YCrCb}$ one, we use the $\text{RGB/YCrCb}$ (analysis)
transform~\cite{malvar2008lifting}
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{Cr} \\
    \text{Cb}
  \end{bmatrix}
  =
  \begin{bmatrix}
    0.299   &   0.587 & 0.114 \\ 
    0.5     & -0.4187 & -0.0813 \\
    -0.1687 & -0.3313 & 0.5
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix},
  \label{eq:YCrCb}
\end{equation}
where $\text{Y}$ is the luma component and $\text{CrCb}$ are the
chromas. The main reason for such mapping is that the HVS is much less
sensitive to the high-frequency information in the
chromas~\cite{burger2016digital}. Thus, as we mentioned above,
compression systems such as
\href{https://en.wikipedia.org/wiki/JPEG}{JPEG} can
\href{https://en.wikipedia.org/wiki/Downsampling_(signal_processing)}{downsample}
the chroma components (usually by 2:1 in the horizontal and vertical
directions), as well as increase their quantization step sizes with
respect to the luma, to achieve further
\href{https://en.wikipedia.org/wiki/Data_compression_ratio}{compression}~\cite{malvar2008lifting}.

Eq.~\ref{eq:YCrCb}
\href{https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html}{can
  be also written as}
\begin{equation}
  \begin{array}{lcl}
    \text{Y}  & = & 0.299\text{R} + 0.587\text{G} + 0.114\text{B} \\
    \text{Cr} & = & 0.713(\text{R} - \text{Y}) + \delta \\
    \text{Cb} & = & 0.564(\text{B} - \text{Y}) + \delta,
  \end{array}
  \label{eq:alternative_YCrCb}
\end{equation}
where,
\begin{equation}
  \delta = \left\{
  \begin{array}{ll}
    128 & \text{for 8 bits (unsigned) images},\\
    32768 & \text{for 16 bits (unsigned) images},\\
    0.5 & \text{for floating point (}[0,1]\text{) images}
  \end{array}
  \right.
\end{equation}
is used to avoid negative components\footnote{In most transforms
schemes, the output elements of the analysis transform are commonly
called coefficients. However, in the context of the color transform,
the most used term is component.}. As it can be seen, $\text{Cr}$ and
$\text{Cb}$ are scaled versions of $\text{R} - \text{Y}$ and $\text{B}
- \text{Y}$, so $\text{Cr}$ and $\text{Cb}$ can be interpreted as
measures of how much red and blue content in a pixel differs from
luma, respectively. Notice also that for a gray pixel,
$\text{R}=\text{G}=\text{B}=\text{Y}$, and so
$\text{Cr}=\text{Cb}=0$~\cite{malvar2008lifting}.

The inverse (synthesis) transform is defined by
\begin{equation}
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1.402  & 0 \\ 
    1  &  -0.714  &  -0.344 \\ 
    1  & 0  & 1.772
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{Cr} \\
    \text{Cb}
  \end{bmatrix},
\end{equation}
or alternatively, by
\begin{equation}
  \begin{array}{lcl}
    \text{R} & = & \text{Y} + 1.403(\text{Cr} - \delta) \\
    \text{G} & = & \text{Y} - 0.714(\text{Cr} - \delta) - 0.344(\text{Cb} - \delta)\\
    \text{B} & = & \text{Y} + 1.773(\text{Cb} - \delta).
  \end{array}
  \label{eq:iYCrCb}
\end{equation}

As it can be seen, considering that the $\text{RGB}$ values ranges
between $0$ and $255$ (and rounding to the nearest integer),
$0\le\text{Y}\le 255$, $-128\le\text{Cr}\le 127$ and
$-128\le\text{Cb}\le 127$, and therefore, the number of bits that are
necessary to represent each $\text{YCrCb}$ component is 8 (although we
must use floating point arithmetic to perform the transform).

The synthesis filters generates a gain of $||1^2 + 1^2 + 1^2||^2=3$
(squared norm) for the $\text{Y}$ component, $||1.402^2 + 0.714^2 +
0^2||^2=2.4754$ for the $\text{Cr}$ component, and $||0^2 + 0.344^2+
1.772^2||^2=3.25832$ for the $\text{Cb}$ component. So, when
compressing an image through quantization, the QSs should be modulated
accordinly (the higher the gain, the higher the quantization error,
and therefore, the smaller the QS should be).

Finally, notice that the $\text{YCrCb}$ transform is not orthogonal
because the analysis filters are not independent. This can be seen in
the Eq.~\ref{eq:alternative_YCrCb}, where the $\text{Cr}$ values
depend on the values of $\text{Y}$, and therefore, there is a
dependency between both
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis},
and something similar happens for the $\text{Cb}$ components. This can
be also easely checked: $0.299*0.5 + 0.587*(-0.4187) + 0.114*(-0.0813)
= -0.1055451 \neq 0$, $0.299*(-0.1687) + 0.587*(-0.3313) + 0.114*0.5 =
-0.1879144 \neq 0$, and $0.5*(-0.1687) + (-0.4187)*(-0.3313 ) +
(-0.0813)*0.5 = 0.01371531 \neq 0$.

\begin{comment}
\subsubsection{Quantization}
After analyzing the frame (representing it in the YCrCb domain), the
next natural step is quantization. Unfortunately, the RGB/YCrCb
transform is not orthogonal\footnote{The RGB/YCrCb is not orthogonal
because, for example, as we can see in the
Eq.~\ref{eq:YCrCb_analysis}, the value of Cr depends on the value of
Y, and therefore, there is a dependency between both
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis}.}
and therefore the contribution of each channel to the quality of the
reconstructed image $\tilde{X}$ are not additive (this can be seen in
this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}). For
that reason, and only for the sake of simplicity, we will use
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}
\end{comment}

\begin{comment}
Lets suppose that we use a static
uniform dead-zone quantizer with QSs $\Delta_{\text{Y}}$,
$\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$, for the components Y,
Cr, and Cb, repectively. Lets suppose also that the RGB/YCrCb
transform is orthogonal\footnote{The RGB/YCrCb
  is not orthogonal because, for example, as we can see in the
  Eq.~\ref{eq:YCrCb_analysis}, the value of Cr depends on the value of
  Y, and therefore, there is a dependency between both
  \href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis}.},
that is, the filters of the analysis transform are orthogonal (that is
the same that the columns of the synthesis transform are orthogonal),
in order to assume that
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}
is a good quantization pattern. However, 

--------------

and under the
assumption of that the RGB/YCbCr is an
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}
transform and that each channel is compressed independently, the
optimal quantization of the channels should use $\Delta_{\text{Y}}$,
$\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$ so that
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cr}} = \lambda_{\text{Cb}},
  \label{eq:optimal_quantization}
\end{equation}
for a given total bit-rate $R$ (see this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook})~\cite{vetterli1995wavelets,sayood2017introduction}. Therefore,
if all the channels have the same gain\footnote{The gain of a
transform can be determined computing the squared norm of the rows of
the synthesis transform (the synthesis filters).}, a quantization
strategy that should approximate Eq.~\ref{eq:optimal_quantization} is
to use
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
  \label{eq:simple_Q}
\end{equation}
When the gains are not the same, the quantization steps should be
divided\footnote{The squared norms measure the contribution of each
component to the energy of the pixel, and therefore, the higher the
contribution, the lower the $\Delta$.} by the channel gains, that for
the RGB/YCrCb transform are:
\begin{equation*}
  \begin{array}{rl}
    \text{Y}: & 1^2 + 1^2 + 1^2 = 3\\
    \text{Cr}: & 1.402^2 + 0.714^2 = 2.4754\\
    \text{Cb}: & 0.344^2 + 1.772^2 = 3.25832
  \end{array}
\end{equation*}

% Si un coeficiente tiene una gran ganancia es implica que su
% quantization también se dejará sentir más que si la ganancia es
% menor. Por tanto, tiene sentido usar un QS mayor en aquellos
% coeficientes de menor ganancia.

Unfortunately, the RGB/YCrCb transform is not orthogonal. This
means that the quantization noise introduced in one of the channel
will also affect to the rest of channels, which will degrade the RD
performance. The lack of orthogonality also reduces the effectivity of
the previous algorithm for determining the optimal quantization steps.

\end{comment}

\begin{comment}

After analyzing the frame (representing it in the YCrCb domain), the
next natural step is quantization. Supposing that we will use a static
uniform dead-zone quantizer with quantization steps
$\Delta_{\text{Y}}$, $\Delta_{\text{Cr}}$, and $\Delta_{\text{Cb}}$,
for the coefficients Y, Cr, and Cb, repectively, and supposing that
the contribution to the reconstruction of $X$ of one of the
coefficients is not influenced by the contribution of the rest of
coefficients (for this, both color spaces (RGB and YCrCb) should be
\href{https://en.wikipedia.org/wiki/Orthogonality}{orthogonal}), the
optimal quantization steps $\Delta^*_{\text{Y}}$,
$\Delta^*_{\text{Cr}}$, and $\Delta^*_{\text{Cb}}$, can be found using
a constant slope
(\href{https://en.wikipedia.org/wiki/Rate-distortion_theory}{RD}-$\lambda$)
quantization
strategy~\cite{vetterli1995wavelets,sayood2017introduction}.

As it can be seen in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
a RD (Rate-Distortion) curve is a 2D graph where we represent the
distortion generated by the quantization as a function of the bit-rate
of the quantization indexes. Thus, the closer the curve to the point
(0,0) of the graph, the better the performance of the encoding system
in RD terms. Now, if we suppose that each component (Y, Cr, and Cb) is
quantized and compressed independently, we can find the optimal
quantization steps, given a maximum target bit-rate $R^{\text{max}}$,
selecting them as
\begin{equation}
  \lambda_{\text{Y}} = \lambda_{\text{Cr}} = \lambda_{\text{Cb}},
\end{equation}
where $\lambda(R)$ is the slope of the RD curve for a given bit-rate
$R$, satisfiying also that
\begin{equation}
  R_{\text{Y}} + R_{\text{Cr}} + R_{\text{Cb}} \le R^{\text{max}}.
\end{equation}

Unfortunately, the RGB-to-YCrCb transform is not orthogonal (for
example, in Eq.~\ref{eq:YCrCb_analysis}, the value of Cr depends on the
value of Y, and therefore, there is a dependency between both
\href{https://en.wikipedia.org/wiki/Basis_(linear_algebra)}{basis})\footnote{This
can be also seen computing the
\href{https://en.wikipedia.org/wiki/Dot_product}{inner product} of the
basis functions of the analysis transform (only the inner product of
orthogonal vectors is 0). Thus, for example, the product of the basis
functions for Y and Cr is $0.299\times 0.5+0.587\times (-0.4187) +
0.144\times (-0.0813) = -0.1055451$.} and therefore neither the RGB
and the YCrCb spaces. This dificults the finding of
$\Delta^*_{\text{Y}}$, $\Delta^*_{\text{Cr}}$, and
$\Delta^*_{\text{Cb}}$ because the quantization error generated in one
of the components influences the quantization error of the rest of
components, and when this happens, we cannot use CS-RS-QS.

Anyway, as you can see in this
\href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook},
the use of the YCrCb color domain can be beneficial, even using a
simple quantization strategy such as
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Cr}} = \Delta_{\text{Cb}}.
\end{equation}
As it can be seen, the RD curves can be improved for most bit-rates,
and therefore, it can be an interesting tool for removing the
intercomponent redundancy from a pure mathematical point of view.
\end{comment}

\subsection{The \href{https://en.wikipedia.org/wiki/YCoCg}{$\text{RGB/YCoCg}$ transform}}
%\subsubsection{Analysis and synthesis}
Clearly, orthogonality is a desired property in lossy compression
systems because it helps to isolate\footnote{Without considering the
rest of components.} the impact (in the case of a color transform) of
each component on the quality of the reconstruction of the image,
simplifying significantly the determination of the pattern of QSs that
generate the optimal RD curve.

Moreover, Eqs.~\ref{eq:YCrCb} and \ref{eq:iYCrCb} were derived by
\href{https://en.wikipedia.org/wiki/Principal_component_analysis}{Principal
  Component Analysis (PCA)} on old\footnote{Recorded with the first
analog color cameras in the 70's.} video data. The same procedure has
been carried out with newer\footnote{\cite{malvar2008lifting} is dated
in 2008.} images, obtaining
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{C}_1 \\
    \text{C}_2
  \end{bmatrix}
  =
  \begin{bmatrix}
    \frac{1}{3} & \frac{1}{3} &  \frac{1}{3} \\ 
    \frac{1}{2} &           0 & -\frac{1}{2} \\
   -\frac{1}{4} & \frac{1}{2} & -\frac{1}{4}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  \Leftrightarrow
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1  & -\frac{2}{3} \\ 
    1  &  0  &  \frac{4}{3} \\ 
    1  & -1  & -\frac{2}{3}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{C}_1 \\
    \text{C}_2
  \end{bmatrix}.
  \label{eq:optimal}
\end{equation}

This transform is orthogonal and the synthesis filters
gains\footnote{The gain of a transform can be determined computing the
squared norm of the rows of the synthesis transform (the synthesis
filters).} are 22/9 (for $\text{Y}$), 25/9 (for $\text{C}_1$) and 22/9
(for $\text{C}_2$).

Unfortunately, from a perceptual perspective we must impose (thinking
of the subsampling of the chromas) some features in a color transform
(such as the influence of the green channel on the luma channel should
be high) that violates the orthogonality constrain
\cite{malvar2008lifting}. For this reason the authors finally propose
the transform
\begin{equation}
  \begin{bmatrix}
    \text{Y} \\
    \text{Co} \\
    \text{Cg}
  \end{bmatrix}
  =
  \begin{bmatrix}
    \frac{1}{4} &  \frac{1}{2}  &  \frac{1}{4} \\ 
    \frac{1}{2} &            0  & -\frac{1}{2} \\
    -\frac{1}{4} &  \frac{1}{2}  & -\frac{1}{4}
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  \Leftrightarrow
  \begin{bmatrix}
    \text{R} \\
    \text{G} \\
    \text{B}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1  &  1  & -1 \\ 
    1  &  0  &  1 \\ 
    1  & -1  & -1
  \end{bmatrix}
  %\cdot
  \begin{bmatrix}
    \text{Y} \\
    \text{Co} \\
    \text{Cg}
  \end{bmatrix},
\end{equation}
that is near orthogonal\footnote{For example, $\frac{1}{4}\frac{-1}{4}
+ \frac{1}{2}\frac{1}{2} + \frac{1}{4}\frac{-1}{4} = \frac{1}{8}$, and
we should obtain always 0.}, and has channel gains 3 ($\text{Y}$), 2
($\text{Co}$) and 3 ($\text{Cg}$). %These gains suggest that

Again, notice that if the $\text{RGB}$ values ranges between $0$
and $255$ (and rounding to the nearest integer), $0\le\text{Y}\le 255$,
$-128\le\text{Co}\le 127$ and $-128\le\text{Cg}\le 127$, and
therefore, the number of bits that are necessary to represent each
component is $8$. Therefore, we can use the same QS range for each
component.

\subsubsection{Quantization}
The previous channel gains suggest to use
\begin{equation}
  \Delta_{\text{Y}} = \frac{3}{2}\Delta_{\text{Co}} = \Delta_{\text{Cg}}.
\end{equation}
However, as it can be seen in this \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook} the differences with using
\begin{equation}
  \Delta_{\text{Y}} = \Delta_{\text{Co}} = \Delta_{\text{Cg}}.
\end{equation}
are very small. Therefore, this last quantization scheme will be adopted.

\section{What you have to do?}

\begin{enumerate}
\item Please, run the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  to learn some insights about the problem of the optimal
  quantization in the color domain.
\item Include in the previous
  \href{https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/study_guide/06-color_transform/performance.ipynb}{notebook}
  an implementation of the
  \href{https://en.wikipedia.org/wiki/JPEG_2000#Color_components_transformation}{RCT
    (Reversible Color Transform)} and compare it's RD performance with
  the other transforms.
\item Implement the transform described in Eq.~\ref{eq:optimal}, and
  compare it with the other transforms.
\end{enumerate}

\section{Timming}

Please, finish this milestone before the next class session.

\section{Deliverables}

None.

\section{Resources}

\renewcommand{\addcontentsline}[3]{}% Remove functionality of \addcontentsline
\bibliography{maths,data-compression,signal-processing,DWT,image-compression,image-processing}
